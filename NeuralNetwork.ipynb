{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_df = pd.read_csv('Dataset/output_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'country', 'account_currency', 'Trading_Method' and 'active' to categorical\n",
    "modelling_df['country'] = modelling_df['country'].astype('category')\n",
    "modelling_df['account_currency'] = modelling_df['account_currency'].astype('category')\n",
    "modelling_df['Trading_Method'] = modelling_df['Trading_Method'].astype('category')\n",
    "modelling_df['active'] = modelling_df['active'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified columns and set 'longevity' as the target variable\n",
    "X = modelling_df.drop(columns=['login', 'Total_Trades', 'active', 'Unique_Symbols_Traded', 'Average_Volume', 'longevity', 'longevity_bin'])\n",
    "y = modelling_df['longevity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all numeric columns\n",
    "all_numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_cols = ['country', 'account_currency', 'Trading_Method']  # Specified based on the dataset information provided earlier\n",
    "\n",
    "# Columns to exclude from scaling\n",
    "exclude_scaling = ['Buy_Percentage', 'TP/SL Hit Ratio', 'Reward_Risk_Ratio', 'Ratio_Profitable_Trades']\n",
    "\n",
    "# Numeric columns to be scaled\n",
    "numeric_cols_to_scale = [col for col in all_numeric_cols if col not in exclude_scaling]\n",
    "\n",
    "# Create transformers for numeric and categorical data\n",
    "numeric_transformer = RobustScaler()\n",
    "categorical_transformer = OrdinalEncoder()\n",
    "\n",
    "# Create a column transformer to apply the appropriate transformations to each column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_to_scale', numeric_transformer, numeric_cols_to_scale),\n",
    "        ('num_no_scale', 'passthrough', exclude_scaling),  # Pass through without scaling\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply transformations to the features\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get numeric feature names directly for scaled and non-scaled\n",
    "numeric_feature_names = numeric_cols_to_scale + exclude_scaling\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names_corrected = numeric_feature_names + categorical_cols\n",
    "\n",
    "# Creating the complete feature DataFrame with the correct feature names\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: 4866\n",
      "Test Set Size: 859\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed_df, y, test_size=0.15, random_state=42)\n",
    "\n",
    "print(f\"Train Set Size: {X_train.shape[0]}\")\n",
    "print(f\"Test Set Size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "122/122 [==============================] - 2s 8ms/step - loss: 5428.2573 - mae: 44.2334 - val_loss: 4199.3530 - val_mae: 39.4167\n",
      "Epoch 2/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4865.3711 - mae: 42.8557 - val_loss: 3953.3550 - val_mae: 43.7329\n",
      "Epoch 3/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4549.9248 - mae: 41.3648 - val_loss: 3919.0256 - val_mae: 34.1500\n",
      "Epoch 4/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4262.3232 - mae: 39.1661 - val_loss: 3485.3755 - val_mae: 36.5235\n",
      "Epoch 5/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4157.0454 - mae: 39.2050 - val_loss: 3522.9246 - val_mae: 36.4567\n",
      "Epoch 6/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 4224.5288 - mae: 39.0225 - val_loss: 3532.1580 - val_mae: 36.8212\n",
      "Epoch 7/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3966.1172 - mae: 38.0896 - val_loss: 3485.2495 - val_mae: 33.9220\n",
      "Epoch 8/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4135.2769 - mae: 38.3779 - val_loss: 3559.2358 - val_mae: 33.4189\n",
      "Epoch 9/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3861.9966 - mae: 37.3727 - val_loss: 3656.6143 - val_mae: 33.8818\n",
      "Epoch 10/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 4130.2065 - mae: 37.7929 - val_loss: 3391.2969 - val_mae: 34.8331\n",
      "Epoch 11/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3802.9275 - mae: 37.2454 - val_loss: 3654.3396 - val_mae: 32.8182\n",
      "Epoch 12/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3804.4011 - mae: 37.0971 - val_loss: 3554.6404 - val_mae: 32.3756\n",
      "Epoch 13/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3837.3086 - mae: 36.9880 - val_loss: 3492.8652 - val_mae: 34.5144\n",
      "Epoch 14/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3824.8667 - mae: 36.5424 - val_loss: 3456.7908 - val_mae: 33.1505\n",
      "Epoch 15/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3713.9478 - mae: 36.6049 - val_loss: 3497.3850 - val_mae: 36.7957\n",
      "Epoch 16/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3736.6538 - mae: 36.7752 - val_loss: 3615.9585 - val_mae: 33.9998\n",
      "Epoch 17/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3638.1743 - mae: 35.7858 - val_loss: 3464.0364 - val_mae: 35.0285\n",
      "Epoch 18/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3643.8616 - mae: 36.1717 - val_loss: 3507.1589 - val_mae: 34.1166\n",
      "Epoch 19/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3615.1057 - mae: 36.0052 - val_loss: 3500.0037 - val_mae: 36.7562\n",
      "Epoch 20/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3480.6672 - mae: 35.5342 - val_loss: 3556.7004 - val_mae: 33.6753\n",
      "Epoch 21/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3582.6331 - mae: 35.6000 - val_loss: 3481.0374 - val_mae: 34.5887\n",
      "Epoch 22/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3549.1394 - mae: 35.5837 - val_loss: 3521.0693 - val_mae: 35.2678\n",
      "Epoch 23/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3456.5583 - mae: 34.9902 - val_loss: 3535.8003 - val_mae: 32.9348\n",
      "Epoch 24/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3396.0869 - mae: 34.6616 - val_loss: 3620.9307 - val_mae: 33.0800\n",
      "Epoch 25/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3467.6028 - mae: 35.1883 - val_loss: 3535.4060 - val_mae: 35.7769\n",
      "Epoch 26/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3456.4673 - mae: 35.0702 - val_loss: 3615.9241 - val_mae: 33.1269\n",
      "Epoch 27/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3382.4521 - mae: 34.5441 - val_loss: 3789.3132 - val_mae: 33.6798\n",
      "Epoch 28/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3380.4651 - mae: 34.7479 - val_loss: 3481.4399 - val_mae: 35.9164\n",
      "Epoch 29/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3295.4724 - mae: 34.5191 - val_loss: 3769.9143 - val_mae: 33.2163\n",
      "Epoch 30/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3376.0493 - mae: 34.7639 - val_loss: 3745.7129 - val_mae: 33.4036\n",
      "Epoch 31/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3301.3459 - mae: 34.0438 - val_loss: 3625.9482 - val_mae: 35.0167\n",
      "Epoch 32/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3261.8904 - mae: 34.1180 - val_loss: 3468.9495 - val_mae: 33.2465\n",
      "Epoch 33/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3265.1309 - mae: 34.0055 - val_loss: 3773.3716 - val_mae: 33.1170\n",
      "Epoch 34/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3217.1833 - mae: 33.3790 - val_loss: 3667.8198 - val_mae: 33.3117\n",
      "Epoch 35/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3248.9531 - mae: 34.1378 - val_loss: 3507.9807 - val_mae: 33.9673\n",
      "Epoch 36/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3300.1963 - mae: 33.9100 - val_loss: 3627.7405 - val_mae: 33.1261\n",
      "Epoch 37/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3188.0713 - mae: 33.4064 - val_loss: 3594.4158 - val_mae: 34.1431\n",
      "Epoch 38/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3233.6274 - mae: 33.5075 - val_loss: 3485.6670 - val_mae: 34.5692\n",
      "Epoch 39/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3238.5852 - mae: 33.5320 - val_loss: 3567.7681 - val_mae: 33.0057\n",
      "Epoch 40/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3086.8494 - mae: 32.9858 - val_loss: 3701.5676 - val_mae: 34.6127\n",
      "Epoch 41/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3220.4177 - mae: 33.2537 - val_loss: 3645.2532 - val_mae: 33.6384\n",
      "Epoch 42/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3296.2959 - mae: 33.3219 - val_loss: 3634.9182 - val_mae: 35.2007\n",
      "Epoch 43/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2934.8813 - mae: 32.8592 - val_loss: 3725.8396 - val_mae: 35.9248\n",
      "Epoch 44/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2985.4539 - mae: 32.5678 - val_loss: 3648.6157 - val_mae: 33.4581\n",
      "Epoch 45/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3146.7637 - mae: 33.1823 - val_loss: 3642.6306 - val_mae: 34.0896\n",
      "Epoch 46/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3087.1150 - mae: 32.8536 - val_loss: 3629.8511 - val_mae: 33.1390\n",
      "Epoch 47/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3135.4380 - mae: 32.7023 - val_loss: 3613.8892 - val_mae: 32.6957\n",
      "Epoch 48/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3027.9089 - mae: 33.1712 - val_loss: 3619.2004 - val_mae: 34.8533\n",
      "Epoch 49/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2940.8894 - mae: 32.0412 - val_loss: 3467.8630 - val_mae: 34.1420\n",
      "Epoch 50/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 3007.7732 - mae: 32.4783 - val_loss: 3478.3521 - val_mae: 33.1243\n",
      "Epoch 51/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2989.5793 - mae: 32.4491 - val_loss: 3546.7488 - val_mae: 32.1792\n",
      "Epoch 52/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2960.9409 - mae: 32.1041 - val_loss: 3463.8865 - val_mae: 33.1346\n",
      "Epoch 53/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2854.4873 - mae: 32.1184 - val_loss: 3672.4836 - val_mae: 33.4994\n",
      "Epoch 54/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2903.6433 - mae: 31.5923 - val_loss: 3585.2407 - val_mae: 32.6842\n",
      "Epoch 55/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2771.5027 - mae: 31.5494 - val_loss: 3651.6865 - val_mae: 33.2978\n",
      "Epoch 56/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2675.1697 - mae: 31.0260 - val_loss: 3539.7598 - val_mae: 32.3684\n",
      "Epoch 57/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2745.3013 - mae: 31.5668 - val_loss: 3621.4741 - val_mae: 32.8896\n",
      "Epoch 58/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2800.0996 - mae: 31.1502 - val_loss: 3559.7861 - val_mae: 34.5679\n",
      "Epoch 59/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 3051.8970 - mae: 32.6128 - val_loss: 3558.3906 - val_mae: 33.5667\n",
      "Epoch 60/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2768.0798 - mae: 31.0881 - val_loss: 3705.6067 - val_mae: 33.3780\n",
      "Epoch 61/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2609.8237 - mae: 30.5572 - val_loss: 3432.3618 - val_mae: 34.1154\n",
      "Epoch 62/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2856.0410 - mae: 31.2627 - val_loss: 3547.2515 - val_mae: 33.4444\n",
      "Epoch 63/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2638.9812 - mae: 30.8800 - val_loss: 3860.9082 - val_mae: 34.8139\n",
      "Epoch 64/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2656.2336 - mae: 30.9579 - val_loss: 3647.2551 - val_mae: 32.8876\n",
      "Epoch 65/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2527.4070 - mae: 30.5547 - val_loss: 3558.5957 - val_mae: 34.1523\n",
      "Epoch 66/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2667.3516 - mae: 30.6476 - val_loss: 3629.5508 - val_mae: 33.3849\n",
      "Epoch 67/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2496.5740 - mae: 29.9589 - val_loss: 3606.8188 - val_mae: 32.3263\n",
      "Epoch 68/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2519.6479 - mae: 30.1272 - val_loss: 3536.7312 - val_mae: 33.5782\n",
      "Epoch 69/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2582.0537 - mae: 30.4231 - val_loss: 3582.2534 - val_mae: 32.8897\n",
      "Epoch 70/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2561.7974 - mae: 30.0040 - val_loss: 3455.0227 - val_mae: 32.9013\n",
      "Epoch 71/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2591.4587 - mae: 30.4593 - val_loss: 3607.4419 - val_mae: 32.4485\n",
      "Epoch 72/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2411.8613 - mae: 29.3077 - val_loss: 3375.2056 - val_mae: 32.4675\n",
      "Epoch 73/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2563.9182 - mae: 30.4891 - val_loss: 3588.7065 - val_mae: 32.4645\n",
      "Epoch 74/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2583.0894 - mae: 30.1044 - val_loss: 3482.7014 - val_mae: 31.9879\n",
      "Epoch 75/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2448.8923 - mae: 29.8501 - val_loss: 3626.5864 - val_mae: 34.1251\n",
      "Epoch 76/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2481.1785 - mae: 29.9809 - val_loss: 3677.2773 - val_mae: 32.5041\n",
      "Epoch 77/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2409.3748 - mae: 29.3243 - val_loss: 3623.9678 - val_mae: 33.2502\n",
      "Epoch 78/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2247.6792 - mae: 28.6239 - val_loss: 3634.9629 - val_mae: 32.4142\n",
      "Epoch 79/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2484.0164 - mae: 29.6618 - val_loss: 3458.5342 - val_mae: 33.1577\n",
      "Epoch 80/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2333.9893 - mae: 29.2279 - val_loss: 3580.2227 - val_mae: 33.4857\n",
      "Epoch 81/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2336.6807 - mae: 29.5705 - val_loss: 3655.1873 - val_mae: 32.7161\n",
      "Epoch 82/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2331.0447 - mae: 28.9102 - val_loss: 3705.6230 - val_mae: 35.4726\n",
      "Epoch 83/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2238.1233 - mae: 28.7391 - val_loss: 3838.3359 - val_mae: 35.9629\n",
      "Epoch 84/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2253.6448 - mae: 28.7154 - val_loss: 3655.7129 - val_mae: 33.9544\n",
      "Epoch 85/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2284.3174 - mae: 28.9981 - val_loss: 3622.9592 - val_mae: 31.7415\n",
      "Epoch 86/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2353.9602 - mae: 28.9186 - val_loss: 3603.4592 - val_mae: 33.6146\n",
      "Epoch 87/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2326.5684 - mae: 29.0549 - val_loss: 3692.2993 - val_mae: 32.9236\n",
      "Epoch 88/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2293.7520 - mae: 28.6234 - val_loss: 3553.0977 - val_mae: 32.3025\n",
      "Epoch 89/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2207.7439 - mae: 28.2821 - val_loss: 3619.2722 - val_mae: 32.2947\n",
      "Epoch 90/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2296.4707 - mae: 28.9555 - val_loss: 3632.9885 - val_mae: 31.9798\n",
      "Epoch 91/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2265.1533 - mae: 28.3325 - val_loss: 3779.9485 - val_mae: 34.3602\n",
      "Epoch 92/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2274.1877 - mae: 28.1996 - val_loss: 3517.1704 - val_mae: 33.7006\n",
      "Epoch 93/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2244.0735 - mae: 28.3830 - val_loss: 3492.7053 - val_mae: 32.7584\n",
      "Epoch 94/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2100.8293 - mae: 27.9354 - val_loss: 3668.6514 - val_mae: 33.3059\n",
      "Epoch 95/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2245.9868 - mae: 28.1449 - val_loss: 3702.1782 - val_mae: 35.2920\n",
      "Epoch 96/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2143.7913 - mae: 27.9156 - val_loss: 3691.0833 - val_mae: 33.1846\n",
      "Epoch 97/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2301.0706 - mae: 28.4752 - val_loss: 3608.1995 - val_mae: 32.8450\n",
      "Epoch 98/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2060.1509 - mae: 27.4831 - val_loss: 3609.4536 - val_mae: 33.1401\n",
      "Epoch 99/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2115.5576 - mae: 27.8480 - val_loss: 3561.1589 - val_mae: 33.7982\n",
      "Epoch 100/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2232.2148 - mae: 28.5457 - val_loss: 3564.6094 - val_mae: 33.1305\n",
      "Epoch 101/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1952.7029 - mae: 27.0266 - val_loss: 3719.5542 - val_mae: 33.1985\n",
      "Epoch 102/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2012.2914 - mae: 27.2426 - val_loss: 3614.4192 - val_mae: 32.9689\n",
      "Epoch 103/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1976.5826 - mae: 27.2341 - val_loss: 3705.8650 - val_mae: 32.1326\n",
      "Epoch 104/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2124.0596 - mae: 27.5408 - val_loss: 3827.8833 - val_mae: 34.2793\n",
      "Epoch 105/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1988.6652 - mae: 26.6459 - val_loss: 3712.2708 - val_mae: 32.7446\n",
      "Epoch 106/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1999.0024 - mae: 27.0356 - val_loss: 3559.5688 - val_mae: 32.7277\n",
      "Epoch 107/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1903.4072 - mae: 26.9590 - val_loss: 3713.7393 - val_mae: 32.1418\n",
      "Epoch 108/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 2034.5985 - mae: 27.3510 - val_loss: 3756.0950 - val_mae: 33.5276\n",
      "Epoch 109/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2033.0996 - mae: 26.7942 - val_loss: 3566.0308 - val_mae: 32.8325\n",
      "Epoch 110/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 2052.0247 - mae: 27.2613 - val_loss: 3591.4773 - val_mae: 33.1209\n",
      "Epoch 111/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1928.2963 - mae: 26.7739 - val_loss: 3531.5283 - val_mae: 32.7820\n",
      "Epoch 112/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1983.1260 - mae: 26.6698 - val_loss: 3660.0029 - val_mae: 32.9170\n",
      "Epoch 113/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1990.1329 - mae: 26.6657 - val_loss: 3543.8801 - val_mae: 32.4750\n",
      "Epoch 114/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1973.5040 - mae: 26.6479 - val_loss: 3696.2231 - val_mae: 33.4935\n",
      "Epoch 115/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1863.1643 - mae: 26.1972 - val_loss: 3688.7842 - val_mae: 32.7556\n",
      "Epoch 116/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1995.6089 - mae: 26.8455 - val_loss: 3524.4565 - val_mae: 31.9948\n",
      "Epoch 117/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1816.8938 - mae: 26.1724 - val_loss: 3697.1531 - val_mae: 33.2412\n",
      "Epoch 118/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1847.6647 - mae: 25.7524 - val_loss: 3669.5850 - val_mae: 32.8546\n",
      "Epoch 119/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1936.3405 - mae: 26.6724 - val_loss: 3601.4045 - val_mae: 32.8345\n",
      "Epoch 120/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1850.2098 - mae: 26.4422 - val_loss: 3686.5405 - val_mae: 32.5508\n",
      "Epoch 121/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1814.9349 - mae: 25.8834 - val_loss: 3602.2090 - val_mae: 32.6377\n",
      "Epoch 122/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1834.7264 - mae: 25.9260 - val_loss: 3617.4692 - val_mae: 32.7805\n",
      "Epoch 123/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1857.3119 - mae: 26.1011 - val_loss: 3582.8394 - val_mae: 32.7404\n",
      "Epoch 124/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1883.6495 - mae: 25.8958 - val_loss: 3531.7559 - val_mae: 32.0614\n",
      "Epoch 125/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1816.9297 - mae: 25.9464 - val_loss: 3617.0808 - val_mae: 33.3398\n",
      "Epoch 126/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1773.5009 - mae: 25.8092 - val_loss: 3617.9329 - val_mae: 32.6655\n",
      "Epoch 127/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1819.7991 - mae: 25.5589 - val_loss: 3599.5435 - val_mae: 32.7253\n",
      "Epoch 128/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1824.7012 - mae: 25.8141 - val_loss: 3738.8718 - val_mae: 32.8099\n",
      "Epoch 129/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1862.8601 - mae: 25.7404 - val_loss: 3555.4885 - val_mae: 32.6690\n",
      "Epoch 130/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1674.0211 - mae: 24.4833 - val_loss: 3498.3213 - val_mae: 32.0764\n",
      "Epoch 131/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1720.5366 - mae: 25.2058 - val_loss: 3697.0247 - val_mae: 33.2413\n",
      "Epoch 132/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1838.4404 - mae: 25.5519 - val_loss: 3707.4692 - val_mae: 32.3135\n",
      "Epoch 133/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1717.3433 - mae: 25.0925 - val_loss: 3602.3320 - val_mae: 33.1884\n",
      "Epoch 134/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1718.6724 - mae: 24.8952 - val_loss: 3796.1394 - val_mae: 33.8507\n",
      "Epoch 135/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1680.2239 - mae: 25.1131 - val_loss: 3674.9646 - val_mae: 32.9753\n",
      "Epoch 136/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1731.8501 - mae: 25.3516 - val_loss: 3748.7529 - val_mae: 34.2192\n",
      "Epoch 137/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1794.3774 - mae: 25.7143 - val_loss: 3635.5022 - val_mae: 32.4484\n",
      "Epoch 138/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1799.9114 - mae: 25.1234 - val_loss: 3478.9380 - val_mae: 33.0715\n",
      "Epoch 139/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1646.2029 - mae: 24.3296 - val_loss: 3731.9390 - val_mae: 32.5836\n",
      "Epoch 140/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1680.7834 - mae: 24.8784 - val_loss: 3575.8936 - val_mae: 32.7230\n",
      "Epoch 141/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1707.4685 - mae: 24.8153 - val_loss: 3594.9641 - val_mae: 32.7539\n",
      "Epoch 142/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1748.2833 - mae: 25.4264 - val_loss: 3521.5308 - val_mae: 32.7381\n",
      "Epoch 143/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1710.1226 - mae: 24.9127 - val_loss: 3544.6929 - val_mae: 32.3717\n",
      "Epoch 144/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1725.1659 - mae: 25.1515 - val_loss: 3598.9763 - val_mae: 33.1464\n",
      "Epoch 145/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1717.8802 - mae: 24.5910 - val_loss: 3570.8882 - val_mae: 32.8861\n",
      "Epoch 146/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1734.4038 - mae: 24.7046 - val_loss: 3506.7834 - val_mae: 32.3778\n",
      "Epoch 147/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1675.4763 - mae: 24.5726 - val_loss: 3506.4717 - val_mae: 32.2201\n",
      "Epoch 148/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1650.5522 - mae: 24.4520 - val_loss: 3521.1213 - val_mae: 31.8943\n",
      "Epoch 149/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1586.7013 - mae: 24.1087 - val_loss: 3656.1260 - val_mae: 32.7750\n",
      "Epoch 150/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1671.5929 - mae: 24.5309 - val_loss: 3496.8892 - val_mae: 32.0922\n",
      "Epoch 151/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1619.8799 - mae: 24.2536 - val_loss: 3576.8511 - val_mae: 32.6651\n",
      "Epoch 152/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1612.8340 - mae: 24.3508 - val_loss: 3560.0320 - val_mae: 32.3300\n",
      "Epoch 153/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1621.0630 - mae: 24.5306 - val_loss: 3601.5869 - val_mae: 32.7710\n",
      "Epoch 154/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1692.7493 - mae: 24.6507 - val_loss: 3565.9265 - val_mae: 33.2265\n",
      "Epoch 155/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1705.5795 - mae: 24.9316 - val_loss: 3611.2839 - val_mae: 32.7838\n",
      "Epoch 156/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1634.8264 - mae: 24.2009 - val_loss: 3556.9468 - val_mae: 33.3365\n",
      "Epoch 157/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1659.8450 - mae: 24.4780 - val_loss: 3863.8271 - val_mae: 33.3232\n",
      "Epoch 158/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1566.5999 - mae: 24.1032 - val_loss: 3503.3203 - val_mae: 32.8082\n",
      "Epoch 159/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1517.5928 - mae: 23.5864 - val_loss: 3495.4233 - val_mae: 32.0558\n",
      "Epoch 160/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1496.4292 - mae: 23.4496 - val_loss: 3521.1140 - val_mae: 32.6878\n",
      "Epoch 161/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1624.9136 - mae: 24.2197 - val_loss: 3532.0627 - val_mae: 32.1079\n",
      "Epoch 162/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1506.4236 - mae: 23.4053 - val_loss: 3537.2119 - val_mae: 32.3472\n",
      "Epoch 163/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1630.8459 - mae: 24.1669 - val_loss: 3606.5945 - val_mae: 32.5189\n",
      "Epoch 164/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1662.7937 - mae: 24.4132 - val_loss: 3511.4121 - val_mae: 32.4583\n",
      "Epoch 165/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1525.5498 - mae: 23.9541 - val_loss: 3652.8865 - val_mae: 32.8519\n",
      "Epoch 166/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1535.9843 - mae: 23.4239 - val_loss: 3687.1860 - val_mae: 34.5966\n",
      "Epoch 167/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1426.5071 - mae: 23.1540 - val_loss: 3591.4131 - val_mae: 32.9768\n",
      "Epoch 168/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1513.4972 - mae: 23.7932 - val_loss: 3529.7820 - val_mae: 31.8017\n",
      "Epoch 169/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1542.5513 - mae: 23.7750 - val_loss: 3566.1245 - val_mae: 32.8476\n",
      "Epoch 170/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1583.7751 - mae: 23.9304 - val_loss: 3616.0334 - val_mae: 32.9912\n",
      "Epoch 171/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1478.2771 - mae: 23.1085 - val_loss: 3629.6245 - val_mae: 33.4832\n",
      "Epoch 172/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1452.9353 - mae: 23.3606 - val_loss: 3477.5229 - val_mae: 32.6660\n",
      "Epoch 173/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1590.5452 - mae: 24.0929 - val_loss: 3499.6438 - val_mae: 32.7192\n",
      "Epoch 174/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1454.4667 - mae: 23.0857 - val_loss: 3501.3813 - val_mae: 32.1719\n",
      "Epoch 175/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1533.0441 - mae: 23.4827 - val_loss: 3594.2000 - val_mae: 32.9578\n",
      "Epoch 176/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1462.9794 - mae: 23.3079 - val_loss: 3611.6860 - val_mae: 32.9357\n",
      "Epoch 177/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1495.1807 - mae: 23.4759 - val_loss: 3684.0608 - val_mae: 34.1927\n",
      "Epoch 178/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1531.2883 - mae: 23.6776 - val_loss: 3638.1392 - val_mae: 33.0315\n",
      "Epoch 179/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1477.9291 - mae: 23.1646 - val_loss: 3742.7737 - val_mae: 33.2217\n",
      "Epoch 180/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1526.4673 - mae: 23.4200 - val_loss: 3592.5227 - val_mae: 32.7624\n",
      "Epoch 181/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1473.1935 - mae: 23.3150 - val_loss: 3636.3262 - val_mae: 33.9568\n",
      "Epoch 182/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1427.0469 - mae: 22.8931 - val_loss: 3917.4023 - val_mae: 32.9289\n",
      "Epoch 183/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1530.4806 - mae: 23.3697 - val_loss: 3567.6106 - val_mae: 32.0652\n",
      "Epoch 184/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1388.4142 - mae: 22.7714 - val_loss: 3499.7632 - val_mae: 32.3763\n",
      "Epoch 185/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1476.8398 - mae: 23.1577 - val_loss: 3639.8044 - val_mae: 33.0135\n",
      "Epoch 186/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1427.8104 - mae: 22.9371 - val_loss: 3600.6067 - val_mae: 32.9136\n",
      "Epoch 187/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1480.8409 - mae: 23.2835 - val_loss: 3599.3203 - val_mae: 32.7439\n",
      "Epoch 188/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1345.6750 - mae: 22.4188 - val_loss: 3643.9907 - val_mae: 32.6767\n",
      "Epoch 189/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1417.2104 - mae: 22.6672 - val_loss: 3640.2212 - val_mae: 32.8099\n",
      "Epoch 190/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1421.6776 - mae: 22.8474 - val_loss: 3634.7622 - val_mae: 33.2632\n",
      "Epoch 191/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1428.0673 - mae: 23.1167 - val_loss: 3666.9773 - val_mae: 32.2483\n",
      "Epoch 192/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1370.4114 - mae: 22.5168 - val_loss: 3595.0339 - val_mae: 32.1947\n",
      "Epoch 193/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1317.2566 - mae: 22.5052 - val_loss: 3637.8979 - val_mae: 32.3742\n",
      "Epoch 194/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1466.7794 - mae: 23.0309 - val_loss: 3628.6819 - val_mae: 32.5190\n",
      "Epoch 195/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1370.4331 - mae: 22.5203 - val_loss: 3564.6865 - val_mae: 32.2613\n",
      "Epoch 196/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1414.5250 - mae: 22.8961 - val_loss: 3565.4397 - val_mae: 32.8358\n",
      "Epoch 197/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1255.4945 - mae: 21.9053 - val_loss: 3591.2878 - val_mae: 31.9568\n",
      "Epoch 198/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1317.7549 - mae: 22.0831 - val_loss: 3641.4014 - val_mae: 32.5389\n",
      "Epoch 199/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1345.7711 - mae: 22.2518 - val_loss: 3627.6653 - val_mae: 33.0756\n",
      "Epoch 200/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1516.0054 - mae: 23.1068 - val_loss: 3567.6189 - val_mae: 33.0690\n",
      "Epoch 201/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1504.0659 - mae: 23.1983 - val_loss: 3611.3406 - val_mae: 32.7776\n",
      "Epoch 202/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1320.9722 - mae: 22.3501 - val_loss: 3704.3704 - val_mae: 33.7846\n",
      "Epoch 203/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1288.7288 - mae: 22.1366 - val_loss: 3652.4792 - val_mae: 33.4023\n",
      "Epoch 204/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1388.4271 - mae: 22.5317 - val_loss: 3664.6045 - val_mae: 33.6028\n",
      "Epoch 205/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1377.5557 - mae: 22.3698 - val_loss: 3670.4060 - val_mae: 33.8891\n",
      "Epoch 206/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1436.9327 - mae: 22.5942 - val_loss: 3630.5002 - val_mae: 32.5801\n",
      "Epoch 207/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1286.3257 - mae: 21.8391 - val_loss: 3641.7312 - val_mae: 33.0992\n",
      "Epoch 208/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1216.3691 - mae: 21.5302 - val_loss: 3614.6704 - val_mae: 33.3026\n",
      "Epoch 209/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1319.8550 - mae: 21.8589 - val_loss: 3541.1863 - val_mae: 32.7358\n",
      "Epoch 210/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1373.2563 - mae: 22.2735 - val_loss: 3653.2510 - val_mae: 33.0017\n",
      "Epoch 211/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1344.9320 - mae: 22.1994 - val_loss: 3656.1189 - val_mae: 33.1160\n",
      "Epoch 212/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1319.0392 - mae: 22.2775 - val_loss: 3640.2661 - val_mae: 33.4334\n",
      "Epoch 213/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1311.8733 - mae: 21.8158 - val_loss: 3633.8098 - val_mae: 33.1298\n",
      "Epoch 214/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1399.7688 - mae: 22.4827 - val_loss: 3676.8198 - val_mae: 32.8403\n",
      "Epoch 215/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1344.4546 - mae: 22.1807 - val_loss: 3656.7434 - val_mae: 33.5801\n",
      "Epoch 216/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1349.6171 - mae: 22.1308 - val_loss: 3736.1880 - val_mae: 33.2255\n",
      "Epoch 217/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1175.7854 - mae: 21.4004 - val_loss: 3661.6956 - val_mae: 32.9982\n",
      "Epoch 218/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1305.6061 - mae: 21.5740 - val_loss: 3605.4792 - val_mae: 32.9632\n",
      "Epoch 219/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1279.7246 - mae: 21.5326 - val_loss: 3640.9878 - val_mae: 32.9002\n",
      "Epoch 220/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1346.8706 - mae: 21.8848 - val_loss: 3716.8508 - val_mae: 32.5192\n",
      "Epoch 221/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1239.3641 - mae: 21.6961 - val_loss: 3628.2354 - val_mae: 33.7048\n",
      "Epoch 222/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1259.7922 - mae: 21.0611 - val_loss: 3601.9128 - val_mae: 33.4924\n",
      "Epoch 223/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1227.9778 - mae: 21.2157 - val_loss: 3720.6167 - val_mae: 33.1633\n",
      "Epoch 224/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1284.2738 - mae: 21.6436 - val_loss: 3623.5112 - val_mae: 34.0786\n",
      "Epoch 225/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1257.6340 - mae: 21.4031 - val_loss: 3642.0984 - val_mae: 34.0071\n",
      "Epoch 226/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1157.2817 - mae: 21.0348 - val_loss: 3657.7483 - val_mae: 33.2560\n",
      "Epoch 227/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1222.8042 - mae: 21.4341 - val_loss: 3774.6548 - val_mae: 34.0037\n",
      "Epoch 228/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1296.7852 - mae: 21.6884 - val_loss: 3708.9937 - val_mae: 33.2959\n",
      "Epoch 229/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1273.9557 - mae: 21.2312 - val_loss: 3730.3660 - val_mae: 33.7825\n",
      "Epoch 230/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1318.5614 - mae: 21.7617 - val_loss: 3634.7893 - val_mae: 33.9045\n",
      "Epoch 231/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1275.6405 - mae: 21.4975 - val_loss: 3576.4116 - val_mae: 33.3976\n",
      "Epoch 232/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1279.6553 - mae: 21.6261 - val_loss: 3665.8914 - val_mae: 33.1184\n",
      "Epoch 233/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1221.6714 - mae: 21.3240 - val_loss: 3681.2493 - val_mae: 33.0360\n",
      "Epoch 234/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1233.2037 - mae: 21.2405 - val_loss: 3665.0571 - val_mae: 33.3753\n",
      "Epoch 235/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1313.2893 - mae: 21.7283 - val_loss: 3604.0151 - val_mae: 32.5892\n",
      "Epoch 236/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1266.9143 - mae: 21.1593 - val_loss: 3674.6858 - val_mae: 33.5648\n",
      "Epoch 237/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1185.8182 - mae: 20.9431 - val_loss: 3792.8064 - val_mae: 33.9204\n",
      "Epoch 238/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1239.9514 - mae: 21.2894 - val_loss: 3739.1604 - val_mae: 34.3990\n",
      "Epoch 239/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1272.9995 - mae: 21.3415 - val_loss: 3674.9199 - val_mae: 33.3673\n",
      "Epoch 240/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1261.2318 - mae: 21.2574 - val_loss: 3598.7947 - val_mae: 33.1602\n",
      "Epoch 241/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1296.8146 - mae: 21.6155 - val_loss: 3689.4919 - val_mae: 32.9087\n",
      "Epoch 242/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1360.0703 - mae: 21.9122 - val_loss: 3625.7351 - val_mae: 32.9373\n",
      "Epoch 243/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1247.7670 - mae: 21.4643 - val_loss: 3756.9128 - val_mae: 33.5132\n",
      "Epoch 244/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1158.3097 - mae: 20.6414 - val_loss: 3601.5750 - val_mae: 33.3644\n",
      "Epoch 245/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1232.9233 - mae: 21.2450 - val_loss: 3659.6682 - val_mae: 33.3606\n",
      "Epoch 246/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1177.4938 - mae: 20.5965 - val_loss: 3574.1265 - val_mae: 33.5842\n",
      "Epoch 247/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1232.2195 - mae: 20.9060 - val_loss: 3626.6538 - val_mae: 33.6922\n",
      "Epoch 248/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1208.9119 - mae: 20.8108 - val_loss: 3603.7212 - val_mae: 33.0467\n",
      "Epoch 249/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1163.7643 - mae: 20.4656 - val_loss: 3605.6665 - val_mae: 32.8028\n",
      "Epoch 250/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1232.0876 - mae: 20.8226 - val_loss: 3600.8528 - val_mae: 33.1949\n",
      "Epoch 251/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1191.0721 - mae: 21.1112 - val_loss: 3661.5764 - val_mae: 33.9161\n",
      "Epoch 252/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1152.0886 - mae: 20.9139 - val_loss: 3776.8403 - val_mae: 33.7160\n",
      "Epoch 253/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1271.6710 - mae: 21.3745 - val_loss: 3683.4807 - val_mae: 33.3681\n",
      "Epoch 254/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1154.5283 - mae: 20.7164 - val_loss: 3633.0120 - val_mae: 34.0316\n",
      "Epoch 255/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1242.9838 - mae: 21.1054 - val_loss: 3663.0659 - val_mae: 32.7532\n",
      "Epoch 256/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1140.4230 - mae: 20.4920 - val_loss: 3589.9268 - val_mae: 34.1967\n",
      "Epoch 257/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1250.3038 - mae: 20.8376 - val_loss: 3602.7068 - val_mae: 33.5735\n",
      "Epoch 258/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1150.8916 - mae: 20.4925 - val_loss: 3738.0142 - val_mae: 34.2874\n",
      "Epoch 259/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1126.7181 - mae: 20.6787 - val_loss: 3648.4451 - val_mae: 33.5450\n",
      "Epoch 260/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1110.2413 - mae: 20.2402 - val_loss: 3621.3606 - val_mae: 33.3586\n",
      "Epoch 261/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1083.4824 - mae: 20.1091 - val_loss: 3839.4668 - val_mae: 35.1657\n",
      "Epoch 262/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1161.8068 - mae: 20.6628 - val_loss: 3676.1580 - val_mae: 33.3299\n",
      "Epoch 263/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1127.9092 - mae: 20.4465 - val_loss: 3727.1746 - val_mae: 33.5238\n",
      "Epoch 264/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1157.9646 - mae: 20.6547 - val_loss: 3577.3127 - val_mae: 32.7995\n",
      "Epoch 265/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1063.3413 - mae: 20.1904 - val_loss: 3697.3853 - val_mae: 33.3534\n",
      "Epoch 266/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1183.9747 - mae: 20.8313 - val_loss: 3713.4541 - val_mae: 33.5161\n",
      "Epoch 267/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1160.9421 - mae: 20.6021 - val_loss: 3728.4023 - val_mae: 34.3164\n",
      "Epoch 268/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1152.0430 - mae: 20.3469 - val_loss: 3603.4651 - val_mae: 33.3879\n",
      "Epoch 269/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1086.6854 - mae: 20.3652 - val_loss: 3613.1790 - val_mae: 33.3654\n",
      "Epoch 270/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1065.0162 - mae: 19.5534 - val_loss: 3665.0229 - val_mae: 33.5898\n",
      "Epoch 271/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 995.8277 - mae: 19.5874 - val_loss: 3637.0022 - val_mae: 33.5224\n",
      "Epoch 272/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1079.4508 - mae: 19.8047 - val_loss: 3704.5229 - val_mae: 33.7400\n",
      "Epoch 273/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1144.0575 - mae: 20.4302 - val_loss: 3677.8804 - val_mae: 33.5578\n",
      "Epoch 274/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1157.2031 - mae: 20.3172 - val_loss: 3565.9756 - val_mae: 32.4392\n",
      "Epoch 275/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1144.8947 - mae: 19.9847 - val_loss: 3705.7371 - val_mae: 33.2675\n",
      "Epoch 276/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1161.9023 - mae: 20.2054 - val_loss: 3666.1150 - val_mae: 33.8280\n",
      "Epoch 277/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1053.0558 - mae: 19.4939 - val_loss: 3562.2117 - val_mae: 33.0755\n",
      "Epoch 278/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1125.5800 - mae: 19.8385 - val_loss: 3650.6577 - val_mae: 33.6727\n",
      "Epoch 279/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1182.6788 - mae: 20.1966 - val_loss: 3685.4844 - val_mae: 33.3956\n",
      "Epoch 280/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1227.8304 - mae: 20.2033 - val_loss: 3615.9153 - val_mae: 33.2166\n",
      "Epoch 281/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1132.6686 - mae: 20.2632 - val_loss: 3571.8896 - val_mae: 33.3149\n",
      "Epoch 282/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1011.0443 - mae: 19.7644 - val_loss: 3656.7473 - val_mae: 33.1700\n",
      "Epoch 283/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1092.5431 - mae: 19.9684 - val_loss: 3503.8416 - val_mae: 33.1973\n",
      "Epoch 284/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1110.6750 - mae: 20.0337 - val_loss: 3635.8113 - val_mae: 33.8717\n",
      "Epoch 285/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1107.5096 - mae: 19.7022 - val_loss: 3632.6833 - val_mae: 33.1658\n",
      "Epoch 286/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1055.7302 - mae: 19.8809 - val_loss: 3787.0664 - val_mae: 34.3510\n",
      "Epoch 287/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1106.2612 - mae: 20.1198 - val_loss: 3595.9229 - val_mae: 33.4411\n",
      "Epoch 288/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1049.8455 - mae: 19.5945 - val_loss: 3673.9219 - val_mae: 33.2498\n",
      "Epoch 289/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1194.4021 - mae: 20.0903 - val_loss: 3671.3904 - val_mae: 33.0629\n",
      "Epoch 290/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1031.0338 - mae: 19.4826 - val_loss: 3724.4995 - val_mae: 33.5480\n",
      "Epoch 291/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1131.2163 - mae: 19.4832 - val_loss: 3641.1670 - val_mae: 32.8162\n",
      "Epoch 292/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1158.1104 - mae: 20.2302 - val_loss: 3607.0708 - val_mae: 32.4847\n",
      "Epoch 293/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1004.8852 - mae: 19.1313 - val_loss: 3622.9890 - val_mae: 33.4108\n",
      "Epoch 294/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1015.5919 - mae: 19.0607 - val_loss: 3671.1292 - val_mae: 33.6230\n",
      "Epoch 295/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1007.2492 - mae: 19.1116 - val_loss: 3624.2871 - val_mae: 32.4041\n",
      "Epoch 296/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1062.5393 - mae: 19.2988 - val_loss: 3591.0078 - val_mae: 32.5447\n",
      "Epoch 297/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1107.2079 - mae: 19.5268 - val_loss: 3610.6782 - val_mae: 33.2258\n",
      "Epoch 298/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1117.3704 - mae: 19.5828 - val_loss: 3679.2388 - val_mae: 32.9973\n",
      "Epoch 299/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1057.3671 - mae: 19.2426 - val_loss: 3622.2053 - val_mae: 33.3043\n",
      "Epoch 300/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 984.8147 - mae: 18.7862 - val_loss: 3662.9045 - val_mae: 32.8184\n",
      "Epoch 301/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1120.7213 - mae: 19.3416 - val_loss: 3700.3584 - val_mae: 32.7825\n",
      "Epoch 302/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1124.2407 - mae: 19.5402 - val_loss: 3702.0911 - val_mae: 33.3638\n",
      "Epoch 303/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1126.2725 - mae: 19.6771 - val_loss: 3639.0457 - val_mae: 32.8119\n",
      "Epoch 304/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1056.0553 - mae: 19.2953 - val_loss: 3671.1792 - val_mae: 33.2869\n",
      "Epoch 305/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1086.7430 - mae: 19.5586 - val_loss: 3749.3894 - val_mae: 33.4585\n",
      "Epoch 306/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1137.3962 - mae: 19.7623 - val_loss: 3671.3982 - val_mae: 33.3968\n",
      "Epoch 307/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1148.3921 - mae: 19.5461 - val_loss: 3544.2380 - val_mae: 32.5325\n",
      "Epoch 308/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1011.5899 - mae: 19.2839 - val_loss: 3610.7932 - val_mae: 32.9465\n",
      "Epoch 309/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 980.7740 - mae: 18.8332 - val_loss: 3635.0779 - val_mae: 32.9846\n",
      "Epoch 310/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1014.9281 - mae: 18.7075 - val_loss: 3634.2312 - val_mae: 32.6952\n",
      "Epoch 311/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1013.9030 - mae: 18.8930 - val_loss: 3580.7554 - val_mae: 32.6101\n",
      "Epoch 312/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 954.8721 - mae: 18.6693 - val_loss: 3580.2622 - val_mae: 32.1925\n",
      "Epoch 313/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1052.6241 - mae: 19.1308 - val_loss: 3732.8240 - val_mae: 32.8089\n",
      "Epoch 314/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1006.7640 - mae: 18.7762 - val_loss: 3614.8137 - val_mae: 32.8242\n",
      "Epoch 315/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1026.2360 - mae: 18.9513 - val_loss: 3766.9373 - val_mae: 34.1348\n",
      "Epoch 316/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1033.5638 - mae: 19.0632 - val_loss: 3727.1665 - val_mae: 33.6053\n",
      "Epoch 317/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 979.8694 - mae: 18.5737 - val_loss: 3840.9529 - val_mae: 33.2249\n",
      "Epoch 318/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1015.9362 - mae: 19.0356 - val_loss: 3810.5752 - val_mae: 33.5843\n",
      "Epoch 319/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1031.3824 - mae: 18.9760 - val_loss: 3672.0012 - val_mae: 33.1509\n",
      "Epoch 320/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 988.0707 - mae: 18.5230 - val_loss: 3621.4839 - val_mae: 33.0377\n",
      "Epoch 321/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 974.2156 - mae: 18.5622 - val_loss: 3650.4133 - val_mae: 32.9731\n",
      "Epoch 322/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1030.5370 - mae: 19.0216 - val_loss: 3639.3816 - val_mae: 33.3935\n",
      "Epoch 323/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 950.0786 - mae: 18.5864 - val_loss: 3658.9202 - val_mae: 32.8619\n",
      "Epoch 324/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 934.7495 - mae: 18.7208 - val_loss: 3770.6155 - val_mae: 33.4855\n",
      "Epoch 325/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 981.7201 - mae: 18.8532 - val_loss: 3607.1306 - val_mae: 32.5451\n",
      "Epoch 326/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 927.8012 - mae: 18.2881 - val_loss: 3635.0247 - val_mae: 32.7024\n",
      "Epoch 327/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 982.4575 - mae: 18.4745 - val_loss: 3722.7637 - val_mae: 33.3829\n",
      "Epoch 328/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1004.4985 - mae: 18.9137 - val_loss: 3726.7219 - val_mae: 33.5958\n",
      "Epoch 329/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1011.1541 - mae: 18.8864 - val_loss: 3634.0142 - val_mae: 33.2239\n",
      "Epoch 330/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 965.8690 - mae: 18.4039 - val_loss: 3643.6221 - val_mae: 32.8484\n",
      "Epoch 331/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1046.8862 - mae: 19.1002 - val_loss: 3660.3350 - val_mae: 34.3453\n",
      "Epoch 332/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 963.4909 - mae: 18.8965 - val_loss: 3667.2385 - val_mae: 33.3203\n",
      "Epoch 333/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 957.4404 - mae: 18.4857 - val_loss: 3729.7756 - val_mae: 33.4621\n",
      "Epoch 334/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 973.3937 - mae: 18.5849 - val_loss: 3659.3616 - val_mae: 33.2606\n",
      "Epoch 335/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 1045.2633 - mae: 18.4926 - val_loss: 3528.5676 - val_mae: 32.8609\n",
      "Epoch 336/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 900.3685 - mae: 17.9483 - val_loss: 3678.7122 - val_mae: 33.7517\n",
      "Epoch 337/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1088.8184 - mae: 19.6435 - val_loss: 3719.6738 - val_mae: 34.0577\n",
      "Epoch 338/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 927.5595 - mae: 18.7961 - val_loss: 3697.2942 - val_mae: 34.0495\n",
      "Epoch 339/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 942.3857 - mae: 18.5122 - val_loss: 3638.5667 - val_mae: 33.0260\n",
      "Epoch 340/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 951.8393 - mae: 18.4279 - val_loss: 3698.1709 - val_mae: 33.2051\n",
      "Epoch 341/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 974.2612 - mae: 18.6815 - val_loss: 3640.1521 - val_mae: 33.2512\n",
      "Epoch 342/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 970.6744 - mae: 18.7842 - val_loss: 3551.0005 - val_mae: 32.6918\n",
      "Epoch 343/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 994.0451 - mae: 18.5669 - val_loss: 3570.4465 - val_mae: 32.8880\n",
      "Epoch 344/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1018.3910 - mae: 18.8866 - val_loss: 3638.6091 - val_mae: 32.9544\n",
      "Epoch 345/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 989.6548 - mae: 18.7753 - val_loss: 3706.6282 - val_mae: 33.8274\n",
      "Epoch 346/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1004.9051 - mae: 18.4417 - val_loss: 3722.6182 - val_mae: 33.4991\n",
      "Epoch 347/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 866.4247 - mae: 17.6716 - val_loss: 3678.7141 - val_mae: 33.6049\n",
      "Epoch 348/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 905.3447 - mae: 18.5076 - val_loss: 3674.0378 - val_mae: 33.8467\n",
      "Epoch 349/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 929.3685 - mae: 18.2109 - val_loss: 3614.1470 - val_mae: 32.6196\n",
      "Epoch 350/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 975.4572 - mae: 18.5846 - val_loss: 3734.3682 - val_mae: 33.1272\n",
      "Epoch 351/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 951.8251 - mae: 18.4103 - val_loss: 3667.8718 - val_mae: 32.7493\n",
      "Epoch 352/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 954.9128 - mae: 18.3631 - val_loss: 3596.4341 - val_mae: 32.8741\n",
      "Epoch 353/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 942.8067 - mae: 18.0233 - val_loss: 3622.0164 - val_mae: 32.9219\n",
      "Epoch 354/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 899.7134 - mae: 17.9537 - val_loss: 3628.7554 - val_mae: 32.3830\n",
      "Epoch 355/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 965.9347 - mae: 18.0977 - val_loss: 3665.4856 - val_mae: 33.4767\n",
      "Epoch 356/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1001.8072 - mae: 18.3740 - val_loss: 3879.6638 - val_mae: 34.1013\n",
      "Epoch 357/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 964.1862 - mae: 18.6380 - val_loss: 3803.3950 - val_mae: 34.7107\n",
      "Epoch 358/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 970.9230 - mae: 18.0806 - val_loss: 3646.5029 - val_mae: 32.6407\n",
      "Epoch 359/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 940.9802 - mae: 18.1626 - val_loss: 3570.2610 - val_mae: 32.9877\n",
      "Epoch 360/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 912.8198 - mae: 18.0788 - val_loss: 3581.8665 - val_mae: 33.7475\n",
      "Epoch 361/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 975.6358 - mae: 18.5693 - val_loss: 3617.9751 - val_mae: 32.4527\n",
      "Epoch 362/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 929.9719 - mae: 18.0245 - val_loss: 3623.2878 - val_mae: 32.6367\n",
      "Epoch 363/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1009.5676 - mae: 18.4757 - val_loss: 3535.8198 - val_mae: 33.3971\n",
      "Epoch 364/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 886.6194 - mae: 17.7248 - val_loss: 3597.6372 - val_mae: 32.9961\n",
      "Epoch 365/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 857.6949 - mae: 17.6160 - val_loss: 3610.8850 - val_mae: 33.7237\n",
      "Epoch 366/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 982.7083 - mae: 19.1318 - val_loss: 3746.9807 - val_mae: 34.3218\n",
      "Epoch 367/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 961.8193 - mae: 18.3497 - val_loss: 3548.7351 - val_mae: 32.6161\n",
      "Epoch 368/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 989.6118 - mae: 18.2688 - val_loss: 3630.7520 - val_mae: 33.0567\n",
      "Epoch 369/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 912.3127 - mae: 17.7090 - val_loss: 3658.9802 - val_mae: 33.0322\n",
      "Epoch 370/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 891.9267 - mae: 17.5743 - val_loss: 3735.0698 - val_mae: 33.0509\n",
      "Epoch 371/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 954.2916 - mae: 18.3100 - val_loss: 3643.3289 - val_mae: 32.8593\n",
      "Epoch 372/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 884.0982 - mae: 17.8144 - val_loss: 3674.0884 - val_mae: 33.2870\n",
      "Epoch 373/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 943.2438 - mae: 18.4267 - val_loss: 3705.9968 - val_mae: 34.1852\n",
      "Epoch 374/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 950.2426 - mae: 18.1365 - val_loss: 3571.0771 - val_mae: 33.0033\n",
      "Epoch 375/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 941.8437 - mae: 17.9616 - val_loss: 3641.1680 - val_mae: 33.0966\n",
      "Epoch 376/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 911.2632 - mae: 17.7646 - val_loss: 3614.6931 - val_mae: 33.0408\n",
      "Epoch 377/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 828.3971 - mae: 17.4585 - val_loss: 3556.3101 - val_mae: 32.5395\n",
      "Epoch 378/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 994.1702 - mae: 18.2104 - val_loss: 3651.0083 - val_mae: 33.4229\n",
      "Epoch 379/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 971.4423 - mae: 18.0129 - val_loss: 3652.0994 - val_mae: 33.4837\n",
      "Epoch 380/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 961.8852 - mae: 18.2185 - val_loss: 3816.9080 - val_mae: 34.8011\n",
      "Epoch 381/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 937.9414 - mae: 18.0101 - val_loss: 3573.1511 - val_mae: 33.3428\n",
      "Epoch 382/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 875.9102 - mae: 17.4394 - val_loss: 3573.8267 - val_mae: 33.9884\n",
      "Epoch 383/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 941.6845 - mae: 18.9401 - val_loss: 3668.0247 - val_mae: 34.2106\n",
      "Epoch 384/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 967.0394 - mae: 18.2765 - val_loss: 3678.3970 - val_mae: 34.1538\n",
      "Epoch 385/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 817.2414 - mae: 17.3397 - val_loss: 3594.1492 - val_mae: 33.4612\n",
      "Epoch 386/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 911.3994 - mae: 17.8206 - val_loss: 3664.6838 - val_mae: 33.6856\n",
      "Epoch 387/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 899.2454 - mae: 17.6684 - val_loss: 3635.0603 - val_mae: 33.4880\n",
      "Epoch 388/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 832.1758 - mae: 17.4974 - val_loss: 3764.8328 - val_mae: 33.6184\n",
      "Epoch 389/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 927.7667 - mae: 17.8228 - val_loss: 3612.6499 - val_mae: 33.6637\n",
      "Epoch 390/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 857.3680 - mae: 17.5882 - val_loss: 3631.2012 - val_mae: 33.1485\n",
      "Epoch 391/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 952.5038 - mae: 17.5961 - val_loss: 3538.3560 - val_mae: 33.1289\n",
      "Epoch 392/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 910.7615 - mae: 17.8260 - val_loss: 3671.1365 - val_mae: 33.7814\n",
      "Epoch 393/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 829.4410 - mae: 17.3102 - val_loss: 3607.1306 - val_mae: 32.8307\n",
      "Epoch 394/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 951.7797 - mae: 18.4869 - val_loss: 3624.4280 - val_mae: 33.5562\n",
      "Epoch 395/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 926.9010 - mae: 17.8451 - val_loss: 3744.4709 - val_mae: 33.2774\n",
      "Epoch 396/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 982.0286 - mae: 18.4092 - val_loss: 3636.8005 - val_mae: 32.8714\n",
      "Epoch 397/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 854.0045 - mae: 17.5301 - val_loss: 3758.2505 - val_mae: 34.5673\n",
      "Epoch 398/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 975.4683 - mae: 18.0425 - val_loss: 3702.5359 - val_mae: 34.2528\n",
      "Epoch 399/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 868.1617 - mae: 17.5828 - val_loss: 3727.5073 - val_mae: 33.7175\n",
      "Epoch 400/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 878.6764 - mae: 17.4080 - val_loss: 3618.3923 - val_mae: 33.3907\n",
      "Epoch 401/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 846.2976 - mae: 17.2335 - val_loss: 3564.8123 - val_mae: 32.8960\n",
      "Epoch 402/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 837.7714 - mae: 17.3430 - val_loss: 3763.3857 - val_mae: 33.4862\n",
      "Epoch 403/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 818.5483 - mae: 17.0087 - val_loss: 3652.0962 - val_mae: 33.2971\n",
      "Epoch 404/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 787.6505 - mae: 16.7426 - val_loss: 3730.5396 - val_mae: 34.1965\n",
      "Epoch 405/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 831.7297 - mae: 17.1877 - val_loss: 3587.2903 - val_mae: 33.3093\n",
      "Epoch 406/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 840.0236 - mae: 16.9426 - val_loss: 3679.3655 - val_mae: 33.2764\n",
      "Epoch 407/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 761.2932 - mae: 16.5681 - val_loss: 3586.6763 - val_mae: 33.1615\n",
      "Epoch 408/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 835.8519 - mae: 17.1963 - val_loss: 3569.5439 - val_mae: 33.3169\n",
      "Epoch 409/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 816.7165 - mae: 16.8788 - val_loss: 3627.5984 - val_mae: 32.9223\n",
      "Epoch 410/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 796.1461 - mae: 16.8823 - val_loss: 3616.5181 - val_mae: 32.7258\n",
      "Epoch 411/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 829.3136 - mae: 17.2225 - val_loss: 3700.5779 - val_mae: 33.3943\n",
      "Epoch 412/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 770.5278 - mae: 16.4778 - val_loss: 3595.2969 - val_mae: 33.6695\n",
      "Epoch 413/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 905.3140 - mae: 17.5992 - val_loss: 3677.8569 - val_mae: 33.3841\n",
      "Epoch 414/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 830.9385 - mae: 17.1198 - val_loss: 3663.3340 - val_mae: 33.5683\n",
      "Epoch 415/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 925.8234 - mae: 17.3142 - val_loss: 3675.0784 - val_mae: 33.2740\n",
      "Epoch 416/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 900.9195 - mae: 17.4097 - val_loss: 3717.1365 - val_mae: 33.6877\n",
      "Epoch 417/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 850.5801 - mae: 17.5032 - val_loss: 3702.3296 - val_mae: 33.5722\n",
      "Epoch 418/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 793.9258 - mae: 16.9732 - val_loss: 3596.5132 - val_mae: 33.2687\n",
      "Epoch 419/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 936.4988 - mae: 17.6308 - val_loss: 3634.1694 - val_mae: 32.9234\n",
      "Epoch 420/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 871.3910 - mae: 17.3274 - val_loss: 3672.9902 - val_mae: 33.3712\n",
      "Epoch 421/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 864.9705 - mae: 17.5412 - val_loss: 3673.4316 - val_mae: 34.3462\n",
      "Epoch 422/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 877.2068 - mae: 18.1223 - val_loss: 3667.1128 - val_mae: 35.0144\n",
      "Epoch 423/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 858.6320 - mae: 18.0376 - val_loss: 3788.9883 - val_mae: 35.7742\n",
      "Epoch 424/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 897.1118 - mae: 18.0275 - val_loss: 3673.6301 - val_mae: 34.0207\n",
      "Epoch 425/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 801.4680 - mae: 17.2363 - val_loss: 3769.5098 - val_mae: 34.3668\n",
      "Epoch 426/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 815.8468 - mae: 17.2066 - val_loss: 3725.0549 - val_mae: 33.7235\n",
      "Epoch 427/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 865.8417 - mae: 17.4036 - val_loss: 3742.7129 - val_mae: 34.5318\n",
      "Epoch 428/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 869.5449 - mae: 17.5986 - val_loss: 3701.5784 - val_mae: 34.0290\n",
      "Epoch 429/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 874.4346 - mae: 17.6318 - val_loss: 3714.3096 - val_mae: 33.4918\n",
      "Epoch 430/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 889.6008 - mae: 17.7748 - val_loss: 3709.3943 - val_mae: 33.9068\n",
      "Epoch 431/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 757.1912 - mae: 16.4873 - val_loss: 3840.7278 - val_mae: 34.0063\n",
      "Epoch 432/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 895.5124 - mae: 17.5389 - val_loss: 3621.7019 - val_mae: 33.3208\n",
      "Epoch 433/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 718.6461 - mae: 16.5140 - val_loss: 3610.6243 - val_mae: 32.9681\n",
      "Epoch 434/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 828.4041 - mae: 17.0295 - val_loss: 3633.4260 - val_mae: 33.5186\n",
      "Epoch 435/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 831.7998 - mae: 17.1528 - val_loss: 3704.6318 - val_mae: 33.6236\n",
      "Epoch 436/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 799.9675 - mae: 16.8854 - val_loss: 3709.1707 - val_mae: 33.7771\n",
      "Epoch 437/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 845.7406 - mae: 17.0100 - val_loss: 3625.1565 - val_mae: 32.6467\n",
      "Epoch 438/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 858.9396 - mae: 17.1728 - val_loss: 3655.3647 - val_mae: 32.8201\n",
      "Epoch 439/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 841.5229 - mae: 17.2815 - val_loss: 3599.1057 - val_mae: 33.0331\n",
      "Epoch 440/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 774.7302 - mae: 16.8748 - val_loss: 3727.1870 - val_mae: 33.7041\n",
      "Epoch 441/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 854.4022 - mae: 17.1699 - val_loss: 3633.5005 - val_mae: 33.7604\n",
      "Epoch 442/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 835.1364 - mae: 16.8470 - val_loss: 3660.0271 - val_mae: 33.5413\n",
      "Epoch 443/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 818.3876 - mae: 16.8757 - val_loss: 3626.9224 - val_mae: 33.0214\n",
      "Epoch 444/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 819.8381 - mae: 17.1323 - val_loss: 3720.8923 - val_mae: 33.7473\n",
      "Epoch 445/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 852.8436 - mae: 17.1267 - val_loss: 3683.9873 - val_mae: 33.6041\n",
      "Epoch 446/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 790.5654 - mae: 16.8520 - val_loss: 3624.3101 - val_mae: 33.2626\n",
      "Epoch 447/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 876.7015 - mae: 16.9628 - val_loss: 3692.9470 - val_mae: 33.5139\n",
      "Epoch 448/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 884.9824 - mae: 17.2286 - val_loss: 3786.0205 - val_mae: 33.7845\n",
      "Epoch 449/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 764.6798 - mae: 16.6700 - val_loss: 3537.7493 - val_mae: 33.5621\n",
      "Epoch 450/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 873.4077 - mae: 17.5261 - val_loss: 3509.9307 - val_mae: 33.3339\n",
      "Epoch 451/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 816.9371 - mae: 16.9926 - val_loss: 3634.1218 - val_mae: 33.5608\n",
      "Epoch 452/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 780.2910 - mae: 16.8590 - val_loss: 3792.6233 - val_mae: 34.2075\n",
      "Epoch 453/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 760.4688 - mae: 16.6617 - val_loss: 3589.8293 - val_mae: 33.4750\n",
      "Epoch 454/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 723.5933 - mae: 16.2275 - val_loss: 3697.0762 - val_mae: 34.2066\n",
      "Epoch 455/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 827.1215 - mae: 16.5218 - val_loss: 3574.6409 - val_mae: 32.8744\n",
      "Epoch 456/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 811.8766 - mae: 16.8366 - val_loss: 3619.8831 - val_mae: 34.2082\n",
      "Epoch 457/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 758.3878 - mae: 16.4117 - val_loss: 3581.1621 - val_mae: 33.7072\n",
      "Epoch 458/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 855.5963 - mae: 16.7250 - val_loss: 3615.5759 - val_mae: 33.7808\n",
      "Epoch 459/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 846.8866 - mae: 17.2211 - val_loss: 3692.6045 - val_mae: 33.7707\n",
      "Epoch 460/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 801.1328 - mae: 16.8504 - val_loss: 3637.3579 - val_mae: 32.7333\n",
      "Epoch 461/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 763.6567 - mae: 16.5545 - val_loss: 3700.5513 - val_mae: 33.5321\n",
      "Epoch 462/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 829.7051 - mae: 16.8231 - val_loss: 3660.3440 - val_mae: 33.0008\n",
      "Epoch 463/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 834.0101 - mae: 16.5860 - val_loss: 3714.9531 - val_mae: 33.6943\n",
      "Epoch 464/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 759.4629 - mae: 16.4145 - val_loss: 3629.8022 - val_mae: 33.5568\n",
      "Epoch 465/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 702.9232 - mae: 16.0808 - val_loss: 3567.3792 - val_mae: 33.3378\n",
      "Epoch 466/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 777.6639 - mae: 16.5646 - val_loss: 3589.0347 - val_mae: 33.9742\n",
      "Epoch 467/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 728.2048 - mae: 16.1597 - val_loss: 3724.1213 - val_mae: 33.5287\n",
      "Epoch 468/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 811.5454 - mae: 16.5129 - val_loss: 3743.9426 - val_mae: 34.8837\n",
      "Epoch 469/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 829.8120 - mae: 16.6264 - val_loss: 3726.4370 - val_mae: 34.2970\n",
      "Epoch 470/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 832.4056 - mae: 17.0441 - val_loss: 3682.2502 - val_mae: 33.5842\n",
      "Epoch 471/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 738.6089 - mae: 16.3551 - val_loss: 3639.8088 - val_mae: 33.1838\n",
      "Epoch 472/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 763.1686 - mae: 16.5282 - val_loss: 3603.7273 - val_mae: 33.3707\n",
      "Epoch 473/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 788.3188 - mae: 16.6017 - val_loss: 3623.0669 - val_mae: 33.5683\n",
      "Epoch 474/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 801.7864 - mae: 16.8479 - val_loss: 3618.6885 - val_mae: 33.2634\n",
      "Epoch 475/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 845.2307 - mae: 16.9084 - val_loss: 3610.4465 - val_mae: 33.0641\n",
      "Epoch 476/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 838.0177 - mae: 16.6342 - val_loss: 3788.5627 - val_mae: 34.0752\n",
      "Epoch 477/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 799.4359 - mae: 16.6601 - val_loss: 3729.0605 - val_mae: 33.3516\n",
      "Epoch 478/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 802.5150 - mae: 16.7453 - val_loss: 3662.2229 - val_mae: 33.9160\n",
      "Epoch 479/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 796.3696 - mae: 16.6911 - val_loss: 3737.7544 - val_mae: 34.0607\n",
      "Epoch 480/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 849.4397 - mae: 16.9731 - val_loss: 3629.4045 - val_mae: 33.5684\n",
      "Epoch 481/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 830.6810 - mae: 16.3750 - val_loss: 3696.5039 - val_mae: 33.2574\n",
      "Epoch 482/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 795.1009 - mae: 16.3609 - val_loss: 3666.3264 - val_mae: 33.5224\n",
      "Epoch 483/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 805.7400 - mae: 16.6245 - val_loss: 3588.7148 - val_mae: 34.5494\n",
      "Epoch 484/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 811.7690 - mae: 17.2871 - val_loss: 3657.0410 - val_mae: 33.9872\n",
      "Epoch 485/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 752.5049 - mae: 16.7499 - val_loss: 3643.1558 - val_mae: 34.2808\n",
      "Epoch 486/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 775.4955 - mae: 16.8492 - val_loss: 3637.5488 - val_mae: 34.0405\n",
      "Epoch 487/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 819.4257 - mae: 17.0882 - val_loss: 3586.2896 - val_mae: 33.2855\n",
      "Epoch 488/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 843.7540 - mae: 16.9552 - val_loss: 3647.8442 - val_mae: 33.7556\n",
      "Epoch 489/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 773.8411 - mae: 16.2995 - val_loss: 3711.6511 - val_mae: 33.2230\n",
      "Epoch 490/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 801.4830 - mae: 16.6081 - val_loss: 3711.0945 - val_mae: 34.0601\n",
      "Epoch 491/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 742.8494 - mae: 15.9784 - val_loss: 3794.9656 - val_mae: 34.6743\n",
      "Epoch 492/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 732.1928 - mae: 16.2729 - val_loss: 3651.4722 - val_mae: 33.4694\n",
      "Epoch 493/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 736.0440 - mae: 16.1871 - val_loss: 3592.6111 - val_mae: 32.9042\n",
      "Epoch 494/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 751.7222 - mae: 16.3785 - val_loss: 3660.5938 - val_mae: 33.8429\n",
      "Epoch 495/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 670.9551 - mae: 15.5657 - val_loss: 3632.0261 - val_mae: 33.2605\n",
      "Epoch 496/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 735.2875 - mae: 16.0005 - val_loss: 3616.2327 - val_mae: 33.5409\n",
      "Epoch 497/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 665.2739 - mae: 15.7448 - val_loss: 3722.0732 - val_mae: 34.1149\n",
      "Epoch 498/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 760.2474 - mae: 16.0316 - val_loss: 3590.9866 - val_mae: 32.9111\n",
      "Epoch 499/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 733.7104 - mae: 16.7112 - val_loss: 3598.4045 - val_mae: 34.3562\n",
      "Epoch 500/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 725.3895 - mae: 16.3445 - val_loss: 3688.1558 - val_mae: 33.8302\n",
      "Epoch 501/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 720.4896 - mae: 16.1736 - val_loss: 3744.4729 - val_mae: 34.0256\n",
      "Epoch 502/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 787.8118 - mae: 16.5098 - val_loss: 3645.6843 - val_mae: 33.0133\n",
      "Epoch 503/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 765.0672 - mae: 16.1076 - val_loss: 3613.9746 - val_mae: 33.9332\n",
      "Epoch 504/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 750.4155 - mae: 16.0926 - val_loss: 3573.6929 - val_mae: 32.9242\n",
      "Epoch 505/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 738.1194 - mae: 16.2415 - val_loss: 3552.5247 - val_mae: 33.0360\n",
      "Epoch 506/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 791.4693 - mae: 16.6057 - val_loss: 3690.4709 - val_mae: 33.9297\n",
      "Epoch 507/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 757.0523 - mae: 16.0025 - val_loss: 3639.8262 - val_mae: 33.9547\n",
      "Epoch 508/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 741.9467 - mae: 16.3096 - val_loss: 3634.4629 - val_mae: 33.5005\n",
      "Epoch 509/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 770.8190 - mae: 16.3287 - val_loss: 3853.7559 - val_mae: 35.1144\n",
      "Epoch 510/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 833.4484 - mae: 17.0468 - val_loss: 3689.9233 - val_mae: 33.6455\n",
      "Epoch 511/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 778.9656 - mae: 16.2534 - val_loss: 3601.2200 - val_mae: 33.2175\n",
      "Epoch 512/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 760.8926 - mae: 15.9222 - val_loss: 3645.0264 - val_mae: 32.8708\n",
      "Epoch 513/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 734.7268 - mae: 16.2400 - val_loss: 3681.5398 - val_mae: 34.0328\n",
      "Epoch 514/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 769.6755 - mae: 16.2425 - val_loss: 3688.2603 - val_mae: 34.0096\n",
      "Epoch 515/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 694.0042 - mae: 15.7944 - val_loss: 3572.9214 - val_mae: 33.3292\n",
      "Epoch 516/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 644.4943 - mae: 15.4417 - val_loss: 3702.5195 - val_mae: 33.8860\n",
      "Epoch 517/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 785.5818 - mae: 16.3305 - val_loss: 3630.3586 - val_mae: 33.2057\n",
      "Epoch 518/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 694.9249 - mae: 15.7934 - val_loss: 3549.9802 - val_mae: 32.9157\n",
      "Epoch 519/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 737.9952 - mae: 16.2147 - val_loss: 3654.5627 - val_mae: 33.7868\n",
      "Epoch 520/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 730.0231 - mae: 15.9488 - val_loss: 3640.0278 - val_mae: 33.7277\n",
      "Epoch 521/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 684.4832 - mae: 15.4193 - val_loss: 3577.1260 - val_mae: 33.4056\n",
      "Epoch 522/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 725.6031 - mae: 15.8466 - val_loss: 3679.6677 - val_mae: 34.5080\n",
      "Epoch 523/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 729.5221 - mae: 15.7978 - val_loss: 3526.8591 - val_mae: 33.0065\n",
      "Epoch 524/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 748.0571 - mae: 16.0551 - val_loss: 3604.8247 - val_mae: 33.6017\n",
      "Epoch 525/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 880.2510 - mae: 16.9456 - val_loss: 3608.3630 - val_mae: 33.0449\n",
      "Epoch 526/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 772.1879 - mae: 16.3226 - val_loss: 3621.1877 - val_mae: 33.2417\n",
      "Epoch 527/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 744.2092 - mae: 15.8517 - val_loss: 3589.8074 - val_mae: 32.8394\n",
      "Epoch 528/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 782.5479 - mae: 16.3102 - val_loss: 3627.2695 - val_mae: 33.2451\n",
      "Epoch 529/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 664.1491 - mae: 15.4933 - val_loss: 3654.4956 - val_mae: 33.4477\n",
      "Epoch 530/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 677.3539 - mae: 15.6821 - val_loss: 3654.8879 - val_mae: 33.3030\n",
      "Epoch 531/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 777.9149 - mae: 16.0483 - val_loss: 3658.8738 - val_mae: 34.0831\n",
      "Epoch 532/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 737.4266 - mae: 15.8943 - val_loss: 3613.4221 - val_mae: 33.7152\n",
      "Epoch 533/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 668.2469 - mae: 15.5315 - val_loss: 3626.7261 - val_mae: 33.0535\n",
      "Epoch 534/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 724.9250 - mae: 15.8986 - val_loss: 3719.4402 - val_mae: 34.2829\n",
      "Epoch 535/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 699.5370 - mae: 15.7149 - val_loss: 3549.6968 - val_mae: 33.1323\n",
      "Epoch 536/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 666.5729 - mae: 15.4199 - val_loss: 3662.4666 - val_mae: 34.1082\n",
      "Epoch 537/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 768.4851 - mae: 16.0634 - val_loss: 3589.7759 - val_mae: 33.2453\n",
      "Epoch 538/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 695.8580 - mae: 15.7745 - val_loss: 3572.2278 - val_mae: 33.2477\n",
      "Epoch 539/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 698.1172 - mae: 15.5993 - val_loss: 3661.0146 - val_mae: 33.4700\n",
      "Epoch 540/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 768.4017 - mae: 15.9197 - val_loss: 3700.3623 - val_mae: 33.9651\n",
      "Epoch 541/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 740.2961 - mae: 15.7537 - val_loss: 3626.2654 - val_mae: 33.0651\n",
      "Epoch 542/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 742.9645 - mae: 16.1524 - val_loss: 3617.5803 - val_mae: 33.4737\n",
      "Epoch 543/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 677.5701 - mae: 15.3556 - val_loss: 3583.9404 - val_mae: 33.6766\n",
      "Epoch 544/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 702.3674 - mae: 15.9610 - val_loss: 3523.8860 - val_mae: 33.5509\n",
      "Epoch 545/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 713.7750 - mae: 15.6319 - val_loss: 3487.5540 - val_mae: 32.6074\n",
      "Epoch 546/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 652.6301 - mae: 15.3025 - val_loss: 3526.2922 - val_mae: 33.2138\n",
      "Epoch 547/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 680.3236 - mae: 15.5908 - val_loss: 3493.8130 - val_mae: 33.5276\n",
      "Epoch 548/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 731.5727 - mae: 15.8460 - val_loss: 3595.3457 - val_mae: 33.0524\n",
      "Epoch 549/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 681.9120 - mae: 15.4922 - val_loss: 3752.1335 - val_mae: 34.3185\n",
      "Epoch 550/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 815.1393 - mae: 16.0437 - val_loss: 3649.7720 - val_mae: 33.9950\n",
      "Epoch 551/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 771.2919 - mae: 16.1240 - val_loss: 3552.6592 - val_mae: 33.3830\n",
      "Epoch 552/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 794.5551 - mae: 16.1753 - val_loss: 3700.8542 - val_mae: 33.9762\n",
      "Epoch 553/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 739.9114 - mae: 15.7893 - val_loss: 3670.5867 - val_mae: 33.6852\n",
      "Epoch 554/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 701.2665 - mae: 15.4058 - val_loss: 3662.2683 - val_mae: 33.5729\n",
      "Epoch 555/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 673.3510 - mae: 15.4832 - val_loss: 3719.0703 - val_mae: 33.7215\n",
      "Epoch 556/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 609.1567 - mae: 15.1546 - val_loss: 3606.2122 - val_mae: 33.5841\n",
      "Epoch 557/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 658.8393 - mae: 15.1501 - val_loss: 3685.1321 - val_mae: 34.8416\n",
      "Epoch 558/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 724.9877 - mae: 16.0432 - val_loss: 3613.2349 - val_mae: 33.7680\n",
      "Epoch 559/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 679.1984 - mae: 15.1780 - val_loss: 3692.6597 - val_mae: 33.9778\n",
      "Epoch 560/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 702.8734 - mae: 15.5261 - val_loss: 3740.0410 - val_mae: 34.0359\n",
      "Epoch 561/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 708.2518 - mae: 15.5272 - val_loss: 3755.3618 - val_mae: 34.4002\n",
      "Epoch 562/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 710.2589 - mae: 15.7576 - val_loss: 3732.0310 - val_mae: 34.2696\n",
      "Epoch 563/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 643.5073 - mae: 15.1068 - val_loss: 3705.9233 - val_mae: 34.0704\n",
      "Epoch 564/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 677.6995 - mae: 15.4203 - val_loss: 3713.8408 - val_mae: 33.4225\n",
      "Epoch 565/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 724.5210 - mae: 15.5212 - val_loss: 3684.6321 - val_mae: 33.3833\n",
      "Epoch 566/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 715.5929 - mae: 15.8892 - val_loss: 3735.7444 - val_mae: 34.2178\n",
      "Epoch 567/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 715.1082 - mae: 15.4364 - val_loss: 3671.9595 - val_mae: 33.5347\n",
      "Epoch 568/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 736.4247 - mae: 15.7439 - val_loss: 3762.5847 - val_mae: 33.7906\n",
      "Epoch 569/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 696.1833 - mae: 15.2213 - val_loss: 3590.9446 - val_mae: 33.2813\n",
      "Epoch 570/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 704.6252 - mae: 15.5787 - val_loss: 3712.8867 - val_mae: 33.8552\n",
      "Epoch 571/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 700.3233 - mae: 15.2358 - val_loss: 3654.9819 - val_mae: 33.4715\n",
      "Epoch 572/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 824.0698 - mae: 15.8019 - val_loss: 3765.3586 - val_mae: 33.9975\n",
      "Epoch 573/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 686.7866 - mae: 15.5667 - val_loss: 3678.2747 - val_mae: 33.9648\n",
      "Epoch 574/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 629.8399 - mae: 14.8145 - val_loss: 3609.7732 - val_mae: 33.3157\n",
      "Epoch 575/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 680.6488 - mae: 15.2326 - val_loss: 3623.0046 - val_mae: 33.7220\n",
      "Epoch 576/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 689.6399 - mae: 15.3634 - val_loss: 3636.6260 - val_mae: 33.7506\n",
      "Epoch 577/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 687.2667 - mae: 15.3879 - val_loss: 3544.8381 - val_mae: 33.7303\n",
      "Epoch 578/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 696.3857 - mae: 15.3430 - val_loss: 3671.4158 - val_mae: 33.7250\n",
      "Epoch 579/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 693.8051 - mae: 15.5879 - val_loss: 3626.9165 - val_mae: 33.1524\n",
      "Epoch 580/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 664.7339 - mae: 15.3126 - val_loss: 3670.4734 - val_mae: 33.8656\n",
      "Epoch 581/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 657.0452 - mae: 15.0676 - val_loss: 3658.4844 - val_mae: 34.0400\n",
      "Epoch 582/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 695.8196 - mae: 15.4915 - val_loss: 3739.8950 - val_mae: 33.7862\n",
      "Epoch 583/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 649.0965 - mae: 14.4733 - val_loss: 3766.8108 - val_mae: 34.5205\n",
      "Epoch 584/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 668.8004 - mae: 15.2124 - val_loss: 3616.0986 - val_mae: 33.8868\n",
      "Epoch 585/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 714.2149 - mae: 15.3871 - val_loss: 3720.5442 - val_mae: 34.1889\n",
      "Epoch 586/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 640.7318 - mae: 14.8708 - val_loss: 3692.8320 - val_mae: 34.4853\n",
      "Epoch 587/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 673.3929 - mae: 15.2325 - val_loss: 3679.1633 - val_mae: 33.9718\n",
      "Epoch 588/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 639.9464 - mae: 14.9543 - val_loss: 3706.1882 - val_mae: 33.7450\n",
      "Epoch 589/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 711.3615 - mae: 15.4425 - val_loss: 3588.6733 - val_mae: 32.5988\n",
      "Epoch 590/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 670.6506 - mae: 15.2865 - val_loss: 3699.1692 - val_mae: 33.9598\n",
      "Epoch 591/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 649.7480 - mae: 15.0808 - val_loss: 3686.0669 - val_mae: 33.8684\n",
      "Epoch 592/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 639.0699 - mae: 14.7323 - val_loss: 3730.7207 - val_mae: 33.8922\n",
      "Epoch 593/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 674.5944 - mae: 15.1327 - val_loss: 3680.2146 - val_mae: 33.6437\n",
      "Epoch 594/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 629.2393 - mae: 15.0063 - val_loss: 3783.7158 - val_mae: 34.2626\n",
      "Epoch 595/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 682.9837 - mae: 15.2698 - val_loss: 3769.7778 - val_mae: 33.8030\n",
      "Epoch 596/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 697.7111 - mae: 15.4473 - val_loss: 3812.5403 - val_mae: 34.3158\n",
      "Epoch 597/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 631.6304 - mae: 15.0365 - val_loss: 3800.5671 - val_mae: 34.5058\n",
      "Epoch 598/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 707.9500 - mae: 15.3844 - val_loss: 3841.7966 - val_mae: 34.4957\n",
      "Epoch 599/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 637.0445 - mae: 14.8182 - val_loss: 3752.8340 - val_mae: 34.1074\n",
      "Epoch 600/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 601.3200 - mae: 14.5884 - val_loss: 3719.6357 - val_mae: 33.9502\n",
      "Epoch 601/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 629.5086 - mae: 14.7663 - val_loss: 3620.9431 - val_mae: 33.7854\n",
      "Epoch 602/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 602.3001 - mae: 14.8532 - val_loss: 3853.0378 - val_mae: 35.2318\n",
      "Epoch 603/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 700.4824 - mae: 15.5779 - val_loss: 3671.5493 - val_mae: 33.9851\n",
      "Epoch 604/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 630.6667 - mae: 14.7012 - val_loss: 3725.2256 - val_mae: 34.6888\n",
      "Epoch 605/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 719.9804 - mae: 15.3397 - val_loss: 3574.6624 - val_mae: 33.3914\n",
      "Epoch 606/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 658.8787 - mae: 15.1288 - val_loss: 3603.8508 - val_mae: 33.9221\n",
      "Epoch 607/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 718.7693 - mae: 15.2079 - val_loss: 3589.8320 - val_mae: 33.7066\n",
      "Epoch 608/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 663.2280 - mae: 15.1424 - val_loss: 3589.2712 - val_mae: 34.0572\n",
      "Epoch 609/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 711.1818 - mae: 15.2476 - val_loss: 3564.8137 - val_mae: 33.0363\n",
      "Epoch 610/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 699.2971 - mae: 15.1220 - val_loss: 3562.8804 - val_mae: 33.6334\n",
      "Epoch 611/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 711.7183 - mae: 15.3368 - val_loss: 3535.7864 - val_mae: 33.4945\n",
      "Epoch 612/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 787.6571 - mae: 15.2438 - val_loss: 3506.8767 - val_mae: 32.7034\n",
      "Epoch 613/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 763.0800 - mae: 15.8426 - val_loss: 3573.6545 - val_mae: 35.1813\n",
      "Epoch 614/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 684.1960 - mae: 16.7713 - val_loss: 3633.7539 - val_mae: 34.7781\n",
      "Epoch 615/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 749.1828 - mae: 17.0189 - val_loss: 3725.9761 - val_mae: 35.9675\n",
      "Epoch 616/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 753.1348 - mae: 17.0861 - val_loss: 3751.6873 - val_mae: 35.1544\n",
      "Epoch 617/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 640.3130 - mae: 16.0531 - val_loss: 3743.4453 - val_mae: 35.1413\n",
      "Epoch 618/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 719.6115 - mae: 16.0889 - val_loss: 3707.2715 - val_mae: 34.1877\n",
      "Epoch 619/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 682.2283 - mae: 15.7884 - val_loss: 3660.1079 - val_mae: 33.6143\n",
      "Epoch 620/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 580.8956 - mae: 14.7288 - val_loss: 3614.0833 - val_mae: 33.7232\n",
      "Epoch 621/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 611.7924 - mae: 14.5042 - val_loss: 3774.2991 - val_mae: 34.0987\n",
      "Epoch 622/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 627.9319 - mae: 14.6315 - val_loss: 3662.1538 - val_mae: 33.6171\n",
      "Epoch 623/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 685.1843 - mae: 15.1368 - val_loss: 3700.1414 - val_mae: 34.4831\n",
      "Epoch 624/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 675.4210 - mae: 15.1807 - val_loss: 3645.1316 - val_mae: 34.0948\n",
      "Epoch 625/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 612.7323 - mae: 14.5380 - val_loss: 3563.7649 - val_mae: 33.4649\n",
      "Epoch 626/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 737.3465 - mae: 15.4712 - val_loss: 3605.2185 - val_mae: 33.5355\n",
      "Epoch 627/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 628.8879 - mae: 14.8272 - val_loss: 3720.4214 - val_mae: 34.6541\n",
      "Epoch 628/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 675.4664 - mae: 14.9706 - val_loss: 3775.7100 - val_mae: 34.7466\n",
      "Epoch 629/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 673.2530 - mae: 15.4097 - val_loss: 3601.9951 - val_mae: 34.7551\n",
      "Epoch 630/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 643.5384 - mae: 14.7627 - val_loss: 3671.6978 - val_mae: 34.3566\n",
      "Epoch 631/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 655.9825 - mae: 14.7366 - val_loss: 3674.4763 - val_mae: 33.8404\n",
      "Epoch 632/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 613.2492 - mae: 14.5739 - val_loss: 3604.7815 - val_mae: 34.0784\n",
      "Epoch 633/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 653.4885 - mae: 14.7354 - val_loss: 3634.3811 - val_mae: 33.3246\n",
      "Epoch 634/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 600.8279 - mae: 14.3743 - val_loss: 3642.8606 - val_mae: 33.8514\n",
      "Epoch 635/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 687.3099 - mae: 14.8570 - val_loss: 3757.3369 - val_mae: 34.5994\n",
      "Epoch 636/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 669.9224 - mae: 15.0441 - val_loss: 3610.0017 - val_mae: 33.9933\n",
      "Epoch 637/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 619.8411 - mae: 14.5359 - val_loss: 3694.4604 - val_mae: 34.3334\n",
      "Epoch 638/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 600.4231 - mae: 14.4152 - val_loss: 3822.2085 - val_mae: 34.8772\n",
      "Epoch 639/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 649.9636 - mae: 14.5429 - val_loss: 3655.5864 - val_mae: 33.4044\n",
      "Epoch 640/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 651.8901 - mae: 14.6296 - val_loss: 3760.3811 - val_mae: 33.9256\n",
      "Epoch 641/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 685.2975 - mae: 15.0009 - val_loss: 3703.4902 - val_mae: 33.9283\n",
      "Epoch 642/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 610.6971 - mae: 14.4062 - val_loss: 3861.4939 - val_mae: 34.9954\n",
      "Epoch 643/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 609.8171 - mae: 14.3880 - val_loss: 3863.6284 - val_mae: 34.9508\n",
      "Epoch 644/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 669.5219 - mae: 14.7884 - val_loss: 3607.4038 - val_mae: 34.0605\n",
      "Epoch 645/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 756.0392 - mae: 15.3965 - val_loss: 3697.7478 - val_mae: 33.8336\n",
      "Epoch 646/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 612.3186 - mae: 14.2850 - val_loss: 3780.1147 - val_mae: 34.0949\n",
      "Epoch 647/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 652.2399 - mae: 14.3837 - val_loss: 3836.9832 - val_mae: 34.2950\n",
      "Epoch 648/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 615.2848 - mae: 14.3252 - val_loss: 3668.1533 - val_mae: 34.2663\n",
      "Epoch 649/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 623.5986 - mae: 14.3760 - val_loss: 3651.8691 - val_mae: 33.6564\n",
      "Epoch 650/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 671.4691 - mae: 14.6660 - val_loss: 3647.8250 - val_mae: 33.7979\n",
      "Epoch 651/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 575.7578 - mae: 14.2943 - val_loss: 3682.7407 - val_mae: 33.4195\n",
      "Epoch 652/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 690.5578 - mae: 14.7935 - val_loss: 3733.9619 - val_mae: 34.2174\n",
      "Epoch 653/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 667.2394 - mae: 14.9446 - val_loss: 3619.2559 - val_mae: 33.6079\n",
      "Epoch 654/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 580.9282 - mae: 14.2139 - val_loss: 3765.5032 - val_mae: 33.9240\n",
      "Epoch 655/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 592.2234 - mae: 14.2678 - val_loss: 3652.9746 - val_mae: 33.6248\n",
      "Epoch 656/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 644.6735 - mae: 14.3371 - val_loss: 3638.7141 - val_mae: 33.3645\n",
      "Epoch 657/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 630.0238 - mae: 14.3274 - val_loss: 3682.0132 - val_mae: 33.9712\n",
      "Epoch 658/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 619.4993 - mae: 14.3955 - val_loss: 3751.8406 - val_mae: 33.6421\n",
      "Epoch 659/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 615.7922 - mae: 14.5129 - val_loss: 3815.4373 - val_mae: 34.3412\n",
      "Epoch 660/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 770.1355 - mae: 15.2815 - val_loss: 3721.9612 - val_mae: 33.9269\n",
      "Epoch 661/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 686.1531 - mae: 15.0729 - val_loss: 3717.9309 - val_mae: 33.6850\n",
      "Epoch 662/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 594.0942 - mae: 14.5276 - val_loss: 3680.5500 - val_mae: 33.5826\n",
      "Epoch 663/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 619.3984 - mae: 14.5081 - val_loss: 3641.4695 - val_mae: 33.1803\n",
      "Epoch 664/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 684.4214 - mae: 14.8804 - val_loss: 3635.7078 - val_mae: 33.2924\n",
      "Epoch 665/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 632.8672 - mae: 14.8185 - val_loss: 3737.5129 - val_mae: 33.6697\n",
      "Epoch 666/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 668.3173 - mae: 14.9407 - val_loss: 3647.2573 - val_mae: 33.3626\n",
      "Epoch 667/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 620.9108 - mae: 14.4838 - val_loss: 3752.3640 - val_mae: 33.7765\n",
      "Epoch 668/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 597.8738 - mae: 14.2754 - val_loss: 3646.7703 - val_mae: 33.4275\n",
      "Epoch 669/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 617.0077 - mae: 14.6771 - val_loss: 3753.9590 - val_mae: 34.4948\n",
      "Epoch 670/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 599.4913 - mae: 14.3737 - val_loss: 3722.0747 - val_mae: 33.6767\n",
      "Epoch 671/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 682.0450 - mae: 14.7390 - val_loss: 3653.8669 - val_mae: 33.7467\n",
      "Epoch 672/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 683.6747 - mae: 14.9178 - val_loss: 3646.1492 - val_mae: 33.3237\n",
      "Epoch 673/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 603.2608 - mae: 14.2351 - val_loss: 3752.1914 - val_mae: 34.6051\n",
      "Epoch 674/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 742.7260 - mae: 15.0065 - val_loss: 3678.5835 - val_mae: 33.8776\n",
      "Epoch 675/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 628.4954 - mae: 15.2913 - val_loss: 3646.1116 - val_mae: 33.7684\n",
      "Epoch 676/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 631.7917 - mae: 14.5101 - val_loss: 3698.2690 - val_mae: 34.2606\n",
      "Epoch 677/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 616.9108 - mae: 14.3328 - val_loss: 3686.4802 - val_mae: 33.6948\n",
      "Epoch 678/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 569.5845 - mae: 13.8624 - val_loss: 3589.4893 - val_mae: 33.1572\n",
      "Epoch 679/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 640.0693 - mae: 14.6117 - val_loss: 3590.0647 - val_mae: 33.5278\n",
      "Epoch 680/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 588.9646 - mae: 14.0109 - val_loss: 3694.2058 - val_mae: 33.5719\n",
      "Epoch 681/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 626.3392 - mae: 14.4162 - val_loss: 3732.8608 - val_mae: 34.0285\n",
      "Epoch 682/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 595.1010 - mae: 14.2183 - val_loss: 3754.4802 - val_mae: 34.1105\n",
      "Epoch 683/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 645.5437 - mae: 14.5510 - val_loss: 3656.1328 - val_mae: 34.4845\n",
      "Epoch 684/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 569.5654 - mae: 14.0421 - val_loss: 3593.2749 - val_mae: 33.5075\n",
      "Epoch 685/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 612.0005 - mae: 14.4800 - val_loss: 3622.3862 - val_mae: 33.8947\n",
      "Epoch 686/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 565.4641 - mae: 13.8282 - val_loss: 3672.8491 - val_mae: 33.8839\n",
      "Epoch 687/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 630.3581 - mae: 14.3068 - val_loss: 3779.9731 - val_mae: 34.8474\n",
      "Epoch 688/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 582.6865 - mae: 14.0804 - val_loss: 3611.3816 - val_mae: 33.6298\n",
      "Epoch 689/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 690.4479 - mae: 14.6625 - val_loss: 3661.9714 - val_mae: 33.7851\n",
      "Epoch 690/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 669.6259 - mae: 14.5934 - val_loss: 3471.8318 - val_mae: 33.0893\n",
      "Epoch 691/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 667.6749 - mae: 14.6687 - val_loss: 3603.8059 - val_mae: 33.5069\n",
      "Epoch 692/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 582.6781 - mae: 14.1961 - val_loss: 3667.2256 - val_mae: 34.2030\n",
      "Epoch 693/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 588.6100 - mae: 14.6062 - val_loss: 3608.4456 - val_mae: 34.8628\n",
      "Epoch 694/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 566.7184 - mae: 14.2393 - val_loss: 3655.4465 - val_mae: 33.6623\n",
      "Epoch 695/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 549.8345 - mae: 13.8939 - val_loss: 3603.1621 - val_mae: 32.9717\n",
      "Epoch 696/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 608.5227 - mae: 14.0965 - val_loss: 3602.2549 - val_mae: 33.5497\n",
      "Epoch 697/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 572.9423 - mae: 13.9014 - val_loss: 3644.1785 - val_mae: 33.4739\n",
      "Epoch 698/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 579.9534 - mae: 14.1501 - val_loss: 3589.0659 - val_mae: 33.4987\n",
      "Epoch 699/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 610.1353 - mae: 14.2980 - val_loss: 3550.9666 - val_mae: 32.9629\n",
      "Epoch 700/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 613.2504 - mae: 14.2147 - val_loss: 3706.2400 - val_mae: 33.5533\n",
      "Epoch 701/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 632.9691 - mae: 14.1663 - val_loss: 3639.9500 - val_mae: 33.6858\n",
      "Epoch 702/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 621.1127 - mae: 14.1819 - val_loss: 3602.9043 - val_mae: 33.7181\n",
      "Epoch 703/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 567.9783 - mae: 13.8933 - val_loss: 3799.5120 - val_mae: 34.4236\n",
      "Epoch 704/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 637.4730 - mae: 14.1893 - val_loss: 3759.3271 - val_mae: 33.9034\n",
      "Epoch 705/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 605.6349 - mae: 14.0458 - val_loss: 3553.5498 - val_mae: 33.4355\n",
      "Epoch 706/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 617.7715 - mae: 14.2636 - val_loss: 3625.7244 - val_mae: 33.0115\n",
      "Epoch 707/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 595.5236 - mae: 14.1561 - val_loss: 3683.4929 - val_mae: 33.7104\n",
      "Epoch 708/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 654.0599 - mae: 14.8127 - val_loss: 3652.0278 - val_mae: 33.7778\n",
      "Epoch 709/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 578.7852 - mae: 14.1212 - val_loss: 3858.2812 - val_mae: 34.1218\n",
      "Epoch 710/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 671.8347 - mae: 14.6949 - val_loss: 3880.6494 - val_mae: 34.7825\n",
      "Epoch 711/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 574.6537 - mae: 13.8826 - val_loss: 3694.9797 - val_mae: 33.4508\n",
      "Epoch 712/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 599.1902 - mae: 14.0918 - val_loss: 3579.4163 - val_mae: 32.9714\n",
      "Epoch 713/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 578.0718 - mae: 14.6182 - val_loss: 3679.2434 - val_mae: 35.2488\n",
      "Epoch 714/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 606.8101 - mae: 15.7283 - val_loss: 3702.4734 - val_mae: 34.6134\n",
      "Epoch 715/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 623.2227 - mae: 15.3286 - val_loss: 3587.8511 - val_mae: 34.1061\n",
      "Epoch 716/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 594.6870 - mae: 14.5828 - val_loss: 3643.4468 - val_mae: 34.5844\n",
      "Epoch 717/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 593.9503 - mae: 14.6468 - val_loss: 3661.0137 - val_mae: 34.2638\n",
      "Epoch 718/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 666.6068 - mae: 14.7603 - val_loss: 3500.5935 - val_mae: 33.1377\n",
      "Epoch 719/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 586.7950 - mae: 14.1155 - val_loss: 3553.2664 - val_mae: 33.3441\n",
      "Epoch 720/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 601.7572 - mae: 13.8479 - val_loss: 3491.5930 - val_mae: 33.3563\n",
      "Epoch 721/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 618.3696 - mae: 14.3202 - val_loss: 3638.0703 - val_mae: 33.6451\n",
      "Epoch 722/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 567.0911 - mae: 13.8282 - val_loss: 3603.1218 - val_mae: 33.3487\n",
      "Epoch 723/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 590.1270 - mae: 13.8816 - val_loss: 3627.6624 - val_mae: 33.1906\n",
      "Epoch 724/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 622.4760 - mae: 14.1256 - val_loss: 3574.7197 - val_mae: 33.4327\n",
      "Epoch 725/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 570.2429 - mae: 13.7838 - val_loss: 3520.6558 - val_mae: 33.1844\n",
      "Epoch 726/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 620.1296 - mae: 13.9007 - val_loss: 3646.6580 - val_mae: 33.6797\n",
      "Epoch 727/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 626.1324 - mae: 14.0569 - val_loss: 3631.4797 - val_mae: 33.5600\n",
      "Epoch 728/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 590.7562 - mae: 13.8907 - val_loss: 3579.2581 - val_mae: 33.1534\n",
      "Epoch 729/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 584.3412 - mae: 13.8560 - val_loss: 3563.4902 - val_mae: 32.9207\n",
      "Epoch 730/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 610.2450 - mae: 14.4137 - val_loss: 3705.1055 - val_mae: 33.1754\n",
      "Epoch 731/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 594.5381 - mae: 13.9992 - val_loss: 3672.7302 - val_mae: 33.4378\n",
      "Epoch 732/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 647.0161 - mae: 14.2094 - val_loss: 3574.9902 - val_mae: 33.4551\n",
      "Epoch 733/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 609.0186 - mae: 14.1255 - val_loss: 3597.7971 - val_mae: 33.4621\n",
      "Epoch 734/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 576.7748 - mae: 13.8667 - val_loss: 3687.6062 - val_mae: 34.9268\n",
      "Epoch 735/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 514.3905 - mae: 13.3053 - val_loss: 3784.1885 - val_mae: 34.4155\n",
      "Epoch 736/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 625.6385 - mae: 14.1424 - val_loss: 3630.1821 - val_mae: 34.0004\n",
      "Epoch 737/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 549.5038 - mae: 13.4784 - val_loss: 3539.6658 - val_mae: 33.6337\n",
      "Epoch 738/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 578.9864 - mae: 13.8093 - val_loss: 3437.8054 - val_mae: 32.8896\n",
      "Epoch 739/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 605.6895 - mae: 14.4709 - val_loss: 3576.8252 - val_mae: 33.9717\n",
      "Epoch 740/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 561.8668 - mae: 13.9506 - val_loss: 3525.9185 - val_mae: 32.9594\n",
      "Epoch 741/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 631.8943 - mae: 14.3398 - val_loss: 3521.7507 - val_mae: 33.3593\n",
      "Epoch 742/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 566.2279 - mae: 13.8621 - val_loss: 3570.1323 - val_mae: 33.2814\n",
      "Epoch 743/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 527.0920 - mae: 13.4125 - val_loss: 3474.8599 - val_mae: 33.3169\n",
      "Epoch 744/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 555.5188 - mae: 13.7655 - val_loss: 3457.9421 - val_mae: 32.8224\n",
      "Epoch 745/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 625.4078 - mae: 14.0983 - val_loss: 3576.0955 - val_mae: 33.3399\n",
      "Epoch 746/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 557.1498 - mae: 13.7041 - val_loss: 3552.8511 - val_mae: 33.4145\n",
      "Epoch 747/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 570.5389 - mae: 13.5526 - val_loss: 3548.0818 - val_mae: 32.7105\n",
      "Epoch 748/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 514.2446 - mae: 13.3767 - val_loss: 3579.5322 - val_mae: 32.7485\n",
      "Epoch 749/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 567.5802 - mae: 13.8668 - val_loss: 3530.1216 - val_mae: 32.8067\n",
      "Epoch 750/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 565.5229 - mae: 13.5815 - val_loss: 3689.3293 - val_mae: 33.7694\n",
      "Epoch 751/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 596.2890 - mae: 14.0081 - val_loss: 3763.4292 - val_mae: 34.1306\n",
      "Epoch 752/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 596.0983 - mae: 14.1542 - val_loss: 3595.7871 - val_mae: 34.6499\n",
      "Epoch 753/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 671.3249 - mae: 15.1216 - val_loss: 3541.9102 - val_mae: 33.7298\n",
      "Epoch 754/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 551.4806 - mae: 13.7045 - val_loss: 3552.8428 - val_mae: 33.1365\n",
      "Epoch 755/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 587.5132 - mae: 13.9759 - val_loss: 3770.2180 - val_mae: 34.5000\n",
      "Epoch 756/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 578.8824 - mae: 14.0279 - val_loss: 3650.6223 - val_mae: 34.0404\n",
      "Epoch 757/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 589.5679 - mae: 13.8635 - val_loss: 3705.0801 - val_mae: 34.2341\n",
      "Epoch 758/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 585.2542 - mae: 13.9881 - val_loss: 3662.8491 - val_mae: 34.0667\n",
      "Epoch 759/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 591.3014 - mae: 13.9002 - val_loss: 3676.8752 - val_mae: 34.2012\n",
      "Epoch 760/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 537.4290 - mae: 13.5785 - val_loss: 3657.6113 - val_mae: 33.8280\n",
      "Epoch 761/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 546.8104 - mae: 13.4098 - val_loss: 3651.1348 - val_mae: 33.3283\n",
      "Epoch 762/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 562.3622 - mae: 13.7441 - val_loss: 3584.9124 - val_mae: 34.0130\n",
      "Epoch 763/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 555.4268 - mae: 13.8431 - val_loss: 3527.3472 - val_mae: 33.2971\n",
      "Epoch 764/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 573.9194 - mae: 13.9466 - val_loss: 3624.6328 - val_mae: 33.5653\n",
      "Epoch 765/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 584.1970 - mae: 13.8429 - val_loss: 3670.9878 - val_mae: 33.9728\n",
      "Epoch 766/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 623.4669 - mae: 14.1533 - val_loss: 3787.9458 - val_mae: 34.9170\n",
      "Epoch 767/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 580.2086 - mae: 13.9295 - val_loss: 3716.2007 - val_mae: 34.7579\n",
      "Epoch 768/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 613.0026 - mae: 14.6166 - val_loss: 3702.8047 - val_mae: 34.1803\n",
      "Epoch 769/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 565.6506 - mae: 13.8786 - val_loss: 3744.0657 - val_mae: 33.9500\n",
      "Epoch 770/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 567.3416 - mae: 13.6802 - val_loss: 3726.0378 - val_mae: 34.1174\n",
      "Epoch 771/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 535.3950 - mae: 13.4164 - val_loss: 3746.5996 - val_mae: 34.5062\n",
      "Epoch 772/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 562.3916 - mae: 13.4223 - val_loss: 3597.9619 - val_mae: 33.2665\n",
      "Epoch 773/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 541.4694 - mae: 13.4711 - val_loss: 3589.4287 - val_mae: 33.7521\n",
      "Epoch 774/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 559.9552 - mae: 13.5565 - val_loss: 3714.3833 - val_mae: 34.5731\n",
      "Epoch 775/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 488.7018 - mae: 13.0227 - val_loss: 3538.1619 - val_mae: 33.7317\n",
      "Epoch 776/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.3023 - mae: 13.2482 - val_loss: 3697.0457 - val_mae: 34.3583\n",
      "Epoch 777/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 527.2056 - mae: 13.4378 - val_loss: 3507.5378 - val_mae: 33.2558\n",
      "Epoch 778/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 516.7294 - mae: 13.3520 - val_loss: 3646.7993 - val_mae: 33.1451\n",
      "Epoch 779/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 535.4686 - mae: 13.8924 - val_loss: 3654.5303 - val_mae: 34.2773\n",
      "Epoch 780/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 493.5089 - mae: 13.5206 - val_loss: 3608.5264 - val_mae: 34.0292\n",
      "Epoch 781/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 567.6698 - mae: 13.5703 - val_loss: 3566.4143 - val_mae: 33.1170\n",
      "Epoch 782/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 580.5266 - mae: 13.7881 - val_loss: 3578.6677 - val_mae: 33.8589\n",
      "Epoch 783/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 553.6323 - mae: 13.8249 - val_loss: 3688.1782 - val_mae: 34.0060\n",
      "Epoch 784/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 543.6633 - mae: 13.6810 - val_loss: 3647.7546 - val_mae: 33.5620\n",
      "Epoch 785/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 548.9622 - mae: 13.4891 - val_loss: 3545.2734 - val_mae: 33.1992\n",
      "Epoch 786/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 607.3875 - mae: 14.0422 - val_loss: 3636.2915 - val_mae: 34.3018\n",
      "Epoch 787/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 487.4570 - mae: 13.0094 - val_loss: 3718.5222 - val_mae: 34.1582\n",
      "Epoch 788/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 541.7206 - mae: 13.4334 - val_loss: 3648.0979 - val_mae: 33.9557\n",
      "Epoch 789/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 533.3874 - mae: 13.3150 - val_loss: 3581.7288 - val_mae: 33.9961\n",
      "Epoch 790/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 563.1713 - mae: 13.6013 - val_loss: 3677.7200 - val_mae: 34.0171\n",
      "Epoch 791/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 492.1636 - mae: 13.1753 - val_loss: 3718.0544 - val_mae: 34.8059\n",
      "Epoch 792/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 533.4028 - mae: 13.4973 - val_loss: 3633.4790 - val_mae: 33.6551\n",
      "Epoch 793/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 535.4080 - mae: 13.3981 - val_loss: 3665.4290 - val_mae: 34.0660\n",
      "Epoch 794/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 561.9118 - mae: 14.9400 - val_loss: 3682.4663 - val_mae: 34.7763\n",
      "Epoch 795/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 542.8009 - mae: 13.7070 - val_loss: 3614.3809 - val_mae: 33.5751\n",
      "Epoch 796/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 601.3779 - mae: 13.9598 - val_loss: 3630.4482 - val_mae: 33.9250\n",
      "Epoch 797/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 526.2237 - mae: 13.6916 - val_loss: 3610.8411 - val_mae: 33.9309\n",
      "Epoch 798/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 536.0737 - mae: 13.5093 - val_loss: 3596.6252 - val_mae: 33.7481\n",
      "Epoch 799/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 558.7449 - mae: 13.7847 - val_loss: 3646.2180 - val_mae: 33.6503\n",
      "Epoch 800/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 508.4831 - mae: 13.1370 - val_loss: 3536.5830 - val_mae: 33.2591\n",
      "Epoch 801/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.6967 - mae: 13.2261 - val_loss: 3573.9258 - val_mae: 33.3883\n",
      "Epoch 802/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 475.0621 - mae: 13.0715 - val_loss: 3584.9395 - val_mae: 33.3980\n",
      "Epoch 803/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 571.2929 - mae: 13.3889 - val_loss: 3732.2664 - val_mae: 34.1823\n",
      "Epoch 804/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 543.3973 - mae: 13.5684 - val_loss: 3654.0640 - val_mae: 33.6575\n",
      "Epoch 805/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 554.9401 - mae: 13.4946 - val_loss: 3733.8689 - val_mae: 34.0294\n",
      "Epoch 806/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 584.8239 - mae: 13.6044 - val_loss: 3587.3403 - val_mae: 33.6909\n",
      "Epoch 807/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 557.8280 - mae: 13.7466 - val_loss: 3691.2966 - val_mae: 33.8309\n",
      "Epoch 808/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 604.4587 - mae: 13.8703 - val_loss: 3559.4927 - val_mae: 32.9213\n",
      "Epoch 809/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 539.7222 - mae: 13.3834 - val_loss: 3633.9504 - val_mae: 33.2042\n",
      "Epoch 810/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 540.2867 - mae: 13.3910 - val_loss: 3561.5034 - val_mae: 34.0220\n",
      "Epoch 811/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 562.0491 - mae: 13.3983 - val_loss: 3635.0112 - val_mae: 34.0817\n",
      "Epoch 812/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 557.4434 - mae: 13.4370 - val_loss: 3703.9392 - val_mae: 33.9759\n",
      "Epoch 813/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 523.9567 - mae: 13.6162 - val_loss: 3581.7317 - val_mae: 33.6041\n",
      "Epoch 814/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 505.4817 - mae: 13.4246 - val_loss: 3863.0432 - val_mae: 35.5171\n",
      "Epoch 815/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 546.0655 - mae: 13.5723 - val_loss: 3623.0020 - val_mae: 33.7030\n",
      "Epoch 816/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 550.5636 - mae: 13.5185 - val_loss: 3589.1433 - val_mae: 33.8671\n",
      "Epoch 817/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 524.4059 - mae: 13.2385 - val_loss: 3673.1196 - val_mae: 33.5433\n",
      "Epoch 818/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 519.6163 - mae: 13.0292 - val_loss: 3578.5068 - val_mae: 33.7129\n",
      "Epoch 819/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 550.8035 - mae: 13.2883 - val_loss: 3608.4841 - val_mae: 33.7560\n",
      "Epoch 820/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 544.7381 - mae: 13.3733 - val_loss: 3667.3687 - val_mae: 34.2010\n",
      "Epoch 821/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 590.0220 - mae: 13.9639 - val_loss: 3663.0137 - val_mae: 33.3420\n",
      "Epoch 822/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 513.3772 - mae: 13.3311 - val_loss: 3597.6973 - val_mae: 33.7738\n",
      "Epoch 823/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 572.7293 - mae: 13.8286 - val_loss: 3640.6797 - val_mae: 34.0129\n",
      "Epoch 824/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 458.4008 - mae: 12.8835 - val_loss: 3603.0129 - val_mae: 33.5893\n",
      "Epoch 825/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 498.0901 - mae: 13.0315 - val_loss: 3657.5869 - val_mae: 33.9526\n",
      "Epoch 826/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 601.5023 - mae: 13.9216 - val_loss: 3735.8687 - val_mae: 34.4734\n",
      "Epoch 827/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 531.5320 - mae: 13.3846 - val_loss: 3776.1838 - val_mae: 34.5989\n",
      "Epoch 828/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 513.9162 - mae: 13.3294 - val_loss: 3581.0242 - val_mae: 33.5672\n",
      "Epoch 829/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.3009 - mae: 13.1295 - val_loss: 3583.3113 - val_mae: 33.5653\n",
      "Epoch 830/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 496.0842 - mae: 13.0575 - val_loss: 3685.4578 - val_mae: 33.8372\n",
      "Epoch 831/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 553.3137 - mae: 13.4908 - val_loss: 3708.7378 - val_mae: 34.4288\n",
      "Epoch 832/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 546.6008 - mae: 13.8521 - val_loss: 3593.2913 - val_mae: 33.6722\n",
      "Epoch 833/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 539.8802 - mae: 13.5103 - val_loss: 3674.9207 - val_mae: 33.4556\n",
      "Epoch 834/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 526.3047 - mae: 13.4418 - val_loss: 3586.3445 - val_mae: 33.4397\n",
      "Epoch 835/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 522.0264 - mae: 13.1203 - val_loss: 3676.3457 - val_mae: 34.2749\n",
      "Epoch 836/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 481.5911 - mae: 12.9433 - val_loss: 3667.0063 - val_mae: 33.9953\n",
      "Epoch 837/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 556.5536 - mae: 13.5528 - val_loss: 3756.2871 - val_mae: 33.7889\n",
      "Epoch 838/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 511.9793 - mae: 13.3017 - val_loss: 3752.7566 - val_mae: 34.2396\n",
      "Epoch 839/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 518.3939 - mae: 13.3887 - val_loss: 3711.5955 - val_mae: 33.9834\n",
      "Epoch 840/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 483.2017 - mae: 13.2085 - val_loss: 3586.6931 - val_mae: 33.2480\n",
      "Epoch 841/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.3921 - mae: 13.1295 - val_loss: 3695.6221 - val_mae: 33.8761\n",
      "Epoch 842/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 523.1953 - mae: 13.4298 - val_loss: 3891.6912 - val_mae: 34.8463\n",
      "Epoch 843/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 517.1815 - mae: 13.4715 - val_loss: 3754.6311 - val_mae: 34.1648\n",
      "Epoch 844/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 489.6875 - mae: 12.7715 - val_loss: 3722.2839 - val_mae: 34.3347\n",
      "Epoch 845/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 474.3776 - mae: 13.0099 - val_loss: 3616.8801 - val_mae: 33.7621\n",
      "Epoch 846/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 500.4883 - mae: 13.1011 - val_loss: 3692.2979 - val_mae: 34.0289\n",
      "Epoch 847/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 533.5764 - mae: 13.6113 - val_loss: 3616.2307 - val_mae: 33.5806\n",
      "Epoch 848/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 540.7937 - mae: 13.2592 - val_loss: 3673.4727 - val_mae: 34.4315\n",
      "Epoch 849/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 522.0915 - mae: 13.1960 - val_loss: 3623.4893 - val_mae: 33.7932\n",
      "Epoch 850/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 518.4938 - mae: 13.0953 - val_loss: 3600.8296 - val_mae: 33.9369\n",
      "Epoch 851/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 519.7648 - mae: 12.8676 - val_loss: 3700.9661 - val_mae: 34.3895\n",
      "Epoch 852/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 497.1748 - mae: 12.9822 - val_loss: 3682.4548 - val_mae: 34.1386\n",
      "Epoch 853/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 487.4706 - mae: 12.7078 - val_loss: 3726.1709 - val_mae: 34.6123\n",
      "Epoch 854/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 585.7266 - mae: 13.3273 - val_loss: 3769.9463 - val_mae: 35.4283\n",
      "Epoch 855/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 569.4435 - mae: 13.8502 - val_loss: 3772.1985 - val_mae: 34.5051\n",
      "Epoch 856/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 497.9398 - mae: 13.1412 - val_loss: 3720.0950 - val_mae: 34.4373\n",
      "Epoch 857/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 542.4568 - mae: 13.4949 - val_loss: 3728.8047 - val_mae: 34.1015\n",
      "Epoch 858/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 524.2542 - mae: 13.2236 - val_loss: 3708.9951 - val_mae: 34.3379\n",
      "Epoch 859/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 497.4412 - mae: 13.0007 - val_loss: 3674.2551 - val_mae: 34.0875\n",
      "Epoch 860/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 526.7131 - mae: 13.4506 - val_loss: 3613.3306 - val_mae: 33.2405\n",
      "Epoch 861/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 493.3219 - mae: 13.0030 - val_loss: 3745.9548 - val_mae: 33.8313\n",
      "Epoch 862/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 517.9299 - mae: 12.9968 - val_loss: 3586.3679 - val_mae: 33.9633\n",
      "Epoch 863/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 499.2936 - mae: 12.8914 - val_loss: 3521.5095 - val_mae: 33.2078\n",
      "Epoch 864/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 488.9680 - mae: 12.7738 - val_loss: 3676.1882 - val_mae: 33.8655\n",
      "Epoch 865/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 600.4034 - mae: 13.6145 - val_loss: 3735.2422 - val_mae: 34.2543\n",
      "Epoch 866/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 516.7946 - mae: 12.9140 - val_loss: 3742.4419 - val_mae: 34.0388\n",
      "Epoch 867/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 571.1478 - mae: 13.5855 - val_loss: 3561.2812 - val_mae: 33.2676\n",
      "Epoch 868/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 502.9153 - mae: 12.9368 - val_loss: 3603.6262 - val_mae: 33.2037\n",
      "Epoch 869/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 492.5663 - mae: 13.0565 - val_loss: 3653.7478 - val_mae: 33.6255\n",
      "Epoch 870/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 535.3851 - mae: 13.3520 - val_loss: 3736.6389 - val_mae: 34.4477\n",
      "Epoch 871/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 517.0449 - mae: 13.2895 - val_loss: 3630.1997 - val_mae: 33.6293\n",
      "Epoch 872/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 533.5073 - mae: 13.4981 - val_loss: 3670.3669 - val_mae: 34.0838\n",
      "Epoch 873/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 546.5983 - mae: 13.7105 - val_loss: 3687.6912 - val_mae: 34.3646\n",
      "Epoch 874/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 518.2706 - mae: 13.4087 - val_loss: 3715.4778 - val_mae: 33.9507\n",
      "Epoch 875/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 540.7181 - mae: 14.1873 - val_loss: 3670.0320 - val_mae: 33.5345\n",
      "Epoch 876/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 502.6734 - mae: 13.3498 - val_loss: 3699.6736 - val_mae: 34.0924\n",
      "Epoch 877/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 575.6677 - mae: 13.9283 - val_loss: 3817.4451 - val_mae: 34.3782\n",
      "Epoch 878/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 502.2231 - mae: 13.3149 - val_loss: 3664.1719 - val_mae: 33.3427\n",
      "Epoch 879/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 515.5006 - mae: 13.0924 - val_loss: 3666.3945 - val_mae: 33.5214\n",
      "Epoch 880/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 462.1256 - mae: 12.9900 - val_loss: 3536.3511 - val_mae: 33.4351\n",
      "Epoch 881/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 512.2712 - mae: 13.3850 - val_loss: 3656.9966 - val_mae: 34.3546\n",
      "Epoch 882/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 539.2829 - mae: 13.2744 - val_loss: 3723.4858 - val_mae: 34.2684\n",
      "Epoch 883/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 467.3686 - mae: 12.7605 - val_loss: 3616.0088 - val_mae: 33.3498\n",
      "Epoch 884/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 470.7529 - mae: 12.9055 - val_loss: 3665.4133 - val_mae: 33.5851\n",
      "Epoch 885/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 467.7910 - mae: 12.7549 - val_loss: 3645.9028 - val_mae: 33.6650\n",
      "Epoch 886/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 556.8216 - mae: 13.4044 - val_loss: 3750.5754 - val_mae: 33.8920\n",
      "Epoch 887/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 569.0445 - mae: 13.1910 - val_loss: 3719.0935 - val_mae: 34.4759\n",
      "Epoch 888/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 544.0158 - mae: 13.4173 - val_loss: 3610.3230 - val_mae: 34.0743\n",
      "Epoch 889/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 470.9270 - mae: 12.7244 - val_loss: 3566.4773 - val_mae: 33.1698\n",
      "Epoch 890/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 457.7368 - mae: 12.5077 - val_loss: 3619.9348 - val_mae: 33.3987\n",
      "Epoch 891/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 486.8232 - mae: 12.9104 - val_loss: 3731.6484 - val_mae: 34.2857\n",
      "Epoch 892/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 504.4343 - mae: 12.9942 - val_loss: 3718.2659 - val_mae: 33.6904\n",
      "Epoch 893/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 516.7086 - mae: 13.0772 - val_loss: 3787.3921 - val_mae: 34.2967\n",
      "Epoch 894/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 514.2138 - mae: 13.3632 - val_loss: 3764.4111 - val_mae: 35.2062\n",
      "Epoch 895/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 513.2889 - mae: 13.4216 - val_loss: 3664.1130 - val_mae: 34.7474\n",
      "Epoch 896/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 431.7619 - mae: 12.5296 - val_loss: 3767.3215 - val_mae: 34.3113\n",
      "Epoch 897/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 618.9188 - mae: 13.8695 - val_loss: 3610.0129 - val_mae: 33.8484\n",
      "Epoch 898/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 545.1525 - mae: 14.4813 - val_loss: 3690.8003 - val_mae: 34.9442\n",
      "Epoch 899/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 556.9974 - mae: 13.8803 - val_loss: 3598.7183 - val_mae: 33.6129\n",
      "Epoch 900/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 564.9333 - mae: 13.6170 - val_loss: 3743.1948 - val_mae: 34.6945\n",
      "Epoch 901/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 471.7079 - mae: 12.8911 - val_loss: 3727.8984 - val_mae: 33.7181\n",
      "Epoch 902/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 450.7761 - mae: 12.5115 - val_loss: 3646.7188 - val_mae: 33.5590\n",
      "Epoch 903/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 497.2474 - mae: 12.9062 - val_loss: 3653.2063 - val_mae: 33.7502\n",
      "Epoch 904/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 527.8904 - mae: 13.0797 - val_loss: 3642.2017 - val_mae: 33.6724\n",
      "Epoch 905/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 484.7621 - mae: 12.9166 - val_loss: 3651.6887 - val_mae: 33.5554\n",
      "Epoch 906/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 519.8074 - mae: 13.1997 - val_loss: 3659.7000 - val_mae: 33.5745\n",
      "Epoch 907/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 494.7332 - mae: 13.1942 - val_loss: 3670.8594 - val_mae: 33.4756\n",
      "Epoch 908/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 501.3172 - mae: 12.7855 - val_loss: 3713.2463 - val_mae: 33.3642\n",
      "Epoch 909/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 519.6117 - mae: 13.0535 - val_loss: 3730.8831 - val_mae: 34.2938\n",
      "Epoch 910/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 607.7377 - mae: 13.6969 - val_loss: 3784.4351 - val_mae: 34.2957\n",
      "Epoch 911/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 514.3458 - mae: 12.9818 - val_loss: 3685.8662 - val_mae: 33.7120\n",
      "Epoch 912/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 527.4495 - mae: 13.0962 - val_loss: 3629.5869 - val_mae: 33.6601\n",
      "Epoch 913/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 467.5212 - mae: 12.6885 - val_loss: 3763.0771 - val_mae: 34.1355\n",
      "Epoch 914/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 485.1614 - mae: 13.3564 - val_loss: 3677.5442 - val_mae: 34.5264\n",
      "Epoch 915/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 484.4253 - mae: 12.9020 - val_loss: 3706.5061 - val_mae: 34.0446\n",
      "Epoch 916/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 485.6693 - mae: 12.8362 - val_loss: 3702.5066 - val_mae: 34.4341\n",
      "Epoch 917/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 496.7591 - mae: 12.8072 - val_loss: 3791.8389 - val_mae: 33.7617\n",
      "Epoch 918/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 539.5137 - mae: 13.2807 - val_loss: 3716.0198 - val_mae: 34.1010\n",
      "Epoch 919/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 585.8948 - mae: 13.5103 - val_loss: 3682.2896 - val_mae: 33.3299\n",
      "Epoch 920/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 470.4592 - mae: 12.5478 - val_loss: 3694.2588 - val_mae: 33.3223\n",
      "Epoch 921/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 519.8613 - mae: 13.0699 - val_loss: 3668.3342 - val_mae: 33.2494\n",
      "Epoch 922/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 494.9615 - mae: 12.7461 - val_loss: 3654.0530 - val_mae: 33.8988\n",
      "Epoch 923/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 520.3965 - mae: 13.0875 - val_loss: 3750.1157 - val_mae: 35.1190\n",
      "Epoch 924/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 513.9952 - mae: 12.8932 - val_loss: 3807.0393 - val_mae: 34.5164\n",
      "Epoch 925/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 500.9384 - mae: 12.7137 - val_loss: 3696.2800 - val_mae: 34.1109\n",
      "Epoch 926/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 481.1665 - mae: 12.6683 - val_loss: 3580.0793 - val_mae: 33.4257\n",
      "Epoch 927/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 547.0607 - mae: 12.8838 - val_loss: 3731.5886 - val_mae: 34.6462\n",
      "Epoch 928/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 527.1437 - mae: 13.1140 - val_loss: 3702.6145 - val_mae: 34.6277\n",
      "Epoch 929/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.4120 - mae: 12.8091 - val_loss: 3756.7258 - val_mae: 34.2893\n",
      "Epoch 930/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 447.1545 - mae: 12.3461 - val_loss: 3730.3240 - val_mae: 34.5701\n",
      "Epoch 931/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 531.7151 - mae: 13.4793 - val_loss: 3776.6714 - val_mae: 34.9320\n",
      "Epoch 932/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 494.7218 - mae: 12.7669 - val_loss: 3613.2458 - val_mae: 33.5207\n",
      "Epoch 933/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 490.2417 - mae: 12.8369 - val_loss: 3599.5469 - val_mae: 33.4155\n",
      "Epoch 934/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 503.1270 - mae: 12.9328 - val_loss: 3598.0034 - val_mae: 34.0585\n",
      "Epoch 935/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 526.5248 - mae: 13.2793 - val_loss: 3693.4663 - val_mae: 34.0864\n",
      "Epoch 936/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 495.5692 - mae: 12.9286 - val_loss: 3607.1040 - val_mae: 33.8379\n",
      "Epoch 937/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 474.2260 - mae: 12.3846 - val_loss: 3413.9351 - val_mae: 32.7283\n",
      "Epoch 938/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 494.1096 - mae: 12.8531 - val_loss: 3604.5291 - val_mae: 33.8170\n",
      "Epoch 939/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 507.5127 - mae: 12.7070 - val_loss: 3663.8396 - val_mae: 34.9751\n",
      "Epoch 940/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 494.1276 - mae: 12.9392 - val_loss: 3625.3850 - val_mae: 33.8491\n",
      "Epoch 941/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 562.7039 - mae: 13.1082 - val_loss: 3631.7903 - val_mae: 33.9940\n",
      "Epoch 942/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 523.4260 - mae: 13.2245 - val_loss: 3647.1577 - val_mae: 34.3994\n",
      "Epoch 943/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 431.1017 - mae: 12.2184 - val_loss: 3617.7446 - val_mae: 33.4018\n",
      "Epoch 944/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 520.5396 - mae: 12.9520 - val_loss: 3646.7212 - val_mae: 33.9397\n",
      "Epoch 945/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 520.2452 - mae: 12.8392 - val_loss: 3589.5557 - val_mae: 33.6606\n",
      "Epoch 946/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 475.9098 - mae: 12.6309 - val_loss: 3649.0007 - val_mae: 33.7094\n",
      "Epoch 947/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 469.6510 - mae: 12.6411 - val_loss: 3620.4211 - val_mae: 33.5395\n",
      "Epoch 948/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 503.3175 - mae: 13.0990 - val_loss: 3532.9768 - val_mae: 33.0704\n",
      "Epoch 949/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 487.1687 - mae: 12.8720 - val_loss: 3590.4302 - val_mae: 34.1781\n",
      "Epoch 950/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 495.7880 - mae: 13.0622 - val_loss: 3633.7559 - val_mae: 34.0720\n",
      "Epoch 951/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 524.8438 - mae: 13.2007 - val_loss: 3613.5938 - val_mae: 33.2707\n",
      "Epoch 952/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 500.6931 - mae: 12.8572 - val_loss: 3498.4656 - val_mae: 33.9619\n",
      "Epoch 953/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 459.8569 - mae: 12.5156 - val_loss: 3601.0864 - val_mae: 33.7376\n",
      "Epoch 954/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 463.2059 - mae: 12.6169 - val_loss: 3655.2742 - val_mae: 34.3668\n",
      "Epoch 955/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 490.5685 - mae: 12.9358 - val_loss: 3736.5112 - val_mae: 34.4109\n",
      "Epoch 956/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 470.7406 - mae: 12.7973 - val_loss: 3758.8423 - val_mae: 34.8079\n",
      "Epoch 957/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 456.8531 - mae: 12.5069 - val_loss: 3666.8621 - val_mae: 34.2713\n",
      "Epoch 958/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 464.2456 - mae: 12.4853 - val_loss: 3761.2170 - val_mae: 34.0997\n",
      "Epoch 959/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 504.2363 - mae: 12.7841 - val_loss: 3518.1631 - val_mae: 33.4192\n",
      "Epoch 960/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 468.9484 - mae: 12.6750 - val_loss: 3756.7642 - val_mae: 34.9067\n",
      "Epoch 961/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 480.5208 - mae: 12.7436 - val_loss: 3612.9800 - val_mae: 34.2399\n",
      "Epoch 962/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 460.0226 - mae: 12.6803 - val_loss: 3663.7852 - val_mae: 33.8755\n",
      "Epoch 963/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 492.8002 - mae: 12.5410 - val_loss: 3727.9536 - val_mae: 34.4130\n",
      "Epoch 964/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 461.2097 - mae: 12.5792 - val_loss: 3721.8899 - val_mae: 34.3703\n",
      "Epoch 965/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 482.3574 - mae: 12.9057 - val_loss: 3676.5132 - val_mae: 34.2368\n",
      "Epoch 966/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 433.3238 - mae: 12.3954 - val_loss: 3693.3130 - val_mae: 34.3513\n",
      "Epoch 967/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 507.8417 - mae: 12.6333 - val_loss: 3566.5059 - val_mae: 33.3164\n",
      "Epoch 968/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 495.4110 - mae: 12.8701 - val_loss: 3706.8738 - val_mae: 34.3854\n",
      "Epoch 969/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 489.7256 - mae: 12.7943 - val_loss: 3680.4092 - val_mae: 33.9780\n",
      "Epoch 970/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 507.6226 - mae: 12.7983 - val_loss: 3695.5710 - val_mae: 34.4030\n",
      "Epoch 971/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 441.1134 - mae: 12.5826 - val_loss: 3699.4238 - val_mae: 33.7325\n",
      "Epoch 972/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 509.4778 - mae: 12.7381 - val_loss: 3688.2639 - val_mae: 34.3426\n",
      "Epoch 973/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 482.5938 - mae: 12.9527 - val_loss: 3701.2285 - val_mae: 33.8954\n",
      "Epoch 974/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 483.7072 - mae: 12.9973 - val_loss: 3667.4451 - val_mae: 34.3910\n",
      "Epoch 975/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 512.9485 - mae: 12.9065 - val_loss: 3601.8101 - val_mae: 33.6638\n",
      "Epoch 976/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 561.3037 - mae: 13.4772 - val_loss: 3711.6008 - val_mae: 33.8010\n",
      "Epoch 977/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 482.0383 - mae: 12.6153 - val_loss: 3784.6665 - val_mae: 34.2407\n",
      "Epoch 978/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 524.0701 - mae: 13.2403 - val_loss: 3728.1504 - val_mae: 34.0249\n",
      "Epoch 979/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 437.6101 - mae: 12.1142 - val_loss: 3674.0112 - val_mae: 34.5421\n",
      "Epoch 980/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 482.9849 - mae: 12.4249 - val_loss: 3711.7051 - val_mae: 34.6560\n",
      "Epoch 981/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 418.8783 - mae: 12.3105 - val_loss: 3654.3188 - val_mae: 34.0680\n",
      "Epoch 982/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 492.3419 - mae: 12.6380 - val_loss: 3675.1230 - val_mae: 33.6209\n",
      "Epoch 983/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 476.1518 - mae: 12.7378 - val_loss: 3616.4451 - val_mae: 34.0040\n",
      "Epoch 984/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 570.5227 - mae: 13.5934 - val_loss: 3694.8601 - val_mae: 34.1224\n",
      "Epoch 985/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 483.3455 - mae: 12.9307 - val_loss: 3678.3218 - val_mae: 33.7470\n",
      "Epoch 986/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 462.7781 - mae: 12.3159 - val_loss: 3685.3943 - val_mae: 34.1935\n",
      "Epoch 987/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 474.4442 - mae: 12.4484 - val_loss: 3618.2637 - val_mae: 33.8417\n",
      "Epoch 988/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 500.4156 - mae: 12.7401 - val_loss: 3674.9827 - val_mae: 34.0363\n",
      "Epoch 989/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 450.1126 - mae: 12.2602 - val_loss: 3619.7051 - val_mae: 34.4781\n",
      "Epoch 990/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 465.8403 - mae: 12.7109 - val_loss: 3736.0562 - val_mae: 34.9689\n",
      "Epoch 991/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 431.2035 - mae: 12.2770 - val_loss: 3832.6130 - val_mae: 35.0467\n",
      "Epoch 992/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 442.3738 - mae: 12.1136 - val_loss: 3712.3311 - val_mae: 34.0031\n",
      "Epoch 993/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 545.0174 - mae: 13.0983 - val_loss: 3839.1357 - val_mae: 34.8495\n",
      "Epoch 994/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 523.9167 - mae: 13.0521 - val_loss: 3716.3979 - val_mae: 34.2139\n",
      "Epoch 995/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 437.2244 - mae: 12.3532 - val_loss: 3674.8713 - val_mae: 33.9297\n",
      "Epoch 996/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 430.0894 - mae: 12.2382 - val_loss: 3731.2966 - val_mae: 34.2165\n",
      "Epoch 997/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 462.3238 - mae: 12.5223 - val_loss: 3778.7896 - val_mae: 34.6674\n",
      "Epoch 998/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.8604 - mae: 12.6021 - val_loss: 3677.6572 - val_mae: 33.9954\n",
      "Epoch 999/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 454.0125 - mae: 12.4466 - val_loss: 3726.6250 - val_mae: 34.1624\n",
      "Epoch 1000/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 455.3785 - mae: 12.2663 - val_loss: 3616.9180 - val_mae: 33.7582\n",
      "Epoch 1001/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 436.4324 - mae: 12.3533 - val_loss: 3619.6904 - val_mae: 34.0124\n",
      "Epoch 1002/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 474.9116 - mae: 12.5704 - val_loss: 3625.5686 - val_mae: 33.9182\n",
      "Epoch 1003/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 485.3208 - mae: 12.7388 - val_loss: 3655.0803 - val_mae: 34.7657\n",
      "Epoch 1004/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 476.4595 - mae: 12.4194 - val_loss: 3730.9514 - val_mae: 34.3398\n",
      "Epoch 1005/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 491.0115 - mae: 13.2381 - val_loss: 3586.2344 - val_mae: 35.2487\n",
      "Epoch 1006/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 465.4382 - mae: 13.2194 - val_loss: 3738.3738 - val_mae: 34.9829\n",
      "Epoch 1007/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 426.9102 - mae: 12.1673 - val_loss: 3689.9243 - val_mae: 34.0976\n",
      "Epoch 1008/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 465.1619 - mae: 12.8591 - val_loss: 3779.3853 - val_mae: 35.1223\n",
      "Epoch 1009/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 453.5366 - mae: 12.3281 - val_loss: 3659.5786 - val_mae: 34.1753\n",
      "Epoch 1010/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 439.6598 - mae: 12.3807 - val_loss: 3681.8452 - val_mae: 34.7058\n",
      "Epoch 1011/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 489.1338 - mae: 12.8093 - val_loss: 3650.2407 - val_mae: 33.7081\n",
      "Epoch 1012/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 430.3336 - mae: 11.9988 - val_loss: 3689.4045 - val_mae: 34.2350\n",
      "Epoch 1013/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 479.9646 - mae: 12.3464 - val_loss: 3753.8318 - val_mae: 34.2600\n",
      "Epoch 1014/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 493.6340 - mae: 12.6959 - val_loss: 3763.5969 - val_mae: 34.2955\n",
      "Epoch 1015/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 489.7716 - mae: 12.8605 - val_loss: 3588.1040 - val_mae: 33.4058\n",
      "Epoch 1016/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 437.2904 - mae: 12.3341 - val_loss: 3655.5166 - val_mae: 34.1257\n",
      "Epoch 1017/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 460.2785 - mae: 12.3137 - val_loss: 3688.4487 - val_mae: 34.3526\n",
      "Epoch 1018/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 555.8191 - mae: 13.1409 - val_loss: 3697.8442 - val_mae: 33.9831\n",
      "Epoch 1019/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 480.0179 - mae: 12.4908 - val_loss: 3675.3499 - val_mae: 34.2051\n",
      "Epoch 1020/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 514.6115 - mae: 12.9651 - val_loss: 3698.3931 - val_mae: 34.0562\n",
      "Epoch 1021/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 457.2667 - mae: 12.3907 - val_loss: 3620.5642 - val_mae: 33.6332\n",
      "Epoch 1022/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 439.7121 - mae: 12.2655 - val_loss: 3699.6782 - val_mae: 34.3090\n",
      "Epoch 1023/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 498.3877 - mae: 12.5988 - val_loss: 3657.7842 - val_mae: 33.7593\n",
      "Epoch 1024/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 444.6583 - mae: 12.3010 - val_loss: 3686.8535 - val_mae: 34.0567\n",
      "Epoch 1025/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 441.1777 - mae: 12.3132 - val_loss: 3602.2571 - val_mae: 33.8499\n",
      "Epoch 1026/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 407.4574 - mae: 11.8803 - val_loss: 3607.9360 - val_mae: 33.9186\n",
      "Epoch 1027/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 445.3705 - mae: 12.3436 - val_loss: 3716.0896 - val_mae: 34.3549\n",
      "Epoch 1028/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 424.5699 - mae: 12.2640 - val_loss: 3641.2400 - val_mae: 33.9546\n",
      "Epoch 1029/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 490.0785 - mae: 12.7827 - val_loss: 3728.5232 - val_mae: 34.5073\n",
      "Epoch 1030/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 466.6787 - mae: 12.7286 - val_loss: 3801.6929 - val_mae: 34.6801\n",
      "Epoch 1031/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 481.0394 - mae: 12.4689 - val_loss: 3861.3540 - val_mae: 35.1857\n",
      "Epoch 1032/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 465.9465 - mae: 12.5654 - val_loss: 3780.5020 - val_mae: 34.1810\n",
      "Epoch 1033/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 471.1134 - mae: 12.6343 - val_loss: 3723.5981 - val_mae: 33.6986\n",
      "Epoch 1034/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 467.4198 - mae: 12.6765 - val_loss: 3852.1467 - val_mae: 34.4567\n",
      "Epoch 1035/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 470.1113 - mae: 12.5782 - val_loss: 3710.8430 - val_mae: 34.0461\n",
      "Epoch 1036/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 430.4534 - mae: 12.0902 - val_loss: 3773.8259 - val_mae: 34.4087\n",
      "Epoch 1037/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 477.3342 - mae: 12.7403 - val_loss: 3832.2788 - val_mae: 34.5929\n",
      "Epoch 1038/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 475.2664 - mae: 12.4165 - val_loss: 3773.9587 - val_mae: 34.3567\n",
      "Epoch 1039/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 438.9956 - mae: 12.3853 - val_loss: 3760.3630 - val_mae: 33.5825\n",
      "Epoch 1040/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 444.2869 - mae: 12.2451 - val_loss: 3750.5959 - val_mae: 34.2271\n",
      "Epoch 1041/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 472.4272 - mae: 12.5881 - val_loss: 3649.2832 - val_mae: 34.1189\n",
      "Epoch 1042/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 486.2523 - mae: 12.6610 - val_loss: 3692.7542 - val_mae: 33.8504\n",
      "Epoch 1043/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 472.1159 - mae: 12.6562 - val_loss: 3644.2432 - val_mae: 33.9890\n",
      "Epoch 1044/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 482.4163 - mae: 12.9193 - val_loss: 3654.4441 - val_mae: 33.5465\n",
      "Epoch 1045/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 508.9853 - mae: 12.6945 - val_loss: 3642.7397 - val_mae: 33.3190\n",
      "Epoch 1046/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 452.4121 - mae: 12.7578 - val_loss: 3614.4709 - val_mae: 33.8650\n",
      "Epoch 1047/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 453.0006 - mae: 12.4884 - val_loss: 3669.0110 - val_mae: 34.2921\n",
      "Epoch 1048/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 451.5575 - mae: 12.4692 - val_loss: 3658.2346 - val_mae: 34.2024\n",
      "Epoch 1049/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 424.5231 - mae: 12.0109 - val_loss: 3703.3296 - val_mae: 33.7781\n",
      "Epoch 1050/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 398.8679 - mae: 11.8957 - val_loss: 3792.7944 - val_mae: 34.5416\n",
      "Epoch 1051/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 438.3293 - mae: 12.3477 - val_loss: 3843.3240 - val_mae: 34.8800\n",
      "Epoch 1052/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 496.4074 - mae: 12.6312 - val_loss: 3675.9038 - val_mae: 34.4628\n",
      "Epoch 1053/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 473.6566 - mae: 12.4909 - val_loss: 3689.3813 - val_mae: 34.4543\n",
      "Epoch 1054/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 434.2541 - mae: 12.5395 - val_loss: 3703.2974 - val_mae: 34.4196\n",
      "Epoch 1055/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 499.6494 - mae: 12.6008 - val_loss: 3785.6067 - val_mae: 34.7044\n",
      "Epoch 1056/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 461.1700 - mae: 12.2896 - val_loss: 3672.2434 - val_mae: 33.9214\n",
      "Epoch 1057/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 428.3228 - mae: 11.7783 - val_loss: 3759.1772 - val_mae: 34.6623\n",
      "Epoch 1058/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 522.7507 - mae: 12.9301 - val_loss: 3645.6309 - val_mae: 34.0048\n",
      "Epoch 1059/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 506.5338 - mae: 12.6637 - val_loss: 3658.5969 - val_mae: 34.1544\n",
      "Epoch 1060/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 492.9939 - mae: 12.5104 - val_loss: 3632.2131 - val_mae: 33.9514\n",
      "Epoch 1061/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 418.6367 - mae: 12.3084 - val_loss: 3772.6047 - val_mae: 34.8201\n",
      "Epoch 1062/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 433.3746 - mae: 12.0477 - val_loss: 3809.4651 - val_mae: 35.2681\n",
      "Epoch 1063/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 432.7649 - mae: 12.5509 - val_loss: 3842.4355 - val_mae: 35.2819\n",
      "Epoch 1064/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 466.9117 - mae: 12.3087 - val_loss: 3812.7522 - val_mae: 34.7020\n",
      "Epoch 1065/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 465.2451 - mae: 12.6313 - val_loss: 3822.6514 - val_mae: 34.5944\n",
      "Epoch 1066/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 408.2690 - mae: 12.2192 - val_loss: 3728.1106 - val_mae: 34.2740\n",
      "Epoch 1067/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 488.3481 - mae: 12.6587 - val_loss: 3686.0269 - val_mae: 34.1636\n",
      "Epoch 1068/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 451.2083 - mae: 12.3674 - val_loss: 3874.0793 - val_mae: 35.3030\n",
      "Epoch 1069/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.6931 - mae: 11.9524 - val_loss: 3813.9731 - val_mae: 34.5758\n",
      "Epoch 1070/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 488.0807 - mae: 12.5468 - val_loss: 3782.4099 - val_mae: 35.1530\n",
      "Epoch 1071/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 463.8158 - mae: 12.5618 - val_loss: 3897.2410 - val_mae: 35.1786\n",
      "Epoch 1072/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 486.2408 - mae: 12.5121 - val_loss: 3723.0552 - val_mae: 34.1191\n",
      "Epoch 1073/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 471.1460 - mae: 12.4921 - val_loss: 3807.7720 - val_mae: 34.3906\n",
      "Epoch 1074/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 507.4473 - mae: 12.7929 - val_loss: 3670.1497 - val_mae: 34.1990\n",
      "Epoch 1075/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 463.2539 - mae: 12.2576 - val_loss: 3784.4553 - val_mae: 34.6678\n",
      "Epoch 1076/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 452.2976 - mae: 12.3415 - val_loss: 3672.6782 - val_mae: 33.6277\n",
      "Epoch 1077/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 470.4927 - mae: 12.3966 - val_loss: 3701.4006 - val_mae: 33.9444\n",
      "Epoch 1078/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 472.3629 - mae: 12.2533 - val_loss: 3643.3713 - val_mae: 33.7293\n",
      "Epoch 1079/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 418.3604 - mae: 12.1012 - val_loss: 3577.8137 - val_mae: 33.0071\n",
      "Epoch 1080/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 428.4287 - mae: 12.3033 - val_loss: 3631.5659 - val_mae: 33.6012\n",
      "Epoch 1081/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 491.5657 - mae: 12.2976 - val_loss: 3514.5381 - val_mae: 33.3829\n",
      "Epoch 1082/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 501.3484 - mae: 12.9269 - val_loss: 3600.8142 - val_mae: 33.2487\n",
      "Epoch 1083/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 476.8656 - mae: 12.6667 - val_loss: 3707.4558 - val_mae: 33.8022\n",
      "Epoch 1084/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 420.5555 - mae: 12.1514 - val_loss: 3675.0659 - val_mae: 33.7368\n",
      "Epoch 1085/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 408.7983 - mae: 12.1075 - val_loss: 3689.0327 - val_mae: 34.3204\n",
      "Epoch 1086/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 410.8456 - mae: 12.1149 - val_loss: 3743.2788 - val_mae: 34.2387\n",
      "Epoch 1087/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 424.9494 - mae: 12.0246 - val_loss: 3717.0078 - val_mae: 34.0260\n",
      "Epoch 1088/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 407.7575 - mae: 11.9255 - val_loss: 3868.7896 - val_mae: 35.0169\n",
      "Epoch 1089/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 423.6380 - mae: 11.9940 - val_loss: 3723.3027 - val_mae: 34.3697\n",
      "Epoch 1090/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 409.8419 - mae: 11.8720 - val_loss: 3719.6985 - val_mae: 34.4302\n",
      "Epoch 1091/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 425.8182 - mae: 12.1076 - val_loss: 3721.3806 - val_mae: 34.5659\n",
      "Epoch 1092/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 432.1587 - mae: 12.1658 - val_loss: 3717.7493 - val_mae: 34.7731\n",
      "Epoch 1093/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 459.0424 - mae: 12.7424 - val_loss: 3705.4519 - val_mae: 34.3917\n",
      "Epoch 1094/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 465.0580 - mae: 12.4639 - val_loss: 3869.5229 - val_mae: 34.7222\n",
      "Epoch 1095/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 456.9521 - mae: 12.3337 - val_loss: 3754.3796 - val_mae: 34.9662\n",
      "Epoch 1096/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 461.7871 - mae: 12.2214 - val_loss: 3777.8977 - val_mae: 34.1320\n",
      "Epoch 1097/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 440.0735 - mae: 12.2527 - val_loss: 3734.8130 - val_mae: 34.1074\n",
      "Epoch 1098/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 484.4514 - mae: 12.6794 - val_loss: 3712.8879 - val_mae: 34.3667\n",
      "Epoch 1099/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 441.3792 - mae: 12.3866 - val_loss: 3729.2617 - val_mae: 34.4649\n",
      "Epoch 1100/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 430.0678 - mae: 12.2145 - val_loss: 3639.8560 - val_mae: 33.2924\n",
      "Epoch 1101/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 435.1406 - mae: 12.2190 - val_loss: 3727.4944 - val_mae: 33.6997\n",
      "Epoch 1102/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 412.7857 - mae: 12.0401 - val_loss: 3700.4531 - val_mae: 33.6448\n",
      "Epoch 1103/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 438.1013 - mae: 12.2944 - val_loss: 3871.5972 - val_mae: 34.1024\n",
      "Epoch 1104/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 460.0811 - mae: 12.1393 - val_loss: 3697.7817 - val_mae: 34.2979\n",
      "Epoch 1105/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 436.0659 - mae: 12.2791 - val_loss: 3672.4373 - val_mae: 33.7687\n",
      "Epoch 1106/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 427.3613 - mae: 12.0600 - val_loss: 3680.8621 - val_mae: 33.8994\n",
      "Epoch 1107/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 414.2709 - mae: 12.1182 - val_loss: 3677.4673 - val_mae: 34.5266\n",
      "Epoch 1108/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 468.3337 - mae: 12.5534 - val_loss: 3689.9443 - val_mae: 34.3412\n",
      "Epoch 1109/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 481.4192 - mae: 13.1163 - val_loss: 3693.6577 - val_mae: 33.6347\n",
      "Epoch 1110/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 426.8333 - mae: 12.2006 - val_loss: 3764.3801 - val_mae: 34.1899\n",
      "Epoch 1111/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 448.0682 - mae: 12.4508 - val_loss: 3746.0515 - val_mae: 34.5731\n",
      "Epoch 1112/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 446.3557 - mae: 12.2230 - val_loss: 3728.4985 - val_mae: 34.5178\n",
      "Epoch 1113/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 491.6849 - mae: 13.1684 - val_loss: 3755.2207 - val_mae: 34.5585\n",
      "Epoch 1114/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 460.2508 - mae: 12.6070 - val_loss: 3741.6414 - val_mae: 34.1367\n",
      "Epoch 1115/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 446.7356 - mae: 12.3015 - val_loss: 3658.7332 - val_mae: 33.9044\n",
      "Epoch 1116/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 443.1598 - mae: 12.4778 - val_loss: 3746.0742 - val_mae: 33.6699\n",
      "Epoch 1117/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 416.7621 - mae: 11.9541 - val_loss: 3705.6992 - val_mae: 33.9396\n",
      "Epoch 1118/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 428.7499 - mae: 12.2772 - val_loss: 3676.1365 - val_mae: 34.5182\n",
      "Epoch 1119/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 457.3460 - mae: 12.4065 - val_loss: 3744.4097 - val_mae: 34.2459\n",
      "Epoch 1120/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 408.8678 - mae: 11.8666 - val_loss: 3782.3997 - val_mae: 33.9131\n",
      "Epoch 1121/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 519.7870 - mae: 12.5130 - val_loss: 3731.7708 - val_mae: 34.5376\n",
      "Epoch 1122/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 447.5237 - mae: 12.8245 - val_loss: 3721.1187 - val_mae: 34.6971\n",
      "Epoch 1123/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 457.2263 - mae: 12.7112 - val_loss: 3753.2546 - val_mae: 34.7023\n",
      "Epoch 1124/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 409.4552 - mae: 12.4883 - val_loss: 3641.7549 - val_mae: 33.8187\n",
      "Epoch 1125/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 424.0609 - mae: 12.2401 - val_loss: 3652.6685 - val_mae: 33.9149\n",
      "Epoch 1126/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 422.0633 - mae: 12.0589 - val_loss: 3698.2249 - val_mae: 34.6959\n",
      "Epoch 1127/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 449.8522 - mae: 12.0625 - val_loss: 3745.7864 - val_mae: 34.5831\n",
      "Epoch 1128/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 497.2935 - mae: 12.9459 - val_loss: 3699.7317 - val_mae: 34.7492\n",
      "Epoch 1129/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 428.3683 - mae: 12.3876 - val_loss: 3815.1763 - val_mae: 34.7188\n",
      "Epoch 1130/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 465.9364 - mae: 12.4950 - val_loss: 3908.7490 - val_mae: 35.1538\n",
      "Epoch 1131/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 441.0556 - mae: 12.1993 - val_loss: 3695.9617 - val_mae: 33.9662\n",
      "Epoch 1132/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 441.9979 - mae: 12.2362 - val_loss: 3769.8765 - val_mae: 35.2251\n",
      "Epoch 1133/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 494.2045 - mae: 12.7931 - val_loss: 3861.3508 - val_mae: 35.2636\n",
      "Epoch 1134/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 510.2510 - mae: 13.4221 - val_loss: 3885.9451 - val_mae: 36.2685\n",
      "Epoch 1135/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 450.1237 - mae: 12.6028 - val_loss: 3768.2083 - val_mae: 34.1415\n",
      "Epoch 1136/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 378.0710 - mae: 11.4590 - val_loss: 3770.0847 - val_mae: 34.5514\n",
      "Epoch 1137/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 484.6984 - mae: 12.1430 - val_loss: 3732.9702 - val_mae: 34.4108\n",
      "Epoch 1138/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 451.1835 - mae: 12.0245 - val_loss: 3577.2219 - val_mae: 33.9993\n",
      "Epoch 1139/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 408.3995 - mae: 11.7066 - val_loss: 3840.4385 - val_mae: 35.1873\n",
      "Epoch 1140/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 430.9147 - mae: 12.1128 - val_loss: 3784.6816 - val_mae: 35.0313\n",
      "Epoch 1141/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 464.1750 - mae: 12.1792 - val_loss: 3902.7939 - val_mae: 35.3047\n",
      "Epoch 1142/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 413.8999 - mae: 12.0174 - val_loss: 3878.5618 - val_mae: 36.0321\n",
      "Epoch 1143/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 453.2956 - mae: 12.2972 - val_loss: 3804.3232 - val_mae: 34.3935\n",
      "Epoch 1144/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 440.0613 - mae: 12.1242 - val_loss: 3885.8096 - val_mae: 34.9108\n",
      "Epoch 1145/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.2496 - mae: 11.7729 - val_loss: 3900.7422 - val_mae: 34.7660\n",
      "Epoch 1146/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 426.6709 - mae: 12.0814 - val_loss: 3860.0344 - val_mae: 34.6738\n",
      "Epoch 1147/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 402.4580 - mae: 12.0153 - val_loss: 3855.1462 - val_mae: 35.0464\n",
      "Epoch 1148/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 467.3873 - mae: 12.3730 - val_loss: 3758.0659 - val_mae: 34.0995\n",
      "Epoch 1149/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 465.6754 - mae: 12.2783 - val_loss: 3774.9614 - val_mae: 34.6391\n",
      "Epoch 1150/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 468.0071 - mae: 12.2400 - val_loss: 3746.9221 - val_mae: 34.3271\n",
      "Epoch 1151/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 494.7866 - mae: 12.6076 - val_loss: 3752.7856 - val_mae: 34.9720\n",
      "Epoch 1152/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 450.7610 - mae: 12.2878 - val_loss: 3789.3088 - val_mae: 34.7287\n",
      "Epoch 1153/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 463.5276 - mae: 12.2892 - val_loss: 3773.1960 - val_mae: 34.1530\n",
      "Epoch 1154/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 443.0535 - mae: 12.2088 - val_loss: 3860.6729 - val_mae: 35.2283\n",
      "Epoch 1155/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 456.0717 - mae: 12.2586 - val_loss: 3705.1750 - val_mae: 34.2340\n",
      "Epoch 1156/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 420.4989 - mae: 11.6709 - val_loss: 3702.0979 - val_mae: 34.5656\n",
      "Epoch 1157/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 407.1594 - mae: 11.8306 - val_loss: 3741.8291 - val_mae: 34.5885\n",
      "Epoch 1158/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 407.6576 - mae: 11.9722 - val_loss: 3810.9858 - val_mae: 34.6166\n",
      "Epoch 1159/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 423.9276 - mae: 11.7837 - val_loss: 3703.6067 - val_mae: 34.4364\n",
      "Epoch 1160/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 489.9922 - mae: 12.2362 - val_loss: 3666.1262 - val_mae: 34.7883\n",
      "Epoch 1161/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 396.7035 - mae: 11.6450 - val_loss: 3719.5947 - val_mae: 34.3614\n",
      "Epoch 1162/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 446.8460 - mae: 12.1938 - val_loss: 3813.9397 - val_mae: 35.9335\n",
      "Epoch 1163/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 457.4786 - mae: 12.1578 - val_loss: 3921.9102 - val_mae: 35.0309\n",
      "Epoch 1164/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 496.5384 - mae: 12.0602 - val_loss: 3863.9036 - val_mae: 35.0958\n",
      "Epoch 1165/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 392.1001 - mae: 11.5990 - val_loss: 3760.5256 - val_mae: 34.8770\n",
      "Epoch 1166/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 472.0881 - mae: 12.4663 - val_loss: 3734.0513 - val_mae: 34.1065\n",
      "Epoch 1167/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 451.6785 - mae: 12.7158 - val_loss: 3732.4954 - val_mae: 34.3331\n",
      "Epoch 1168/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 425.5692 - mae: 12.1019 - val_loss: 3756.0461 - val_mae: 34.5953\n",
      "Epoch 1169/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 400.3850 - mae: 11.6466 - val_loss: 3770.0537 - val_mae: 34.3341\n",
      "Epoch 1170/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 403.6089 - mae: 11.6274 - val_loss: 3741.3652 - val_mae: 34.2313\n",
      "Epoch 1171/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 382.3264 - mae: 11.7306 - val_loss: 3697.8101 - val_mae: 33.8924\n",
      "Epoch 1172/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 408.7062 - mae: 11.8201 - val_loss: 3726.6741 - val_mae: 34.1318\n",
      "Epoch 1173/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 420.5854 - mae: 11.7926 - val_loss: 3842.7615 - val_mae: 34.6725\n",
      "Epoch 1174/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 451.5840 - mae: 12.3814 - val_loss: 3814.5254 - val_mae: 35.8566\n",
      "Epoch 1175/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 389.5879 - mae: 12.3655 - val_loss: 3816.2410 - val_mae: 34.5993\n",
      "Epoch 1176/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 415.2187 - mae: 11.6518 - val_loss: 3859.0393 - val_mae: 34.3759\n",
      "Epoch 1177/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 369.1501 - mae: 11.4289 - val_loss: 3831.2791 - val_mae: 34.8786\n",
      "Epoch 1178/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 435.8098 - mae: 11.8590 - val_loss: 3788.8708 - val_mae: 34.6739\n",
      "Epoch 1179/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 430.5215 - mae: 11.7279 - val_loss: 3675.8542 - val_mae: 33.9409\n",
      "Epoch 1180/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 400.8082 - mae: 11.6772 - val_loss: 3768.8813 - val_mae: 34.3887\n",
      "Epoch 1181/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 437.6528 - mae: 12.0129 - val_loss: 3693.2136 - val_mae: 33.8431\n",
      "Epoch 1182/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 406.8691 - mae: 11.9277 - val_loss: 3767.4685 - val_mae: 34.1965\n",
      "Epoch 1183/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 438.6054 - mae: 12.0421 - val_loss: 3723.4702 - val_mae: 34.0535\n",
      "Epoch 1184/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 375.4808 - mae: 11.6799 - val_loss: 3740.4197 - val_mae: 34.2009\n",
      "Epoch 1185/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 417.0283 - mae: 11.6898 - val_loss: 3753.6958 - val_mae: 33.6821\n",
      "Epoch 1186/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 432.6951 - mae: 11.8142 - val_loss: 3618.1802 - val_mae: 34.0005\n",
      "Epoch 1187/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 423.6942 - mae: 12.0166 - val_loss: 3737.5820 - val_mae: 33.6824\n",
      "Epoch 1188/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 421.8103 - mae: 11.8092 - val_loss: 3655.3955 - val_mae: 33.2382\n",
      "Epoch 1189/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 431.9447 - mae: 11.9211 - val_loss: 3691.1177 - val_mae: 33.8139\n",
      "Epoch 1190/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 417.9403 - mae: 12.2202 - val_loss: 3692.7820 - val_mae: 33.8086\n",
      "Epoch 1191/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 437.5428 - mae: 12.0790 - val_loss: 3641.7461 - val_mae: 33.4239\n",
      "Epoch 1192/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 411.2752 - mae: 11.5800 - val_loss: 3619.5117 - val_mae: 34.0386\n",
      "Epoch 1193/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 407.7431 - mae: 11.5288 - val_loss: 3764.1382 - val_mae: 34.6826\n",
      "Epoch 1194/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 464.0785 - mae: 12.1947 - val_loss: 3871.3560 - val_mae: 35.2699\n",
      "Epoch 1195/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 396.0476 - mae: 11.4697 - val_loss: 3727.8320 - val_mae: 34.7235\n",
      "Epoch 1196/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 433.9526 - mae: 11.6491 - val_loss: 3715.9858 - val_mae: 34.1454\n",
      "Epoch 1197/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 424.3341 - mae: 11.7361 - val_loss: 3726.0798 - val_mae: 34.4033\n",
      "Epoch 1198/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 424.6241 - mae: 11.7403 - val_loss: 3706.2935 - val_mae: 33.9404\n",
      "Epoch 1199/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 457.9356 - mae: 12.0186 - val_loss: 3707.2112 - val_mae: 34.3076\n",
      "Epoch 1200/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 420.3118 - mae: 11.7360 - val_loss: 3753.2434 - val_mae: 33.7327\n",
      "Epoch 1201/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 383.7404 - mae: 11.3743 - val_loss: 3675.5444 - val_mae: 33.8364\n",
      "Epoch 1202/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 373.0334 - mae: 11.0261 - val_loss: 3698.8706 - val_mae: 34.3782\n",
      "Epoch 1203/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 379.6395 - mae: 11.3706 - val_loss: 3689.0447 - val_mae: 34.1388\n",
      "Epoch 1204/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 370.0498 - mae: 11.2255 - val_loss: 3832.5181 - val_mae: 34.5756\n",
      "Epoch 1205/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 460.0010 - mae: 11.9843 - val_loss: 3805.4263 - val_mae: 34.9842\n",
      "Epoch 1206/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 408.8384 - mae: 11.6921 - val_loss: 3737.2085 - val_mae: 34.4772\n",
      "Epoch 1207/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 375.2285 - mae: 11.2048 - val_loss: 3846.9631 - val_mae: 34.6457\n",
      "Epoch 1208/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 422.3631 - mae: 11.6395 - val_loss: 3751.7761 - val_mae: 34.5619\n",
      "Epoch 1209/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 438.1414 - mae: 11.8893 - val_loss: 3714.1135 - val_mae: 34.6163\n",
      "Epoch 1210/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 447.6494 - mae: 12.1446 - val_loss: 3782.9009 - val_mae: 34.9170\n",
      "Epoch 1211/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 423.1151 - mae: 11.7345 - val_loss: 3601.7561 - val_mae: 33.7730\n",
      "Epoch 1212/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 420.2827 - mae: 11.6901 - val_loss: 3772.8660 - val_mae: 34.5031\n",
      "Epoch 1213/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 454.2331 - mae: 11.6483 - val_loss: 3774.4827 - val_mae: 34.3730\n",
      "Epoch 1214/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 386.9250 - mae: 11.4648 - val_loss: 3721.2451 - val_mae: 34.0187\n",
      "Epoch 1215/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 424.6358 - mae: 11.9000 - val_loss: 3689.8757 - val_mae: 34.2768\n",
      "Epoch 1216/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 390.7837 - mae: 11.9229 - val_loss: 3842.5823 - val_mae: 35.0268\n",
      "Epoch 1217/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.8560 - mae: 11.6041 - val_loss: 3774.6548 - val_mae: 34.1730\n",
      "Epoch 1218/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 394.5925 - mae: 11.7755 - val_loss: 3889.7559 - val_mae: 34.9824\n",
      "Epoch 1219/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 443.0047 - mae: 11.9272 - val_loss: 3798.9673 - val_mae: 34.4399\n",
      "Epoch 1220/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 421.4027 - mae: 11.8382 - val_loss: 3764.3967 - val_mae: 34.4362\n",
      "Epoch 1221/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 434.2286 - mae: 12.0536 - val_loss: 3769.3699 - val_mae: 34.3017\n",
      "Epoch 1222/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 415.9625 - mae: 11.9970 - val_loss: 3744.9900 - val_mae: 34.4403\n",
      "Epoch 1223/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 386.8577 - mae: 11.8211 - val_loss: 3862.1853 - val_mae: 34.6985\n",
      "Epoch 1224/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 436.9238 - mae: 12.1570 - val_loss: 3845.8262 - val_mae: 35.5594\n",
      "Epoch 1225/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 450.8262 - mae: 12.0898 - val_loss: 3765.4993 - val_mae: 34.0480\n",
      "Epoch 1226/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 416.5320 - mae: 12.0465 - val_loss: 3853.5364 - val_mae: 34.5231\n",
      "Epoch 1227/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 404.8709 - mae: 11.8966 - val_loss: 3749.1411 - val_mae: 34.7259\n",
      "Epoch 1228/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 425.9417 - mae: 12.1688 - val_loss: 3685.9080 - val_mae: 33.9561\n",
      "Epoch 1229/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 424.0428 - mae: 12.2283 - val_loss: 3851.8054 - val_mae: 34.5437\n",
      "Epoch 1230/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.6268 - mae: 11.6909 - val_loss: 3796.7314 - val_mae: 34.5158\n",
      "Epoch 1231/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 428.7514 - mae: 11.9620 - val_loss: 3818.6655 - val_mae: 34.3170\n",
      "Epoch 1232/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 410.6795 - mae: 11.8509 - val_loss: 3739.3523 - val_mae: 34.2123\n",
      "Epoch 1233/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 423.6845 - mae: 12.1006 - val_loss: 3792.4949 - val_mae: 34.5599\n",
      "Epoch 1234/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 393.5549 - mae: 11.6331 - val_loss: 3722.3086 - val_mae: 34.2059\n",
      "Epoch 1235/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 404.3879 - mae: 11.8657 - val_loss: 3785.9216 - val_mae: 34.4205\n",
      "Epoch 1236/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 460.3949 - mae: 12.2877 - val_loss: 3626.5710 - val_mae: 33.9931\n",
      "Epoch 1237/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 403.3849 - mae: 11.8605 - val_loss: 3740.4094 - val_mae: 34.2628\n",
      "Epoch 1238/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 448.6772 - mae: 12.2769 - val_loss: 3711.7627 - val_mae: 33.7473\n",
      "Epoch 1239/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 442.4562 - mae: 12.1075 - val_loss: 3769.8235 - val_mae: 33.9879\n",
      "Epoch 1240/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 494.3683 - mae: 12.4957 - val_loss: 3677.4246 - val_mae: 33.3325\n",
      "Epoch 1241/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 425.4210 - mae: 11.8093 - val_loss: 3675.4282 - val_mae: 34.0714\n",
      "Epoch 1242/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 343.0382 - mae: 11.3393 - val_loss: 3795.2285 - val_mae: 34.2727\n",
      "Epoch 1243/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 421.5081 - mae: 11.7422 - val_loss: 3735.3848 - val_mae: 33.7062\n",
      "Epoch 1244/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 401.7378 - mae: 11.7236 - val_loss: 3718.0032 - val_mae: 33.9392\n",
      "Epoch 1245/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 411.3532 - mae: 12.4109 - val_loss: 3685.6643 - val_mae: 33.9288\n",
      "Epoch 1246/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 378.5088 - mae: 11.9258 - val_loss: 3866.5188 - val_mae: 34.8269\n",
      "Epoch 1247/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 441.1285 - mae: 12.9669 - val_loss: 3821.8381 - val_mae: 35.0522\n",
      "Epoch 1248/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 475.9818 - mae: 13.4279 - val_loss: 3609.0273 - val_mae: 34.4059\n",
      "Epoch 1249/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 415.2425 - mae: 12.5899 - val_loss: 3675.1562 - val_mae: 35.2874\n",
      "Epoch 1250/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 380.1930 - mae: 12.3755 - val_loss: 3732.7769 - val_mae: 34.6002\n",
      "Epoch 1251/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 427.8150 - mae: 12.7756 - val_loss: 3798.0840 - val_mae: 35.1406\n",
      "Epoch 1252/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 437.3905 - mae: 12.9258 - val_loss: 3771.6094 - val_mae: 34.3728\n",
      "Epoch 1253/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 409.9580 - mae: 12.5892 - val_loss: 3785.5593 - val_mae: 35.1150\n",
      "Epoch 1254/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 421.9878 - mae: 12.6646 - val_loss: 3673.2864 - val_mae: 34.8988\n",
      "Epoch 1255/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 404.0412 - mae: 12.5482 - val_loss: 3686.8691 - val_mae: 35.8514\n",
      "Epoch 1256/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 445.1355 - mae: 12.6403 - val_loss: 3828.6172 - val_mae: 35.7433\n",
      "Epoch 1257/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 367.7314 - mae: 12.1989 - val_loss: 3852.1816 - val_mae: 35.7136\n",
      "Epoch 1258/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 408.8411 - mae: 12.2145 - val_loss: 3846.8389 - val_mae: 35.6415\n",
      "Epoch 1259/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 458.3423 - mae: 12.7487 - val_loss: 3670.2705 - val_mae: 34.1658\n",
      "Epoch 1260/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 388.5008 - mae: 12.2278 - val_loss: 3642.4285 - val_mae: 34.5855\n",
      "Epoch 1261/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 361.1498 - mae: 12.0771 - val_loss: 3661.1692 - val_mae: 34.3916\n",
      "Epoch 1262/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 387.1461 - mae: 12.1359 - val_loss: 3681.1689 - val_mae: 34.6572\n",
      "Epoch 1263/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.2519 - mae: 11.7655 - val_loss: 3832.9177 - val_mae: 35.6999\n",
      "Epoch 1264/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 391.4422 - mae: 12.1530 - val_loss: 3709.0259 - val_mae: 35.2015\n",
      "Epoch 1265/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 360.1969 - mae: 12.0247 - val_loss: 3691.3821 - val_mae: 34.8951\n",
      "Epoch 1266/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 414.7771 - mae: 12.2984 - val_loss: 3716.2803 - val_mae: 34.6403\n",
      "Epoch 1267/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 431.9557 - mae: 12.3572 - val_loss: 3645.1272 - val_mae: 34.9876\n",
      "Epoch 1268/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 426.6046 - mae: 12.5321 - val_loss: 3653.4163 - val_mae: 34.9919\n",
      "Epoch 1269/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 385.0306 - mae: 11.9671 - val_loss: 3696.1067 - val_mae: 34.6200\n",
      "Epoch 1270/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 451.2439 - mae: 12.7092 - val_loss: 3845.2874 - val_mae: 35.4590\n",
      "Epoch 1271/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 427.1907 - mae: 12.3047 - val_loss: 3735.8696 - val_mae: 34.3314\n",
      "Epoch 1272/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.6550 - mae: 12.1722 - val_loss: 3681.9014 - val_mae: 34.7335\n",
      "Epoch 1273/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 401.2391 - mae: 12.0693 - val_loss: 3769.0251 - val_mae: 35.4730\n",
      "Epoch 1274/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 400.9091 - mae: 12.2252 - val_loss: 3681.2271 - val_mae: 34.4871\n",
      "Epoch 1275/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 401.8058 - mae: 12.3021 - val_loss: 3733.2046 - val_mae: 34.4475\n",
      "Epoch 1276/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 399.9733 - mae: 12.0511 - val_loss: 3649.1511 - val_mae: 34.6920\n",
      "Epoch 1277/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 399.6910 - mae: 12.0891 - val_loss: 3735.3582 - val_mae: 35.7302\n",
      "Epoch 1278/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 416.3468 - mae: 12.0954 - val_loss: 3701.3259 - val_mae: 34.9045\n",
      "Epoch 1279/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 407.6288 - mae: 12.5955 - val_loss: 3739.4832 - val_mae: 36.4133\n",
      "Epoch 1280/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 404.7612 - mae: 12.1808 - val_loss: 3658.8000 - val_mae: 34.3532\n",
      "Epoch 1281/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 414.0696 - mae: 12.2199 - val_loss: 3605.6311 - val_mae: 34.2749\n",
      "Epoch 1282/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 362.0736 - mae: 11.6436 - val_loss: 3767.6008 - val_mae: 34.5716\n",
      "Epoch 1283/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 370.8300 - mae: 12.0747 - val_loss: 3662.3140 - val_mae: 34.3485\n",
      "Epoch 1284/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 365.1135 - mae: 11.7797 - val_loss: 3663.3755 - val_mae: 34.2223\n",
      "Epoch 1285/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 393.9868 - mae: 12.0712 - val_loss: 3646.8438 - val_mae: 34.4756\n",
      "Epoch 1286/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 389.7208 - mae: 11.8463 - val_loss: 3709.8503 - val_mae: 34.4303\n",
      "Epoch 1287/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 368.1967 - mae: 11.6554 - val_loss: 3715.6733 - val_mae: 34.6371\n",
      "Epoch 1288/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 407.8021 - mae: 11.9067 - val_loss: 3813.2451 - val_mae: 34.6866\n",
      "Epoch 1289/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 436.3090 - mae: 12.1633 - val_loss: 3706.8069 - val_mae: 34.1955\n",
      "Epoch 1290/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 387.3239 - mae: 11.9012 - val_loss: 3793.2986 - val_mae: 34.9466\n",
      "Epoch 1291/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 376.5993 - mae: 11.7636 - val_loss: 3656.0591 - val_mae: 34.2377\n",
      "Epoch 1292/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 433.6628 - mae: 12.0636 - val_loss: 3783.3577 - val_mae: 34.9979\n",
      "Epoch 1293/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 393.9370 - mae: 11.9024 - val_loss: 3743.6982 - val_mae: 34.5906\n",
      "Epoch 1294/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 397.5850 - mae: 12.2811 - val_loss: 3724.9382 - val_mae: 34.7681\n",
      "Epoch 1295/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 433.2241 - mae: 11.9843 - val_loss: 3798.1768 - val_mae: 34.3020\n",
      "Epoch 1296/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 434.0295 - mae: 12.4429 - val_loss: 3788.1179 - val_mae: 34.6360\n",
      "Epoch 1297/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 405.8234 - mae: 11.8586 - val_loss: 3865.5928 - val_mae: 34.5820\n",
      "Epoch 1298/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 389.4321 - mae: 11.7726 - val_loss: 3734.7283 - val_mae: 34.7945\n",
      "Epoch 1299/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 396.4105 - mae: 11.9522 - val_loss: 3750.7744 - val_mae: 34.3861\n",
      "Epoch 1300/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 392.9212 - mae: 11.7669 - val_loss: 3804.5981 - val_mae: 34.7728\n",
      "Epoch 1301/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 404.0123 - mae: 11.7645 - val_loss: 3678.7002 - val_mae: 34.0768\n",
      "Epoch 1302/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 411.8516 - mae: 11.8696 - val_loss: 3701.8599 - val_mae: 34.5526\n",
      "Epoch 1303/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 468.2531 - mae: 12.4496 - val_loss: 3756.8196 - val_mae: 34.8600\n",
      "Epoch 1304/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 380.7422 - mae: 11.8435 - val_loss: 3727.8250 - val_mae: 34.4409\n",
      "Epoch 1305/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.5605 - mae: 11.6210 - val_loss: 3785.9517 - val_mae: 34.7878\n",
      "Epoch 1306/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 351.5282 - mae: 11.4907 - val_loss: 3778.2285 - val_mae: 34.5017\n",
      "Epoch 1307/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 374.1201 - mae: 11.5351 - val_loss: 3753.8308 - val_mae: 34.9565\n",
      "Epoch 1308/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 380.2240 - mae: 11.7339 - val_loss: 3592.2649 - val_mae: 33.8678\n",
      "Epoch 1309/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 398.6084 - mae: 11.7508 - val_loss: 3608.7610 - val_mae: 34.1557\n",
      "Epoch 1310/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.4578 - mae: 11.6962 - val_loss: 3738.3062 - val_mae: 34.5723\n",
      "Epoch 1311/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 426.2191 - mae: 12.2158 - val_loss: 3765.1531 - val_mae: 34.5190\n",
      "Epoch 1312/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 410.1541 - mae: 12.1270 - val_loss: 3718.3633 - val_mae: 35.1993\n",
      "Epoch 1313/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 390.2506 - mae: 11.7692 - val_loss: 3777.4519 - val_mae: 35.1089\n",
      "Epoch 1314/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 377.6570 - mae: 11.8161 - val_loss: 3673.8984 - val_mae: 34.6940\n",
      "Epoch 1315/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 391.0537 - mae: 11.8381 - val_loss: 3810.3289 - val_mae: 35.3697\n",
      "Epoch 1316/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 376.6027 - mae: 11.6428 - val_loss: 3766.3984 - val_mae: 35.3533\n",
      "Epoch 1317/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 372.1479 - mae: 11.5135 - val_loss: 3782.2021 - val_mae: 35.2748\n",
      "Epoch 1318/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 393.4306 - mae: 11.7189 - val_loss: 3740.4697 - val_mae: 35.4556\n",
      "Epoch 1319/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 417.7343 - mae: 11.6914 - val_loss: 3710.9138 - val_mae: 34.2880\n",
      "Epoch 1320/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 385.1696 - mae: 11.5498 - val_loss: 3757.2383 - val_mae: 34.7733\n",
      "Epoch 1321/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 393.8585 - mae: 11.6855 - val_loss: 3877.8481 - val_mae: 34.3510\n",
      "Epoch 1322/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 321.7854 - mae: 11.0955 - val_loss: 3852.7070 - val_mae: 35.4646\n",
      "Epoch 1323/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 381.4521 - mae: 11.7016 - val_loss: 3814.7217 - val_mae: 35.0062\n",
      "Epoch 1324/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 346.1753 - mae: 11.3107 - val_loss: 3900.5403 - val_mae: 35.0480\n",
      "Epoch 1325/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 380.4476 - mae: 11.6609 - val_loss: 3830.2002 - val_mae: 35.9789\n",
      "Epoch 1326/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 361.2568 - mae: 11.2579 - val_loss: 3949.4749 - val_mae: 35.2152\n",
      "Epoch 1327/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 388.5477 - mae: 11.5255 - val_loss: 3749.2856 - val_mae: 34.6235\n",
      "Epoch 1328/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 415.7152 - mae: 11.7217 - val_loss: 3868.2708 - val_mae: 35.9628\n",
      "Epoch 1329/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 381.6993 - mae: 11.5566 - val_loss: 3756.2673 - val_mae: 34.4684\n",
      "Epoch 1330/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.8794 - mae: 11.2735 - val_loss: 3878.6511 - val_mae: 35.1677\n",
      "Epoch 1331/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.8786 - mae: 11.6892 - val_loss: 3821.3357 - val_mae: 35.6199\n",
      "Epoch 1332/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 368.0660 - mae: 11.4733 - val_loss: 3770.1667 - val_mae: 34.7901\n",
      "Epoch 1333/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 391.7076 - mae: 11.4628 - val_loss: 3771.2812 - val_mae: 35.2693\n",
      "Epoch 1334/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 390.0853 - mae: 11.6253 - val_loss: 3839.5332 - val_mae: 35.5167\n",
      "Epoch 1335/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 346.7719 - mae: 11.2346 - val_loss: 3766.0559 - val_mae: 34.2411\n",
      "Epoch 1336/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 412.2192 - mae: 11.5495 - val_loss: 3883.4617 - val_mae: 35.4142\n",
      "Epoch 1337/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 436.6294 - mae: 12.0028 - val_loss: 3859.5613 - val_mae: 35.5781\n",
      "Epoch 1338/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 409.0479 - mae: 11.6788 - val_loss: 4061.7727 - val_mae: 36.1400\n",
      "Epoch 1339/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 393.2430 - mae: 11.3812 - val_loss: 3788.7209 - val_mae: 34.6833\n",
      "Epoch 1340/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 383.0936 - mae: 11.2965 - val_loss: 3858.6016 - val_mae: 35.5954\n",
      "Epoch 1341/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 375.3412 - mae: 11.5336 - val_loss: 3786.1199 - val_mae: 34.9888\n",
      "Epoch 1342/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 403.9292 - mae: 11.6337 - val_loss: 3806.6287 - val_mae: 34.8836\n",
      "Epoch 1343/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 372.7727 - mae: 11.2347 - val_loss: 3810.0488 - val_mae: 35.2486\n",
      "Epoch 1344/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 418.2496 - mae: 11.8338 - val_loss: 3797.0049 - val_mae: 34.9777\n",
      "Epoch 1345/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 414.6296 - mae: 11.8483 - val_loss: 3892.7839 - val_mae: 35.3367\n",
      "Epoch 1346/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 363.9097 - mae: 11.4139 - val_loss: 3680.1016 - val_mae: 34.0557\n",
      "Epoch 1347/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 377.0782 - mae: 11.6757 - val_loss: 3810.3191 - val_mae: 34.7782\n",
      "Epoch 1348/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 418.9613 - mae: 11.7925 - val_loss: 3779.9890 - val_mae: 34.6566\n",
      "Epoch 1349/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 397.0584 - mae: 11.7077 - val_loss: 3886.6711 - val_mae: 34.9000\n",
      "Epoch 1350/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 375.7268 - mae: 11.6020 - val_loss: 3739.8472 - val_mae: 34.4309\n",
      "Epoch 1351/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 353.8947 - mae: 11.3504 - val_loss: 3750.9590 - val_mae: 34.2310\n",
      "Epoch 1352/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 363.0102 - mae: 11.3674 - val_loss: 3760.2756 - val_mae: 34.1125\n",
      "Epoch 1353/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 363.2819 - mae: 11.3072 - val_loss: 3905.3438 - val_mae: 35.0718\n",
      "Epoch 1354/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 453.6421 - mae: 11.8180 - val_loss: 3658.5737 - val_mae: 34.3241\n",
      "Epoch 1355/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 403.3358 - mae: 12.4119 - val_loss: 3798.4365 - val_mae: 36.0448\n",
      "Epoch 1356/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 398.5717 - mae: 11.9545 - val_loss: 3745.4729 - val_mae: 34.6876\n",
      "Epoch 1357/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 359.6741 - mae: 11.5008 - val_loss: 3698.9233 - val_mae: 34.2686\n",
      "Epoch 1358/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 404.4925 - mae: 11.6938 - val_loss: 3825.6123 - val_mae: 34.3966\n",
      "Epoch 1359/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 382.2733 - mae: 11.4337 - val_loss: 3810.6138 - val_mae: 34.6781\n",
      "Epoch 1360/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 375.6162 - mae: 11.2555 - val_loss: 3701.0464 - val_mae: 34.1806\n",
      "Epoch 1361/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 377.5670 - mae: 11.3429 - val_loss: 3716.4607 - val_mae: 34.8682\n",
      "Epoch 1362/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 353.9017 - mae: 11.3903 - val_loss: 3711.0261 - val_mae: 34.8304\n",
      "Epoch 1363/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 338.2991 - mae: 11.0870 - val_loss: 3846.7812 - val_mae: 34.8882\n",
      "Epoch 1364/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 362.4485 - mae: 11.3177 - val_loss: 3791.5642 - val_mae: 34.6388\n",
      "Epoch 1365/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 379.1490 - mae: 11.0871 - val_loss: 3615.1470 - val_mae: 34.1506\n",
      "Epoch 1366/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 373.2669 - mae: 11.3414 - val_loss: 3760.1931 - val_mae: 34.9113\n",
      "Epoch 1367/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 407.2831 - mae: 11.7172 - val_loss: 3786.3435 - val_mae: 35.0344\n",
      "Epoch 1368/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 406.8232 - mae: 11.5806 - val_loss: 3752.3230 - val_mae: 34.5325\n",
      "Epoch 1369/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 359.7912 - mae: 11.3457 - val_loss: 3728.2131 - val_mae: 34.1333\n",
      "Epoch 1370/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 423.4286 - mae: 11.8268 - val_loss: 3860.1313 - val_mae: 35.5089\n",
      "Epoch 1371/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 381.3013 - mae: 11.6374 - val_loss: 3819.6709 - val_mae: 34.6740\n",
      "Epoch 1372/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 380.9386 - mae: 11.3361 - val_loss: 3808.3652 - val_mae: 34.8760\n",
      "Epoch 1373/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 375.6503 - mae: 11.3481 - val_loss: 3806.9150 - val_mae: 34.5582\n",
      "Epoch 1374/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 366.1563 - mae: 11.3245 - val_loss: 3950.6006 - val_mae: 35.7525\n",
      "Epoch 1375/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 368.7495 - mae: 11.1785 - val_loss: 3909.3264 - val_mae: 35.8692\n",
      "Epoch 1376/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 350.5080 - mae: 10.9191 - val_loss: 3825.2615 - val_mae: 34.3737\n",
      "Epoch 1377/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 369.3706 - mae: 11.1723 - val_loss: 3894.5972 - val_mae: 34.7562\n",
      "Epoch 1378/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 312.7107 - mae: 10.6941 - val_loss: 3894.4153 - val_mae: 35.2618\n",
      "Epoch 1379/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 381.9458 - mae: 11.3026 - val_loss: 3795.0588 - val_mae: 34.6635\n",
      "Epoch 1380/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 397.1303 - mae: 11.5386 - val_loss: 3826.3760 - val_mae: 35.1575\n",
      "Epoch 1381/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 443.8325 - mae: 11.8154 - val_loss: 3872.7871 - val_mae: 34.9176\n",
      "Epoch 1382/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 376.6530 - mae: 11.4573 - val_loss: 3804.1216 - val_mae: 34.6245\n",
      "Epoch 1383/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 372.6060 - mae: 11.4031 - val_loss: 3770.9712 - val_mae: 35.1666\n",
      "Epoch 1384/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 370.5874 - mae: 11.3184 - val_loss: 3752.1296 - val_mae: 34.8332\n",
      "Epoch 1385/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 361.1268 - mae: 11.2102 - val_loss: 3844.6748 - val_mae: 35.3573\n",
      "Epoch 1386/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.2119 - mae: 10.6326 - val_loss: 3752.9971 - val_mae: 35.1177\n",
      "Epoch 1387/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 395.5998 - mae: 11.4599 - val_loss: 3745.7717 - val_mae: 35.4068\n",
      "Epoch 1388/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 353.3585 - mae: 11.1104 - val_loss: 3810.6938 - val_mae: 35.2104\n",
      "Epoch 1389/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 378.4179 - mae: 11.3461 - val_loss: 3772.8779 - val_mae: 35.0571\n",
      "Epoch 1390/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 395.1830 - mae: 11.5194 - val_loss: 3916.6301 - val_mae: 35.3078\n",
      "Epoch 1391/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 398.3233 - mae: 11.3861 - val_loss: 3806.5586 - val_mae: 34.7414\n",
      "Epoch 1392/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 372.0569 - mae: 11.2680 - val_loss: 3784.8862 - val_mae: 34.8513\n",
      "Epoch 1393/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 393.6590 - mae: 11.2372 - val_loss: 3793.0166 - val_mae: 34.7326\n",
      "Epoch 1394/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 405.0754 - mae: 11.5115 - val_loss: 3781.9067 - val_mae: 34.3325\n",
      "Epoch 1395/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 352.5284 - mae: 11.1819 - val_loss: 3802.7258 - val_mae: 34.3687\n",
      "Epoch 1396/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 376.9198 - mae: 11.2795 - val_loss: 3894.8159 - val_mae: 36.1226\n",
      "Epoch 1397/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.1302 - mae: 10.8725 - val_loss: 3872.0540 - val_mae: 35.1663\n",
      "Epoch 1398/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 428.0309 - mae: 11.6538 - val_loss: 3707.1897 - val_mae: 34.5541\n",
      "Epoch 1399/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 400.1918 - mae: 11.4446 - val_loss: 3759.2229 - val_mae: 34.2355\n",
      "Epoch 1400/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 412.1601 - mae: 11.5962 - val_loss: 3722.7380 - val_mae: 34.9105\n",
      "Epoch 1401/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 353.9906 - mae: 11.2052 - val_loss: 3720.1943 - val_mae: 34.7254\n",
      "Epoch 1402/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.9348 - mae: 11.2625 - val_loss: 3718.8491 - val_mae: 34.6182\n",
      "Epoch 1403/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 354.5440 - mae: 10.9494 - val_loss: 3905.3767 - val_mae: 35.0130\n",
      "Epoch 1404/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 393.4948 - mae: 11.5686 - val_loss: 3892.6135 - val_mae: 35.1569\n",
      "Epoch 1405/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 358.0359 - mae: 11.1107 - val_loss: 3747.6587 - val_mae: 34.5633\n",
      "Epoch 1406/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 369.0614 - mae: 11.1882 - val_loss: 3686.7739 - val_mae: 34.4932\n",
      "Epoch 1407/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 399.0836 - mae: 11.1158 - val_loss: 3722.0747 - val_mae: 34.4687\n",
      "Epoch 1408/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 423.7887 - mae: 11.7535 - val_loss: 3758.6863 - val_mae: 34.4980\n",
      "Epoch 1409/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 402.5985 - mae: 11.4846 - val_loss: 3703.4221 - val_mae: 34.7158\n",
      "Epoch 1410/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 402.6377 - mae: 11.3444 - val_loss: 3871.1812 - val_mae: 35.1508\n",
      "Epoch 1411/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 345.5912 - mae: 10.9550 - val_loss: 3799.7808 - val_mae: 34.9855\n",
      "Epoch 1412/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 373.4928 - mae: 11.1799 - val_loss: 3879.4099 - val_mae: 35.1888\n",
      "Epoch 1413/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 356.1858 - mae: 11.0598 - val_loss: 3698.8020 - val_mae: 34.4411\n",
      "Epoch 1414/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 392.1059 - mae: 11.3113 - val_loss: 3775.4741 - val_mae: 34.8325\n",
      "Epoch 1415/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 382.1195 - mae: 11.3260 - val_loss: 3838.9785 - val_mae: 35.3145\n",
      "Epoch 1416/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 350.8288 - mae: 10.9540 - val_loss: 3770.8694 - val_mae: 34.6996\n",
      "Epoch 1417/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 351.6196 - mae: 11.1344 - val_loss: 3784.7842 - val_mae: 35.4232\n",
      "Epoch 1418/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 400.3863 - mae: 11.3991 - val_loss: 3940.2446 - val_mae: 35.9451\n",
      "Epoch 1419/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 341.1012 - mae: 10.7825 - val_loss: 3907.4058 - val_mae: 34.9021\n",
      "Epoch 1420/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 384.2130 - mae: 11.1509 - val_loss: 3668.4985 - val_mae: 34.5983\n",
      "Epoch 1421/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 328.3295 - mae: 10.8803 - val_loss: 3770.4573 - val_mae: 34.3565\n",
      "Epoch 1422/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.5078 - mae: 10.8359 - val_loss: 3776.8955 - val_mae: 35.1532\n",
      "Epoch 1423/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 326.5854 - mae: 10.9302 - val_loss: 3829.8594 - val_mae: 34.3734\n",
      "Epoch 1424/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 359.1003 - mae: 10.9947 - val_loss: 3875.6794 - val_mae: 35.1659\n",
      "Epoch 1425/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.6753 - mae: 10.9223 - val_loss: 3910.5059 - val_mae: 35.3620\n",
      "Epoch 1426/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 381.6942 - mae: 11.2214 - val_loss: 3855.3093 - val_mae: 35.2313\n",
      "Epoch 1427/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 365.9386 - mae: 10.8669 - val_loss: 3712.9263 - val_mae: 34.8280\n",
      "Epoch 1428/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 319.8280 - mae: 10.6979 - val_loss: 3783.7527 - val_mae: 34.5966\n",
      "Epoch 1429/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.6295 - mae: 11.0040 - val_loss: 3759.5845 - val_mae: 34.4598\n",
      "Epoch 1430/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 428.6855 - mae: 11.4422 - val_loss: 3777.8271 - val_mae: 34.6230\n",
      "Epoch 1431/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 340.8604 - mae: 10.9629 - val_loss: 3775.2617 - val_mae: 34.4501\n",
      "Epoch 1432/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 401.7702 - mae: 11.2180 - val_loss: 3771.8406 - val_mae: 33.8948\n",
      "Epoch 1433/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 349.7275 - mae: 10.9191 - val_loss: 3930.3989 - val_mae: 35.1778\n",
      "Epoch 1434/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 350.2254 - mae: 11.0266 - val_loss: 3819.7642 - val_mae: 34.4424\n",
      "Epoch 1435/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 377.7795 - mae: 11.0188 - val_loss: 3901.7461 - val_mae: 35.6676\n",
      "Epoch 1436/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 381.2943 - mae: 11.1269 - val_loss: 3815.9219 - val_mae: 35.0408\n",
      "Epoch 1437/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 373.8756 - mae: 11.0132 - val_loss: 3952.5942 - val_mae: 35.6736\n",
      "Epoch 1438/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 344.0006 - mae: 10.8809 - val_loss: 3963.0461 - val_mae: 35.7498\n",
      "Epoch 1439/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 365.1091 - mae: 11.1023 - val_loss: 3919.6172 - val_mae: 35.0905\n",
      "Epoch 1440/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 450.0169 - mae: 11.5718 - val_loss: 3741.4492 - val_mae: 34.3238\n",
      "Epoch 1441/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.1274 - mae: 10.9476 - val_loss: 3769.2080 - val_mae: 34.8255\n",
      "Epoch 1442/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 369.7525 - mae: 11.0304 - val_loss: 3772.9287 - val_mae: 34.6876\n",
      "Epoch 1443/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 375.6292 - mae: 11.0611 - val_loss: 3863.8416 - val_mae: 35.2328\n",
      "Epoch 1444/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 376.3954 - mae: 11.0798 - val_loss: 3722.7463 - val_mae: 34.6132\n",
      "Epoch 1445/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 424.5869 - mae: 11.5328 - val_loss: 3941.8904 - val_mae: 35.4932\n",
      "Epoch 1446/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 355.0030 - mae: 10.7523 - val_loss: 3823.0190 - val_mae: 35.2059\n",
      "Epoch 1447/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 368.9778 - mae: 10.9149 - val_loss: 3780.4819 - val_mae: 34.8374\n",
      "Epoch 1448/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 362.9166 - mae: 10.9980 - val_loss: 3815.6943 - val_mae: 34.9152\n",
      "Epoch 1449/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 337.2299 - mae: 10.7284 - val_loss: 4006.2681 - val_mae: 35.9313\n",
      "Epoch 1450/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.0719 - mae: 10.8192 - val_loss: 3830.4795 - val_mae: 34.6810\n",
      "Epoch 1451/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 401.8542 - mae: 11.5077 - val_loss: 3862.1104 - val_mae: 35.7262\n",
      "Epoch 1452/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 330.9051 - mae: 10.5487 - val_loss: 3992.6121 - val_mae: 35.9502\n",
      "Epoch 1453/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 383.9284 - mae: 11.2294 - val_loss: 3970.7261 - val_mae: 36.1324\n",
      "Epoch 1454/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.6069 - mae: 11.0582 - val_loss: 3917.6543 - val_mae: 35.2006\n",
      "Epoch 1455/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.0654 - mae: 10.8723 - val_loss: 3929.9563 - val_mae: 35.2385\n",
      "Epoch 1456/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.9851 - mae: 10.7735 - val_loss: 3919.3279 - val_mae: 35.3781\n",
      "Epoch 1457/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 374.2661 - mae: 10.9663 - val_loss: 4024.8489 - val_mae: 35.6974\n",
      "Epoch 1458/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 395.2426 - mae: 11.2840 - val_loss: 3914.0544 - val_mae: 35.0303\n",
      "Epoch 1459/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 396.6824 - mae: 11.2923 - val_loss: 3809.7361 - val_mae: 35.6380\n",
      "Epoch 1460/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 363.9691 - mae: 10.9989 - val_loss: 3921.1079 - val_mae: 35.8169\n",
      "Epoch 1461/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 372.2341 - mae: 11.0571 - val_loss: 3874.8684 - val_mae: 35.1396\n",
      "Epoch 1462/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.6140 - mae: 10.7830 - val_loss: 3877.0574 - val_mae: 34.6977\n",
      "Epoch 1463/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 351.1649 - mae: 10.8693 - val_loss: 3778.7903 - val_mae: 34.4890\n",
      "Epoch 1464/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 358.0664 - mae: 10.8872 - val_loss: 3818.5283 - val_mae: 34.8762\n",
      "Epoch 1465/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 349.2014 - mae: 10.8319 - val_loss: 3793.4365 - val_mae: 34.8593\n",
      "Epoch 1466/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 319.1015 - mae: 10.6029 - val_loss: 3794.4092 - val_mae: 34.8334\n",
      "Epoch 1467/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 328.1302 - mae: 10.7230 - val_loss: 3862.6755 - val_mae: 34.4955\n",
      "Epoch 1468/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.4800 - mae: 10.8398 - val_loss: 3998.6533 - val_mae: 35.5128\n",
      "Epoch 1469/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 368.8167 - mae: 11.0128 - val_loss: 3814.0933 - val_mae: 35.2972\n",
      "Epoch 1470/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 339.3089 - mae: 10.9174 - val_loss: 3868.1318 - val_mae: 34.4941\n",
      "Epoch 1471/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 354.9512 - mae: 10.7698 - val_loss: 3913.8901 - val_mae: 34.6648\n",
      "Epoch 1472/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 362.5970 - mae: 10.6612 - val_loss: 3880.0183 - val_mae: 35.0485\n",
      "Epoch 1473/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 344.1761 - mae: 10.8114 - val_loss: 3822.3857 - val_mae: 34.3652\n",
      "Epoch 1474/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 410.0559 - mae: 11.3127 - val_loss: 3930.8235 - val_mae: 35.2025\n",
      "Epoch 1475/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.1160 - mae: 10.5270 - val_loss: 3862.2888 - val_mae: 35.0561\n",
      "Epoch 1476/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 350.3322 - mae: 10.6823 - val_loss: 3825.7756 - val_mae: 35.2164\n",
      "Epoch 1477/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 379.9915 - mae: 10.9540 - val_loss: 3898.4319 - val_mae: 34.9509\n",
      "Epoch 1478/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 331.5329 - mae: 10.5634 - val_loss: 3833.2930 - val_mae: 34.9029\n",
      "Epoch 1479/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 363.0773 - mae: 10.9019 - val_loss: 3748.9614 - val_mae: 34.6527\n",
      "Epoch 1480/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 332.0838 - mae: 10.5133 - val_loss: 3916.0964 - val_mae: 35.3207\n",
      "Epoch 1481/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 348.0302 - mae: 10.5747 - val_loss: 3719.9468 - val_mae: 34.3486\n",
      "Epoch 1482/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 344.6444 - mae: 10.7837 - val_loss: 3782.1191 - val_mae: 34.4513\n",
      "Epoch 1483/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.7337 - mae: 10.6292 - val_loss: 3782.2866 - val_mae: 34.2185\n",
      "Epoch 1484/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 359.4828 - mae: 10.8344 - val_loss: 3838.8806 - val_mae: 34.6230\n",
      "Epoch 1485/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 370.3579 - mae: 10.8709 - val_loss: 3993.5779 - val_mae: 35.4522\n",
      "Epoch 1486/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 388.5891 - mae: 11.1715 - val_loss: 3857.7927 - val_mae: 34.7140\n",
      "Epoch 1487/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 339.6390 - mae: 11.1750 - val_loss: 3965.5957 - val_mae: 35.9561\n",
      "Epoch 1488/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 378.9972 - mae: 11.2745 - val_loss: 3859.2014 - val_mae: 34.2709\n",
      "Epoch 1489/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 419.1706 - mae: 11.1685 - val_loss: 3825.5530 - val_mae: 34.4887\n",
      "Epoch 1490/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 380.3908 - mae: 10.9874 - val_loss: 3895.1370 - val_mae: 34.7945\n",
      "Epoch 1491/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 350.8152 - mae: 10.9063 - val_loss: 3959.1697 - val_mae: 34.9134\n",
      "Epoch 1492/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 330.8000 - mae: 10.6186 - val_loss: 3833.2292 - val_mae: 34.2889\n",
      "Epoch 1493/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 366.6918 - mae: 11.0097 - val_loss: 3853.6802 - val_mae: 35.5125\n",
      "Epoch 1494/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 346.7023 - mae: 10.6043 - val_loss: 3902.5737 - val_mae: 34.8069\n",
      "Epoch 1495/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 369.3552 - mae: 11.1087 - val_loss: 3975.2205 - val_mae: 35.6271\n",
      "Epoch 1496/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 359.8240 - mae: 10.8635 - val_loss: 3851.5732 - val_mae: 34.7137\n",
      "Epoch 1497/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 357.3974 - mae: 10.8183 - val_loss: 3808.5347 - val_mae: 34.6025\n",
      "Epoch 1498/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.8661 - mae: 10.9290 - val_loss: 3791.4368 - val_mae: 34.8627\n",
      "Epoch 1499/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 331.5109 - mae: 10.6775 - val_loss: 3954.0266 - val_mae: 34.7803\n",
      "Epoch 1500/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.2433 - mae: 10.5398 - val_loss: 3892.3340 - val_mae: 34.4429\n",
      "Epoch 1501/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 351.4651 - mae: 10.8144 - val_loss: 3776.8740 - val_mae: 34.2275\n",
      "Epoch 1502/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 371.9447 - mae: 10.8754 - val_loss: 3820.6880 - val_mae: 34.6398\n",
      "Epoch 1503/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.5631 - mae: 10.7100 - val_loss: 3640.5571 - val_mae: 33.5596\n",
      "Epoch 1504/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 344.4680 - mae: 10.8524 - val_loss: 3810.3057 - val_mae: 34.6064\n",
      "Epoch 1505/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 362.2310 - mae: 10.7590 - val_loss: 3748.4697 - val_mae: 34.2756\n",
      "Epoch 1506/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 418.4746 - mae: 11.3929 - val_loss: 3724.0208 - val_mae: 33.7796\n",
      "Epoch 1507/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 365.1477 - mae: 10.9013 - val_loss: 3752.9426 - val_mae: 34.2013\n",
      "Epoch 1508/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 387.2597 - mae: 11.0827 - val_loss: 3822.0073 - val_mae: 35.2360\n",
      "Epoch 1509/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.3416 - mae: 10.8877 - val_loss: 3799.5337 - val_mae: 34.5406\n",
      "Epoch 1510/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 326.7074 - mae: 10.4052 - val_loss: 3795.3567 - val_mae: 34.2617\n",
      "Epoch 1511/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 388.2386 - mae: 11.0056 - val_loss: 3805.7158 - val_mae: 34.6503\n",
      "Epoch 1512/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 342.2647 - mae: 10.7852 - val_loss: 3899.6555 - val_mae: 35.0376\n",
      "Epoch 1513/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 342.3518 - mae: 10.8376 - val_loss: 3826.9980 - val_mae: 34.8490\n",
      "Epoch 1514/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 340.6242 - mae: 10.6338 - val_loss: 3862.0508 - val_mae: 34.8623\n",
      "Epoch 1515/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 327.0439 - mae: 10.6926 - val_loss: 3822.2246 - val_mae: 34.9023\n",
      "Epoch 1516/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.0990 - mae: 10.4043 - val_loss: 3905.7920 - val_mae: 34.9587\n",
      "Epoch 1517/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 354.6785 - mae: 10.8972 - val_loss: 3655.9849 - val_mae: 34.5476\n",
      "Epoch 1518/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 396.3986 - mae: 10.8905 - val_loss: 3802.8979 - val_mae: 35.5534\n",
      "Epoch 1519/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 384.9902 - mae: 11.1256 - val_loss: 3821.3154 - val_mae: 35.4769\n",
      "Epoch 1520/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 380.3697 - mae: 11.1084 - val_loss: 3910.1550 - val_mae: 35.0556\n",
      "Epoch 1521/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 333.3214 - mae: 10.5493 - val_loss: 3919.6267 - val_mae: 35.2708\n",
      "Epoch 1522/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.1298 - mae: 10.5071 - val_loss: 3920.4336 - val_mae: 35.1002\n",
      "Epoch 1523/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 341.3161 - mae: 10.6754 - val_loss: 3782.3628 - val_mae: 34.9942\n",
      "Epoch 1524/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 339.1968 - mae: 10.6309 - val_loss: 3847.9895 - val_mae: 34.7385\n",
      "Epoch 1525/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 351.6482 - mae: 10.6785 - val_loss: 3837.6108 - val_mae: 34.9335\n",
      "Epoch 1526/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 362.1497 - mae: 11.0640 - val_loss: 3768.9985 - val_mae: 34.5289\n",
      "Epoch 1527/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 354.9484 - mae: 10.8284 - val_loss: 3747.9700 - val_mae: 35.1617\n",
      "Epoch 1528/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 330.4260 - mae: 10.7299 - val_loss: 3828.5334 - val_mae: 34.7229\n",
      "Epoch 1529/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.1501 - mae: 10.6400 - val_loss: 3882.7207 - val_mae: 35.1780\n",
      "Epoch 1530/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 308.6286 - mae: 10.4670 - val_loss: 3757.8784 - val_mae: 34.1011\n",
      "Epoch 1531/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 358.6181 - mae: 10.9680 - val_loss: 3723.4910 - val_mae: 34.3348\n",
      "Epoch 1532/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 299.9506 - mae: 10.5549 - val_loss: 3752.0818 - val_mae: 34.1927\n",
      "Epoch 1533/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.8740 - mae: 10.6313 - val_loss: 3688.0623 - val_mae: 34.3660\n",
      "Epoch 1534/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 330.8997 - mae: 10.7057 - val_loss: 3715.5339 - val_mae: 34.2025\n",
      "Epoch 1535/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.9612 - mae: 10.8588 - val_loss: 3771.0852 - val_mae: 34.5804\n",
      "Epoch 1536/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 444.1033 - mae: 11.3411 - val_loss: 3722.2896 - val_mae: 34.3845\n",
      "Epoch 1537/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 348.6677 - mae: 11.3072 - val_loss: 3718.1418 - val_mae: 35.2487\n",
      "Epoch 1538/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.4794 - mae: 10.5904 - val_loss: 3812.9795 - val_mae: 35.0196\n",
      "Epoch 1539/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 309.6829 - mae: 10.3318 - val_loss: 3901.4182 - val_mae: 35.5099\n",
      "Epoch 1540/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.0039 - mae: 10.4550 - val_loss: 3878.6519 - val_mae: 34.7712\n",
      "Epoch 1541/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.7783 - mae: 10.5700 - val_loss: 3960.6162 - val_mae: 34.9764\n",
      "Epoch 1542/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 325.4868 - mae: 10.4837 - val_loss: 3960.4478 - val_mae: 35.4264\n",
      "Epoch 1543/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 355.6015 - mae: 10.7332 - val_loss: 3914.9421 - val_mae: 35.4054\n",
      "Epoch 1544/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 332.1215 - mae: 10.8278 - val_loss: 3871.8823 - val_mae: 35.0297\n",
      "Epoch 1545/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 329.8963 - mae: 10.3579 - val_loss: 3895.8162 - val_mae: 35.1333\n",
      "Epoch 1546/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.0030 - mae: 10.2134 - val_loss: 3810.6970 - val_mae: 34.7737\n",
      "Epoch 1547/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 308.1775 - mae: 10.4054 - val_loss: 3861.4912 - val_mae: 35.1073\n",
      "Epoch 1548/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 325.8743 - mae: 10.3801 - val_loss: 3898.2812 - val_mae: 34.9869\n",
      "Epoch 1549/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.2621 - mae: 10.3126 - val_loss: 3972.1641 - val_mae: 35.1399\n",
      "Epoch 1550/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.1811 - mae: 10.1298 - val_loss: 3828.7483 - val_mae: 35.4349\n",
      "Epoch 1551/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 408.7986 - mae: 11.0407 - val_loss: 3691.4834 - val_mae: 34.7323\n",
      "Epoch 1552/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 305.2588 - mae: 10.3002 - val_loss: 3910.3672 - val_mae: 35.1181\n",
      "Epoch 1553/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 398.6378 - mae: 11.0518 - val_loss: 3831.3621 - val_mae: 34.8401\n",
      "Epoch 1554/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.4918 - mae: 10.5111 - val_loss: 3769.0447 - val_mae: 34.7509\n",
      "Epoch 1555/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 283.4931 - mae: 9.9552 - val_loss: 3883.5251 - val_mae: 34.8771\n",
      "Epoch 1556/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 313.2942 - mae: 10.5363 - val_loss: 3880.8894 - val_mae: 34.8119\n",
      "Epoch 1557/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 361.1697 - mae: 10.7106 - val_loss: 3835.9668 - val_mae: 34.6438\n",
      "Epoch 1558/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 309.9008 - mae: 10.3215 - val_loss: 3872.0527 - val_mae: 34.8250\n",
      "Epoch 1559/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 306.2142 - mae: 10.2142 - val_loss: 3942.3462 - val_mae: 35.0733\n",
      "Epoch 1560/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 298.6404 - mae: 10.2394 - val_loss: 3838.5850 - val_mae: 34.4300\n",
      "Epoch 1561/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 304.5887 - mae: 10.2289 - val_loss: 3848.8301 - val_mae: 34.6615\n",
      "Epoch 1562/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 329.3785 - mae: 10.4922 - val_loss: 3775.6594 - val_mae: 34.0795\n",
      "Epoch 1563/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 540.7783 - mae: 11.0918 - val_loss: 3897.5305 - val_mae: 34.3855\n",
      "Epoch 1564/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 330.4113 - mae: 10.4739 - val_loss: 3767.0452 - val_mae: 34.4278\n",
      "Epoch 1565/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 336.9978 - mae: 10.5925 - val_loss: 3831.8501 - val_mae: 34.5530\n",
      "Epoch 1566/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 328.3304 - mae: 10.3887 - val_loss: 3839.0317 - val_mae: 34.4227\n",
      "Epoch 1567/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.1946 - mae: 10.4073 - val_loss: 3797.9221 - val_mae: 34.8331\n",
      "Epoch 1568/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 327.5410 - mae: 10.3423 - val_loss: 3724.4243 - val_mae: 34.2638\n",
      "Epoch 1569/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 345.0992 - mae: 10.6494 - val_loss: 3908.5920 - val_mae: 35.8546\n",
      "Epoch 1570/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 344.6270 - mae: 10.4061 - val_loss: 3791.2859 - val_mae: 34.5830\n",
      "Epoch 1571/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.9683 - mae: 10.0929 - val_loss: 3861.9297 - val_mae: 34.7408\n",
      "Epoch 1572/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 334.2420 - mae: 10.5682 - val_loss: 3761.2195 - val_mae: 34.4338\n",
      "Epoch 1573/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 316.7867 - mae: 10.2776 - val_loss: 3803.2959 - val_mae: 34.3938\n",
      "Epoch 1574/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.2189 - mae: 10.2224 - val_loss: 3809.4844 - val_mae: 34.8269\n",
      "Epoch 1575/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 353.9286 - mae: 10.4682 - val_loss: 3878.1287 - val_mae: 34.8858\n",
      "Epoch 1576/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 318.5797 - mae: 10.2869 - val_loss: 3792.7515 - val_mae: 33.9662\n",
      "Epoch 1577/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 408.6972 - mae: 11.0700 - val_loss: 3789.5979 - val_mae: 33.9400\n",
      "Epoch 1578/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.5739 - mae: 10.3209 - val_loss: 3823.9883 - val_mae: 34.4136\n",
      "Epoch 1579/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 377.8779 - mae: 10.5310 - val_loss: 3758.7317 - val_mae: 33.7724\n",
      "Epoch 1580/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 368.2591 - mae: 10.7340 - val_loss: 3794.2441 - val_mae: 34.3956\n",
      "Epoch 1581/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 415.0827 - mae: 10.9763 - val_loss: 3766.9558 - val_mae: 34.4642\n",
      "Epoch 1582/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.5532 - mae: 10.7522 - val_loss: 3802.0757 - val_mae: 35.8913\n",
      "Epoch 1583/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 329.9066 - mae: 11.2369 - val_loss: 3793.4980 - val_mae: 34.0893\n",
      "Epoch 1584/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 329.0557 - mae: 10.4933 - val_loss: 3808.4917 - val_mae: 35.0480\n",
      "Epoch 1585/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 338.9236 - mae: 10.6856 - val_loss: 3857.4749 - val_mae: 34.0969\n",
      "Epoch 1586/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 366.9161 - mae: 10.7956 - val_loss: 3819.3740 - val_mae: 34.7248\n",
      "Epoch 1587/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 343.6898 - mae: 10.6400 - val_loss: 3693.2000 - val_mae: 34.0280\n",
      "Epoch 1588/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 366.7885 - mae: 10.9324 - val_loss: 3758.2346 - val_mae: 34.5825\n",
      "Epoch 1589/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 377.0259 - mae: 11.0066 - val_loss: 3716.5945 - val_mae: 34.2576\n",
      "Epoch 1590/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 326.5623 - mae: 10.4473 - val_loss: 3642.8230 - val_mae: 34.2872\n",
      "Epoch 1591/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.9673 - mae: 10.4855 - val_loss: 3703.0542 - val_mae: 34.0682\n",
      "Epoch 1592/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 318.4356 - mae: 10.1161 - val_loss: 3689.3091 - val_mae: 34.2411\n",
      "Epoch 1593/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 355.4559 - mae: 10.5827 - val_loss: 3789.4883 - val_mae: 34.3208\n",
      "Epoch 1594/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 370.3574 - mae: 10.9408 - val_loss: 3754.1082 - val_mae: 34.6804\n",
      "Epoch 1595/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 343.9914 - mae: 10.7655 - val_loss: 3749.0801 - val_mae: 34.4428\n",
      "Epoch 1596/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 347.3879 - mae: 10.7692 - val_loss: 3681.7585 - val_mae: 34.2847\n",
      "Epoch 1597/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 331.7448 - mae: 10.3730 - val_loss: 3696.5991 - val_mae: 34.9935\n",
      "Epoch 1598/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 352.7567 - mae: 10.6075 - val_loss: 3935.6616 - val_mae: 34.8937\n",
      "Epoch 1599/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 318.2977 - mae: 10.2390 - val_loss: 3811.3916 - val_mae: 35.0560\n",
      "Epoch 1600/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 350.9843 - mae: 10.6186 - val_loss: 3855.6235 - val_mae: 34.9274\n",
      "Epoch 1601/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 363.6822 - mae: 10.7763 - val_loss: 3744.3284 - val_mae: 34.3754\n",
      "Epoch 1602/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 333.0794 - mae: 10.5744 - val_loss: 3711.3311 - val_mae: 34.3264\n",
      "Epoch 1603/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 307.6727 - mae: 10.3675 - val_loss: 3843.1038 - val_mae: 34.9343\n",
      "Epoch 1604/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 325.8611 - mae: 10.4022 - val_loss: 3962.7732 - val_mae: 35.1164\n",
      "Epoch 1605/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 327.0909 - mae: 10.3873 - val_loss: 3814.8469 - val_mae: 34.7875\n",
      "Epoch 1606/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 321.4454 - mae: 10.2132 - val_loss: 3763.9756 - val_mae: 34.3270\n",
      "Epoch 1607/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 317.2872 - mae: 10.1567 - val_loss: 3750.0913 - val_mae: 34.7568\n",
      "Epoch 1608/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 358.6108 - mae: 10.5542 - val_loss: 3858.3352 - val_mae: 35.0078\n",
      "Epoch 1609/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 339.4373 - mae: 10.4962 - val_loss: 3801.7578 - val_mae: 34.5652\n",
      "Epoch 1610/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 318.5114 - mae: 10.3047 - val_loss: 3888.5249 - val_mae: 34.5166\n",
      "Epoch 1611/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 353.1331 - mae: 10.4928 - val_loss: 4009.9829 - val_mae: 35.2935\n",
      "Epoch 1612/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 364.3890 - mae: 10.4399 - val_loss: 3895.0457 - val_mae: 35.1120\n",
      "Epoch 1613/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.4371 - mae: 10.0864 - val_loss: 3841.3384 - val_mae: 35.1347\n",
      "Epoch 1614/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 339.6844 - mae: 10.4716 - val_loss: 3669.6062 - val_mae: 33.7861\n",
      "Epoch 1615/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 312.9249 - mae: 10.3195 - val_loss: 3808.6506 - val_mae: 34.1490\n",
      "Epoch 1616/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.1673 - mae: 10.2561 - val_loss: 3897.8376 - val_mae: 34.7271\n",
      "Epoch 1617/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 300.9957 - mae: 10.2173 - val_loss: 3830.6243 - val_mae: 34.9550\n",
      "Epoch 1618/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 310.7335 - mae: 10.2899 - val_loss: 3855.3176 - val_mae: 34.5322\n",
      "Epoch 1619/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.8021 - mae: 10.0430 - val_loss: 4034.2588 - val_mae: 35.2355\n",
      "Epoch 1620/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.3354 - mae: 9.9437 - val_loss: 3824.4756 - val_mae: 34.2886\n",
      "Epoch 1621/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.8415 - mae: 10.0903 - val_loss: 3728.9856 - val_mae: 34.1871\n",
      "Epoch 1622/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 303.7815 - mae: 10.0290 - val_loss: 3850.0398 - val_mae: 34.5504\n",
      "Epoch 1623/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 340.0146 - mae: 10.5676 - val_loss: 3872.7585 - val_mae: 34.8407\n",
      "Epoch 1624/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.8161 - mae: 10.3979 - val_loss: 3906.7388 - val_mae: 34.3756\n",
      "Epoch 1625/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 326.5618 - mae: 10.3062 - val_loss: 3773.8152 - val_mae: 34.8832\n",
      "Epoch 1626/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 349.4344 - mae: 10.8044 - val_loss: 3831.9602 - val_mae: 34.5754\n",
      "Epoch 1627/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 353.0651 - mae: 10.5909 - val_loss: 3920.1184 - val_mae: 34.9038\n",
      "Epoch 1628/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 327.7601 - mae: 10.6495 - val_loss: 3816.0979 - val_mae: 34.3569\n",
      "Epoch 1629/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 372.3151 - mae: 10.8316 - val_loss: 3906.3364 - val_mae: 34.4040\n",
      "Epoch 1630/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 301.9848 - mae: 10.1795 - val_loss: 3842.4922 - val_mae: 34.2220\n",
      "Epoch 1631/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 357.3524 - mae: 10.8001 - val_loss: 3764.6477 - val_mae: 34.2685\n",
      "Epoch 1632/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 368.4245 - mae: 10.4850 - val_loss: 3705.1855 - val_mae: 34.2564\n",
      "Epoch 1633/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 342.4395 - mae: 12.0075 - val_loss: 3903.2363 - val_mae: 35.4599\n",
      "Epoch 1634/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 307.2575 - mae: 11.1953 - val_loss: 3821.8806 - val_mae: 35.3742\n",
      "Epoch 1635/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 336.9144 - mae: 11.3587 - val_loss: 3804.4272 - val_mae: 35.3417\n",
      "Epoch 1636/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 356.9149 - mae: 11.4672 - val_loss: 3683.1748 - val_mae: 35.0263\n",
      "Epoch 1637/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 338.3268 - mae: 11.3529 - val_loss: 3766.9548 - val_mae: 35.4130\n",
      "Epoch 1638/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 371.0792 - mae: 11.5660 - val_loss: 3833.6042 - val_mae: 35.5414\n",
      "Epoch 1639/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 376.4305 - mae: 11.5345 - val_loss: 3714.1692 - val_mae: 34.7217\n",
      "Epoch 1640/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 404.9381 - mae: 11.8611 - val_loss: 3693.3276 - val_mae: 35.0327\n",
      "Epoch 1641/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 354.3591 - mae: 11.3519 - val_loss: 3762.7634 - val_mae: 35.0053\n",
      "Epoch 1642/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 348.6698 - mae: 11.1991 - val_loss: 3777.4224 - val_mae: 35.0594\n",
      "Epoch 1643/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 321.5602 - mae: 10.9133 - val_loss: 3806.0247 - val_mae: 34.6986\n",
      "Epoch 1644/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 321.0331 - mae: 10.7714 - val_loss: 3870.6064 - val_mae: 34.8689\n",
      "Epoch 1645/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 378.6517 - mae: 10.8926 - val_loss: 3933.3521 - val_mae: 35.0259\n",
      "Epoch 1646/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 400.8950 - mae: 11.3080 - val_loss: 3845.0815 - val_mae: 34.1862\n",
      "Epoch 1647/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 330.2872 - mae: 10.9527 - val_loss: 3854.1191 - val_mae: 34.9140\n",
      "Epoch 1648/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 351.2130 - mae: 11.0746 - val_loss: 3853.2271 - val_mae: 34.9178\n",
      "Epoch 1649/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.4631 - mae: 10.7093 - val_loss: 3750.8411 - val_mae: 34.3523\n",
      "Epoch 1650/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 317.8433 - mae: 10.5347 - val_loss: 3792.4622 - val_mae: 34.7683\n",
      "Epoch 1651/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 331.8105 - mae: 10.5667 - val_loss: 3801.3430 - val_mae: 34.3592\n",
      "Epoch 1652/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 319.8112 - mae: 10.3863 - val_loss: 3789.6965 - val_mae: 34.3773\n",
      "Epoch 1653/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.1557 - mae: 9.9089 - val_loss: 3854.7488 - val_mae: 34.4989\n",
      "Epoch 1654/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 322.2924 - mae: 10.1770 - val_loss: 3826.7954 - val_mae: 34.2109\n",
      "Epoch 1655/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 343.7257 - mae: 10.3199 - val_loss: 3717.6633 - val_mae: 33.3617\n",
      "Epoch 1656/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 328.2287 - mae: 10.2812 - val_loss: 3771.7668 - val_mae: 33.6704\n",
      "Epoch 1657/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.6347 - mae: 10.3675 - val_loss: 3773.7498 - val_mae: 34.2304\n",
      "Epoch 1658/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 350.4919 - mae: 10.5158 - val_loss: 3860.7341 - val_mae: 34.5696\n",
      "Epoch 1659/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 326.9816 - mae: 10.3075 - val_loss: 3774.5371 - val_mae: 34.1554\n",
      "Epoch 1660/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 352.1339 - mae: 10.5414 - val_loss: 3834.7942 - val_mae: 34.5649\n",
      "Epoch 1661/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.3215 - mae: 9.8472 - val_loss: 3740.3013 - val_mae: 34.3660\n",
      "Epoch 1662/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.4550 - mae: 9.8675 - val_loss: 3814.2388 - val_mae: 34.4543\n",
      "Epoch 1663/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 325.7002 - mae: 10.2621 - val_loss: 3818.4880 - val_mae: 34.8820\n",
      "Epoch 1664/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 322.2104 - mae: 10.0976 - val_loss: 3674.1008 - val_mae: 34.0064\n",
      "Epoch 1665/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.7295 - mae: 10.3086 - val_loss: 3751.4148 - val_mae: 34.2863\n",
      "Epoch 1666/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 379.7056 - mae: 10.5649 - val_loss: 3805.9377 - val_mae: 34.6596\n",
      "Epoch 1667/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 358.7231 - mae: 10.5334 - val_loss: 3853.5864 - val_mae: 34.7763\n",
      "Epoch 1668/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 296.1565 - mae: 10.0832 - val_loss: 3757.0598 - val_mae: 34.2952\n",
      "Epoch 1669/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 303.8120 - mae: 10.0936 - val_loss: 3730.5156 - val_mae: 34.3193\n",
      "Epoch 1670/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 323.8275 - mae: 10.1449 - val_loss: 3769.3154 - val_mae: 34.5815\n",
      "Epoch 1671/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 296.8552 - mae: 10.0665 - val_loss: 3765.2192 - val_mae: 34.4423\n",
      "Epoch 1672/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 320.3178 - mae: 10.1339 - val_loss: 3779.5862 - val_mae: 34.2219\n",
      "Epoch 1673/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.6101 - mae: 9.8126 - val_loss: 3740.4268 - val_mae: 33.8459\n",
      "Epoch 1674/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 309.1797 - mae: 10.0641 - val_loss: 3805.6343 - val_mae: 34.1118\n",
      "Epoch 1675/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 312.3621 - mae: 10.1075 - val_loss: 3775.7971 - val_mae: 34.4654\n",
      "Epoch 1676/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.3281 - mae: 10.0927 - val_loss: 3745.9983 - val_mae: 33.7009\n",
      "Epoch 1677/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 305.1646 - mae: 9.9941 - val_loss: 3739.1536 - val_mae: 33.5121\n",
      "Epoch 1678/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 332.1806 - mae: 10.3126 - val_loss: 3785.5544 - val_mae: 34.2784\n",
      "Epoch 1679/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 277.3296 - mae: 9.9824 - val_loss: 3733.3867 - val_mae: 33.9810\n",
      "Epoch 1680/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 317.7784 - mae: 10.1592 - val_loss: 3732.7573 - val_mae: 34.0674\n",
      "Epoch 1681/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 301.0613 - mae: 9.9265 - val_loss: 3758.1045 - val_mae: 34.0509\n",
      "Epoch 1682/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 304.5063 - mae: 10.0674 - val_loss: 3784.3083 - val_mae: 34.0067\n",
      "Epoch 1683/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 327.8505 - mae: 10.2735 - val_loss: 3812.0613 - val_mae: 34.5751\n",
      "Epoch 1684/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.8271 - mae: 9.7730 - val_loss: 3742.1362 - val_mae: 34.2211\n",
      "Epoch 1685/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 298.4312 - mae: 9.9517 - val_loss: 3849.1660 - val_mae: 34.5967\n",
      "Epoch 1686/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.8817 - mae: 9.5142 - val_loss: 3835.7107 - val_mae: 34.8029\n",
      "Epoch 1687/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.3198 - mae: 9.9604 - val_loss: 3898.0466 - val_mae: 34.8206\n",
      "Epoch 1688/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 336.3250 - mae: 10.2627 - val_loss: 3756.4639 - val_mae: 33.8311\n",
      "Epoch 1689/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 317.0130 - mae: 10.1563 - val_loss: 3899.2109 - val_mae: 34.6442\n",
      "Epoch 1690/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.7676 - mae: 10.0191 - val_loss: 3845.5991 - val_mae: 35.0941\n",
      "Epoch 1691/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.1497 - mae: 9.8514 - val_loss: 3778.4780 - val_mae: 34.7116\n",
      "Epoch 1692/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 320.6178 - mae: 10.2147 - val_loss: 3849.2278 - val_mae: 34.7082\n",
      "Epoch 1693/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.3500 - mae: 9.8573 - val_loss: 3845.8503 - val_mae: 34.7521\n",
      "Epoch 1694/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 378.1868 - mae: 10.5157 - val_loss: 3938.1846 - val_mae: 35.2301\n",
      "Epoch 1695/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 325.1773 - mae: 10.3189 - val_loss: 3787.7568 - val_mae: 34.7117\n",
      "Epoch 1696/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.6333 - mae: 10.2806 - val_loss: 3782.7639 - val_mae: 34.6372\n",
      "Epoch 1697/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.3065 - mae: 10.1887 - val_loss: 3813.1931 - val_mae: 34.7553\n",
      "Epoch 1698/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 348.3713 - mae: 10.4819 - val_loss: 3761.2422 - val_mae: 34.6052\n",
      "Epoch 1699/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 330.6333 - mae: 10.3055 - val_loss: 3788.9653 - val_mae: 34.2599\n",
      "Epoch 1700/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.7992 - mae: 9.9913 - val_loss: 3790.8240 - val_mae: 33.9692\n",
      "Epoch 1701/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 288.6460 - mae: 9.9825 - val_loss: 3882.5840 - val_mae: 34.7824\n",
      "Epoch 1702/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 305.4514 - mae: 10.0217 - val_loss: 3758.6582 - val_mae: 34.1317\n",
      "Epoch 1703/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 344.6227 - mae: 10.3185 - val_loss: 3773.6438 - val_mae: 34.4623\n",
      "Epoch 1704/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 309.0239 - mae: 10.0465 - val_loss: 3893.2280 - val_mae: 35.4685\n",
      "Epoch 1705/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.2955 - mae: 9.6644 - val_loss: 3899.2673 - val_mae: 35.1704\n",
      "Epoch 1706/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.0877 - mae: 10.1398 - val_loss: 3866.4043 - val_mae: 34.9704\n",
      "Epoch 1707/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 311.0270 - mae: 10.1231 - val_loss: 3871.8445 - val_mae: 35.1736\n",
      "Epoch 1708/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.7525 - mae: 9.9085 - val_loss: 3934.0779 - val_mae: 35.1790\n",
      "Epoch 1709/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 325.6480 - mae: 10.3575 - val_loss: 3791.4197 - val_mae: 35.0242\n",
      "Epoch 1710/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 342.0344 - mae: 10.4197 - val_loss: 4004.0559 - val_mae: 36.0179\n",
      "Epoch 1711/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 314.6972 - mae: 10.1102 - val_loss: 3966.0701 - val_mae: 35.2573\n",
      "Epoch 1712/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 328.7826 - mae: 10.6725 - val_loss: 3795.2231 - val_mae: 34.8417\n",
      "Epoch 1713/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 346.6833 - mae: 10.4236 - val_loss: 3829.2114 - val_mae: 35.1770\n",
      "Epoch 1714/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 335.0518 - mae: 10.5896 - val_loss: 3801.6301 - val_mae: 34.7562\n",
      "Epoch 1715/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 330.1224 - mae: 10.3015 - val_loss: 3896.8271 - val_mae: 35.0295\n",
      "Epoch 1716/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 319.2968 - mae: 10.1141 - val_loss: 3858.7988 - val_mae: 34.6824\n",
      "Epoch 1717/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 291.4265 - mae: 9.9751 - val_loss: 3829.4546 - val_mae: 35.9629\n",
      "Epoch 1718/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 322.0785 - mae: 10.5742 - val_loss: 3823.7834 - val_mae: 35.3087\n",
      "Epoch 1719/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 322.6584 - mae: 10.3043 - val_loss: 3808.6929 - val_mae: 34.9137\n",
      "Epoch 1720/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 283.1879 - mae: 10.1054 - val_loss: 3847.3945 - val_mae: 35.2458\n",
      "Epoch 1721/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 352.8363 - mae: 10.4868 - val_loss: 3874.5222 - val_mae: 35.2150\n",
      "Epoch 1722/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 320.1483 - mae: 10.4439 - val_loss: 3812.4980 - val_mae: 34.6401\n",
      "Epoch 1723/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.0262 - mae: 9.7107 - val_loss: 3858.4106 - val_mae: 35.2542\n",
      "Epoch 1724/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 314.5384 - mae: 10.2803 - val_loss: 3857.6616 - val_mae: 34.8410\n",
      "Epoch 1725/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 288.1464 - mae: 9.8390 - val_loss: 3877.5061 - val_mae: 34.8715\n",
      "Epoch 1726/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.7741 - mae: 9.9251 - val_loss: 4051.8171 - val_mae: 35.6674\n",
      "Epoch 1727/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.1939 - mae: 10.2617 - val_loss: 4018.2715 - val_mae: 35.3583\n",
      "Epoch 1728/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 320.8911 - mae: 10.1058 - val_loss: 3870.2800 - val_mae: 34.7006\n",
      "Epoch 1729/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 283.3903 - mae: 9.8520 - val_loss: 3955.7371 - val_mae: 35.9130\n",
      "Epoch 1730/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 295.4176 - mae: 9.9547 - val_loss: 3878.7368 - val_mae: 35.7427\n",
      "Epoch 1731/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 333.7417 - mae: 10.0957 - val_loss: 3975.8518 - val_mae: 35.1611\n",
      "Epoch 1732/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 309.8195 - mae: 10.0670 - val_loss: 3980.8057 - val_mae: 35.3007\n",
      "Epoch 1733/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.5338 - mae: 10.0005 - val_loss: 4085.4766 - val_mae: 35.9969\n",
      "Epoch 1734/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 412.7594 - mae: 10.9995 - val_loss: 4013.0703 - val_mae: 36.2086\n",
      "Epoch 1735/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 352.0831 - mae: 10.4873 - val_loss: 3913.8000 - val_mae: 35.5085\n",
      "Epoch 1736/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 346.1456 - mae: 10.4871 - val_loss: 3812.3801 - val_mae: 34.8637\n",
      "Epoch 1737/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 319.3801 - mae: 10.2296 - val_loss: 3869.6465 - val_mae: 35.0288\n",
      "Epoch 1738/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.5760 - mae: 9.9389 - val_loss: 3872.1462 - val_mae: 34.9145\n",
      "Epoch 1739/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 354.0729 - mae: 10.5652 - val_loss: 3957.8860 - val_mae: 34.9851\n",
      "Epoch 1740/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 323.2470 - mae: 10.2720 - val_loss: 3854.3894 - val_mae: 34.9541\n",
      "Epoch 1741/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 304.7869 - mae: 10.2970 - val_loss: 3909.1392 - val_mae: 35.1420\n",
      "Epoch 1742/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.3467 - mae: 9.9238 - val_loss: 4032.2019 - val_mae: 35.3872\n",
      "Epoch 1743/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.3514 - mae: 9.9490 - val_loss: 3877.0217 - val_mae: 34.6478\n",
      "Epoch 1744/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.6049 - mae: 9.7360 - val_loss: 3777.4207 - val_mae: 33.7993\n",
      "Epoch 1745/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.3338 - mae: 9.9059 - val_loss: 3839.1230 - val_mae: 34.2653\n",
      "Epoch 1746/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 301.3383 - mae: 9.9323 - val_loss: 3828.0603 - val_mae: 34.3266\n",
      "Epoch 1747/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.7581 - mae: 10.1068 - val_loss: 3807.2893 - val_mae: 34.5059\n",
      "Epoch 1748/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 326.3931 - mae: 10.1494 - val_loss: 3807.8113 - val_mae: 33.9047\n",
      "Epoch 1749/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.4045 - mae: 10.2461 - val_loss: 3880.8904 - val_mae: 34.4920\n",
      "Epoch 1750/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 351.5105 - mae: 10.4661 - val_loss: 3846.1885 - val_mae: 34.6622\n",
      "Epoch 1751/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 353.0913 - mae: 10.3697 - val_loss: 3816.6284 - val_mae: 34.6342\n",
      "Epoch 1752/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 348.9355 - mae: 10.6411 - val_loss: 3761.6287 - val_mae: 34.1940\n",
      "Epoch 1753/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.2652 - mae: 10.1298 - val_loss: 3705.2305 - val_mae: 34.2139\n",
      "Epoch 1754/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 323.2642 - mae: 10.3769 - val_loss: 3766.9766 - val_mae: 33.7681\n",
      "Epoch 1755/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.3290 - mae: 10.1009 - val_loss: 3775.0835 - val_mae: 34.4667\n",
      "Epoch 1756/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 312.0880 - mae: 10.3078 - val_loss: 3837.6843 - val_mae: 34.6373\n",
      "Epoch 1757/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 283.5274 - mae: 10.0575 - val_loss: 3944.8669 - val_mae: 35.1429\n",
      "Epoch 1758/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 364.1301 - mae: 10.5818 - val_loss: 3861.7671 - val_mae: 34.6287\n",
      "Epoch 1759/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 351.9205 - mae: 10.4807 - val_loss: 3866.3342 - val_mae: 35.0904\n",
      "Epoch 1760/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 350.7583 - mae: 10.6484 - val_loss: 4099.0757 - val_mae: 35.5159\n",
      "Epoch 1761/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 342.4943 - mae: 10.4254 - val_loss: 3991.0540 - val_mae: 35.6571\n",
      "Epoch 1762/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 324.1804 - mae: 10.1891 - val_loss: 3977.7964 - val_mae: 35.1736\n",
      "Epoch 1763/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.6937 - mae: 9.8791 - val_loss: 4135.0063 - val_mae: 36.0976\n",
      "Epoch 1764/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 333.2719 - mae: 10.4633 - val_loss: 4062.5935 - val_mae: 35.8327\n",
      "Epoch 1765/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 316.3729 - mae: 10.2162 - val_loss: 3922.1047 - val_mae: 34.9581\n",
      "Epoch 1766/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.7567 - mae: 10.2140 - val_loss: 3917.6035 - val_mae: 35.2511\n",
      "Epoch 1767/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.6675 - mae: 9.9645 - val_loss: 3862.3159 - val_mae: 34.7421\n",
      "Epoch 1768/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.3615 - mae: 10.0568 - val_loss: 3833.1548 - val_mae: 34.6474\n",
      "Epoch 1769/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.3804 - mae: 9.7876 - val_loss: 3863.2244 - val_mae: 35.2733\n",
      "Epoch 1770/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.5903 - mae: 9.9647 - val_loss: 3993.3831 - val_mae: 35.5754\n",
      "Epoch 1771/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.6508 - mae: 10.4160 - val_loss: 3920.4932 - val_mae: 34.1191\n",
      "Epoch 1772/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 304.8728 - mae: 10.1741 - val_loss: 3922.7581 - val_mae: 34.5644\n",
      "Epoch 1773/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 335.4630 - mae: 10.3117 - val_loss: 3786.4131 - val_mae: 34.1151\n",
      "Epoch 1774/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 345.9738 - mae: 10.3069 - val_loss: 3862.6587 - val_mae: 34.2725\n",
      "Epoch 1775/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.6360 - mae: 9.7628 - val_loss: 3812.2917 - val_mae: 34.1332\n",
      "Epoch 1776/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.4795 - mae: 9.4299 - val_loss: 3956.1780 - val_mae: 34.6829\n",
      "Epoch 1777/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 305.1530 - mae: 9.8860 - val_loss: 3895.6926 - val_mae: 34.4864\n",
      "Epoch 1778/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.3309 - mae: 9.7999 - val_loss: 3753.0437 - val_mae: 34.1181\n",
      "Epoch 1779/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.0574 - mae: 9.3877 - val_loss: 3800.0105 - val_mae: 34.9360\n",
      "Epoch 1780/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 244.5065 - mae: 9.4215 - val_loss: 3817.1306 - val_mae: 34.3992\n",
      "Epoch 1781/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 298.2501 - mae: 10.0689 - val_loss: 3937.9229 - val_mae: 35.3555\n",
      "Epoch 1782/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.7809 - mae: 9.7708 - val_loss: 3907.9583 - val_mae: 35.0694\n",
      "Epoch 1783/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.3589 - mae: 9.8380 - val_loss: 3873.9041 - val_mae: 35.0649\n",
      "Epoch 1784/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 310.5065 - mae: 9.9032 - val_loss: 3844.0447 - val_mae: 35.0186\n",
      "Epoch 1785/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 324.0064 - mae: 10.2022 - val_loss: 3818.4756 - val_mae: 35.0209\n",
      "Epoch 1786/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.1439 - mae: 9.6234 - val_loss: 3922.3577 - val_mae: 34.9436\n",
      "Epoch 1787/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.4080 - mae: 9.7299 - val_loss: 3851.2871 - val_mae: 35.0054\n",
      "Epoch 1788/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.6414 - mae: 9.8425 - val_loss: 3799.1406 - val_mae: 34.5501\n",
      "Epoch 1789/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 321.1561 - mae: 10.1026 - val_loss: 3887.2051 - val_mae: 34.7151\n",
      "Epoch 1790/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.8076 - mae: 9.9938 - val_loss: 3699.0098 - val_mae: 34.1355\n",
      "Epoch 1791/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.2043 - mae: 9.9512 - val_loss: 3813.4805 - val_mae: 34.4846\n",
      "Epoch 1792/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.6470 - mae: 10.3469 - val_loss: 3801.9216 - val_mae: 34.4758\n",
      "Epoch 1793/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.2434 - mae: 9.8935 - val_loss: 3788.8743 - val_mae: 34.3510\n",
      "Epoch 1794/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 299.9704 - mae: 10.1114 - val_loss: 3794.9490 - val_mae: 34.3278\n",
      "Epoch 1795/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 273.8184 - mae: 9.7175 - val_loss: 3840.4167 - val_mae: 35.1110\n",
      "Epoch 1796/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 302.5053 - mae: 10.0483 - val_loss: 3767.3005 - val_mae: 34.0248\n",
      "Epoch 1797/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 311.9705 - mae: 10.2639 - val_loss: 3759.5864 - val_mae: 34.5132\n",
      "Epoch 1798/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 317.8060 - mae: 10.1911 - val_loss: 3892.1218 - val_mae: 35.2054\n",
      "Epoch 1799/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 334.8365 - mae: 10.2375 - val_loss: 3790.2646 - val_mae: 35.2155\n",
      "Epoch 1800/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.3249 - mae: 10.6071 - val_loss: 3894.7639 - val_mae: 34.5488\n",
      "Epoch 1801/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.6713 - mae: 10.3096 - val_loss: 3879.5447 - val_mae: 35.4334\n",
      "Epoch 1802/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 355.0838 - mae: 10.4655 - val_loss: 3802.9255 - val_mae: 34.8359\n",
      "Epoch 1803/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.1737 - mae: 9.8400 - val_loss: 3944.7749 - val_mae: 35.1639\n",
      "Epoch 1804/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 340.1165 - mae: 10.3254 - val_loss: 3813.8113 - val_mae: 34.9816\n",
      "Epoch 1805/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 343.3981 - mae: 10.6688 - val_loss: 3779.5654 - val_mae: 34.3324\n",
      "Epoch 1806/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 341.8957 - mae: 10.4222 - val_loss: 3825.1936 - val_mae: 34.8469\n",
      "Epoch 1807/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 314.3941 - mae: 10.2692 - val_loss: 3904.0864 - val_mae: 34.9998\n",
      "Epoch 1808/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 322.9731 - mae: 10.2901 - val_loss: 3831.4248 - val_mae: 34.4718\n",
      "Epoch 1809/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 330.8447 - mae: 10.4123 - val_loss: 3807.6614 - val_mae: 34.2974\n",
      "Epoch 1810/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.4061 - mae: 9.8005 - val_loss: 3780.8369 - val_mae: 34.5455\n",
      "Epoch 1811/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 306.1023 - mae: 9.9847 - val_loss: 3766.5645 - val_mae: 34.2047\n",
      "Epoch 1812/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 309.9344 - mae: 10.0490 - val_loss: 3817.8403 - val_mae: 34.6757\n",
      "Epoch 1813/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.7355 - mae: 10.0394 - val_loss: 3851.4492 - val_mae: 34.9911\n",
      "Epoch 1814/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 322.6866 - mae: 10.1074 - val_loss: 3883.9043 - val_mae: 34.3663\n",
      "Epoch 1815/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 375.8392 - mae: 10.4600 - val_loss: 3704.1458 - val_mae: 33.7270\n",
      "Epoch 1816/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 304.4952 - mae: 10.0129 - val_loss: 3813.4207 - val_mae: 33.9984\n",
      "Epoch 1817/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.9274 - mae: 9.8915 - val_loss: 3752.9685 - val_mae: 34.1531\n",
      "Epoch 1818/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 340.7198 - mae: 10.3775 - val_loss: 3743.6306 - val_mae: 33.9687\n",
      "Epoch 1819/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 312.0404 - mae: 10.0489 - val_loss: 3797.8340 - val_mae: 34.1123\n",
      "Epoch 1820/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 352.0158 - mae: 10.4081 - val_loss: 3745.8127 - val_mae: 33.9626\n",
      "Epoch 1821/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.5294 - mae: 10.0193 - val_loss: 3689.0879 - val_mae: 34.1492\n",
      "Epoch 1822/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 316.5263 - mae: 10.0323 - val_loss: 3699.5161 - val_mae: 33.9395\n",
      "Epoch 1823/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 331.4271 - mae: 10.0897 - val_loss: 3726.4583 - val_mae: 33.8475\n",
      "Epoch 1824/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 304.7856 - mae: 10.0501 - val_loss: 3717.0012 - val_mae: 33.8509\n",
      "Epoch 1825/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.4134 - mae: 9.8956 - val_loss: 3748.7183 - val_mae: 34.2795\n",
      "Epoch 1826/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 370.7566 - mae: 10.7159 - val_loss: 3792.5776 - val_mae: 34.3004\n",
      "Epoch 1827/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 323.5786 - mae: 10.0963 - val_loss: 3854.2983 - val_mae: 34.7784\n",
      "Epoch 1828/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 341.9630 - mae: 10.2180 - val_loss: 3887.9956 - val_mae: 34.8036\n",
      "Epoch 1829/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.1653 - mae: 9.7923 - val_loss: 3771.1433 - val_mae: 34.5430\n",
      "Epoch 1830/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.3401 - mae: 9.8558 - val_loss: 3773.3193 - val_mae: 34.3153\n",
      "Epoch 1831/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.8244 - mae: 9.9846 - val_loss: 3771.0503 - val_mae: 34.7876\n",
      "Epoch 1832/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 378.6762 - mae: 10.3251 - val_loss: 3817.5188 - val_mae: 34.0641\n",
      "Epoch 1833/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 330.8291 - mae: 10.3394 - val_loss: 3840.6838 - val_mae: 34.7411\n",
      "Epoch 1834/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 303.0968 - mae: 9.8182 - val_loss: 3795.1951 - val_mae: 34.3494\n",
      "Epoch 1835/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.6647 - mae: 9.8719 - val_loss: 3853.8091 - val_mae: 35.0242\n",
      "Epoch 1836/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.8479 - mae: 9.8094 - val_loss: 3753.4495 - val_mae: 34.0739\n",
      "Epoch 1837/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.5348 - mae: 9.5328 - val_loss: 3787.7468 - val_mae: 34.4742\n",
      "Epoch 1838/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.9251 - mae: 9.9633 - val_loss: 3823.6157 - val_mae: 34.7109\n",
      "Epoch 1839/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 339.5662 - mae: 10.3748 - val_loss: 3803.4902 - val_mae: 34.5135\n",
      "Epoch 1840/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.2812 - mae: 9.8395 - val_loss: 3897.0071 - val_mae: 34.7055\n",
      "Epoch 1841/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.3555 - mae: 9.8592 - val_loss: 3948.2637 - val_mae: 35.2083\n",
      "Epoch 1842/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.3253 - mae: 9.8572 - val_loss: 3833.4719 - val_mae: 34.5284\n",
      "Epoch 1843/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.5435 - mae: 10.0920 - val_loss: 3814.9819 - val_mae: 34.7492\n",
      "Epoch 1844/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 283.1706 - mae: 9.8138 - val_loss: 3873.4270 - val_mae: 34.8481\n",
      "Epoch 1845/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 329.3823 - mae: 10.1661 - val_loss: 3913.0867 - val_mae: 34.8026\n",
      "Epoch 1846/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.3111 - mae: 9.8539 - val_loss: 3890.4978 - val_mae: 35.2377\n",
      "Epoch 1847/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 306.1163 - mae: 9.7748 - val_loss: 3972.4783 - val_mae: 35.3869\n",
      "Epoch 1848/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 313.3391 - mae: 9.7181 - val_loss: 3885.4395 - val_mae: 35.0352\n",
      "Epoch 1849/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.2999 - mae: 9.7503 - val_loss: 3943.3855 - val_mae: 34.9911\n",
      "Epoch 1850/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.0146 - mae: 9.7728 - val_loss: 3790.5562 - val_mae: 34.2925\n",
      "Epoch 1851/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 327.3943 - mae: 10.1907 - val_loss: 3756.8069 - val_mae: 34.4769\n",
      "Epoch 1852/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 337.1715 - mae: 10.2624 - val_loss: 3749.5913 - val_mae: 34.5875\n",
      "Epoch 1853/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 277.7802 - mae: 9.8160 - val_loss: 3705.1196 - val_mae: 34.6956\n",
      "Epoch 1854/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.8737 - mae: 10.0974 - val_loss: 3777.8650 - val_mae: 34.4720\n",
      "Epoch 1855/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 313.0376 - mae: 10.1857 - val_loss: 3745.2878 - val_mae: 34.4492\n",
      "Epoch 1856/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 359.0030 - mae: 10.4266 - val_loss: 3682.2039 - val_mae: 33.9752\n",
      "Epoch 1857/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 306.2699 - mae: 10.3797 - val_loss: 3721.3308 - val_mae: 33.9020\n",
      "Epoch 1858/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.3469 - mae: 9.9823 - val_loss: 3840.2258 - val_mae: 34.9335\n",
      "Epoch 1859/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 304.0588 - mae: 10.0386 - val_loss: 3739.5298 - val_mae: 34.1322\n",
      "Epoch 1860/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.4562 - mae: 9.9443 - val_loss: 3717.5784 - val_mae: 34.4066\n",
      "Epoch 1861/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 258.7186 - mae: 9.7128 - val_loss: 3817.2739 - val_mae: 34.1761\n",
      "Epoch 1862/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.2669 - mae: 10.0811 - val_loss: 3777.3398 - val_mae: 34.4058\n",
      "Epoch 1863/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 298.4076 - mae: 9.9628 - val_loss: 3813.9626 - val_mae: 34.4197\n",
      "Epoch 1864/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 286.0422 - mae: 9.8237 - val_loss: 3715.9019 - val_mae: 33.8092\n",
      "Epoch 1865/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.5103 - mae: 9.5888 - val_loss: 3729.2507 - val_mae: 34.7347\n",
      "Epoch 1866/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 294.7917 - mae: 9.8906 - val_loss: 3766.3286 - val_mae: 34.1398\n",
      "Epoch 1867/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.7592 - mae: 9.7493 - val_loss: 3851.5244 - val_mae: 34.9887\n",
      "Epoch 1868/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.5245 - mae: 9.4359 - val_loss: 3889.6121 - val_mae: 35.1835\n",
      "Epoch 1869/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.5883 - mae: 9.5381 - val_loss: 3825.2129 - val_mae: 34.9282\n",
      "Epoch 1870/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.8846 - mae: 9.9680 - val_loss: 3862.5149 - val_mae: 34.2816\n",
      "Epoch 1871/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.3161 - mae: 9.5283 - val_loss: 3865.5779 - val_mae: 35.0760\n",
      "Epoch 1872/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.5817 - mae: 10.2461 - val_loss: 3872.4238 - val_mae: 35.4719\n",
      "Epoch 1873/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 357.2786 - mae: 10.6836 - val_loss: 3792.9595 - val_mae: 34.7210\n",
      "Epoch 1874/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.1060 - mae: 10.4359 - val_loss: 4029.5330 - val_mae: 35.5344\n",
      "Epoch 1875/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.5299 - mae: 9.7371 - val_loss: 3862.0022 - val_mae: 35.4939\n",
      "Epoch 1876/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.5105 - mae: 10.0645 - val_loss: 3718.1895 - val_mae: 34.4331\n",
      "Epoch 1877/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 329.6033 - mae: 10.4135 - val_loss: 3780.7727 - val_mae: 34.6294\n",
      "Epoch 1878/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 354.3429 - mae: 10.3257 - val_loss: 3674.2822 - val_mae: 34.8363\n",
      "Epoch 1879/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 309.2501 - mae: 10.0610 - val_loss: 3869.8384 - val_mae: 34.6187\n",
      "Epoch 1880/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 331.4061 - mae: 10.0518 - val_loss: 3708.4817 - val_mae: 34.5393\n",
      "Epoch 1881/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.8192 - mae: 9.7925 - val_loss: 3716.2305 - val_mae: 34.1761\n",
      "Epoch 1882/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 333.5169 - mae: 10.1292 - val_loss: 3826.3235 - val_mae: 34.7891\n",
      "Epoch 1883/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.5111 - mae: 10.0221 - val_loss: 3995.6167 - val_mae: 35.2780\n",
      "Epoch 1884/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 310.2242 - mae: 9.7610 - val_loss: 3815.4358 - val_mae: 34.8298\n",
      "Epoch 1885/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 344.7380 - mae: 10.4566 - val_loss: 3901.5120 - val_mae: 35.0734\n",
      "Epoch 1886/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 353.7940 - mae: 10.3251 - val_loss: 3906.6213 - val_mae: 35.0344\n",
      "Epoch 1887/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.0139 - mae: 9.8857 - val_loss: 3906.6614 - val_mae: 35.1888\n",
      "Epoch 1888/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.2683 - mae: 9.6280 - val_loss: 3815.3821 - val_mae: 34.6887\n",
      "Epoch 1889/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 302.6412 - mae: 9.8887 - val_loss: 3928.1050 - val_mae: 34.8438\n",
      "Epoch 1890/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 307.6265 - mae: 9.9839 - val_loss: 3816.5781 - val_mae: 34.6432\n",
      "Epoch 1891/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.1233 - mae: 9.4456 - val_loss: 3973.2378 - val_mae: 35.3727\n",
      "Epoch 1892/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.3658 - mae: 9.6728 - val_loss: 3970.1504 - val_mae: 35.4491\n",
      "Epoch 1893/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.8346 - mae: 9.3989 - val_loss: 3882.8740 - val_mae: 35.1633\n",
      "Epoch 1894/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 339.5448 - mae: 10.1977 - val_loss: 3801.8792 - val_mae: 34.3596\n",
      "Epoch 1895/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 306.0742 - mae: 9.9596 - val_loss: 3784.9812 - val_mae: 33.9324\n",
      "Epoch 1896/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 320.2183 - mae: 10.3541 - val_loss: 3875.8660 - val_mae: 34.1433\n",
      "Epoch 1897/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 355.4809 - mae: 10.3950 - val_loss: 3816.6768 - val_mae: 35.1037\n",
      "Epoch 1898/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 356.7500 - mae: 10.6372 - val_loss: 3824.8115 - val_mae: 34.7728\n",
      "Epoch 1899/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.7622 - mae: 10.2645 - val_loss: 3778.1199 - val_mae: 34.4131\n",
      "Epoch 1900/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 326.9087 - mae: 10.3032 - val_loss: 3793.7402 - val_mae: 34.4284\n",
      "Epoch 1901/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 372.8227 - mae: 10.6441 - val_loss: 3812.8589 - val_mae: 33.9949\n",
      "Epoch 1902/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 355.2928 - mae: 10.3055 - val_loss: 3672.7261 - val_mae: 33.1955\n",
      "Epoch 1903/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 304.2237 - mae: 10.1848 - val_loss: 3772.9438 - val_mae: 34.2829\n",
      "Epoch 1904/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 350.1485 - mae: 10.4038 - val_loss: 3642.0486 - val_mae: 33.8056\n",
      "Epoch 1905/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.7792 - mae: 9.8243 - val_loss: 3734.8411 - val_mae: 34.1352\n",
      "Epoch 1906/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.0211 - mae: 10.1364 - val_loss: 3753.1135 - val_mae: 34.0570\n",
      "Epoch 1907/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.5789 - mae: 9.9301 - val_loss: 3864.1929 - val_mae: 34.4796\n",
      "Epoch 1908/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.8411 - mae: 9.6971 - val_loss: 3883.2703 - val_mae: 34.5920\n",
      "Epoch 1909/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.1217 - mae: 9.7189 - val_loss: 3973.4954 - val_mae: 35.0742\n",
      "Epoch 1910/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 316.2913 - mae: 9.9821 - val_loss: 3737.0042 - val_mae: 34.2505\n",
      "Epoch 1911/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.4366 - mae: 9.7331 - val_loss: 3828.7346 - val_mae: 34.4969\n",
      "Epoch 1912/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.8611 - mae: 10.0625 - val_loss: 3864.7505 - val_mae: 34.2300\n",
      "Epoch 1913/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.7315 - mae: 9.4880 - val_loss: 3805.5493 - val_mae: 34.0133\n",
      "Epoch 1914/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.2166 - mae: 9.6358 - val_loss: 3844.4033 - val_mae: 34.6658\n",
      "Epoch 1915/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.8810 - mae: 9.7469 - val_loss: 3809.9883 - val_mae: 34.2542\n",
      "Epoch 1916/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 308.6353 - mae: 10.0009 - val_loss: 3838.0283 - val_mae: 34.4889\n",
      "Epoch 1917/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.9553 - mae: 9.8620 - val_loss: 3874.9128 - val_mae: 34.5786\n",
      "Epoch 1918/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.8724 - mae: 9.6560 - val_loss: 3844.2490 - val_mae: 34.8642\n",
      "Epoch 1919/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 301.0188 - mae: 9.9656 - val_loss: 3828.8384 - val_mae: 34.9541\n",
      "Epoch 1920/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 317.9593 - mae: 9.9385 - val_loss: 3812.4712 - val_mae: 34.9542\n",
      "Epoch 1921/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 302.7044 - mae: 9.8234 - val_loss: 3890.0679 - val_mae: 34.4287\n",
      "Epoch 1922/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 284.8210 - mae: 9.9342 - val_loss: 3963.1167 - val_mae: 35.5939\n",
      "Epoch 1923/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.8902 - mae: 9.8858 - val_loss: 3964.8777 - val_mae: 35.4251\n",
      "Epoch 1924/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 327.9334 - mae: 10.2988 - val_loss: 3893.2573 - val_mae: 35.2726\n",
      "Epoch 1925/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.5282 - mae: 9.7765 - val_loss: 3968.6523 - val_mae: 35.1967\n",
      "Epoch 1926/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.4424 - mae: 9.8796 - val_loss: 3906.1328 - val_mae: 34.6644\n",
      "Epoch 1927/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 316.3052 - mae: 9.9805 - val_loss: 3858.1077 - val_mae: 34.1926\n",
      "Epoch 1928/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 333.0087 - mae: 10.1585 - val_loss: 3800.5972 - val_mae: 34.1845\n",
      "Epoch 1929/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.3478 - mae: 10.0587 - val_loss: 3843.0300 - val_mae: 34.4232\n",
      "Epoch 1930/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 284.3468 - mae: 9.7814 - val_loss: 3869.7817 - val_mae: 34.5072\n",
      "Epoch 1931/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 250.3659 - mae: 9.4218 - val_loss: 3818.0842 - val_mae: 34.1509\n",
      "Epoch 1932/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.3436 - mae: 9.4213 - val_loss: 3804.6660 - val_mae: 34.3559\n",
      "Epoch 1933/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 258.7303 - mae: 9.6084 - val_loss: 3858.8108 - val_mae: 34.1858\n",
      "Epoch 1934/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.4246 - mae: 9.4312 - val_loss: 3751.2192 - val_mae: 34.5513\n",
      "Epoch 1935/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 262.6580 - mae: 9.4924 - val_loss: 3807.8113 - val_mae: 35.1276\n",
      "Epoch 1936/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 333.3480 - mae: 10.1015 - val_loss: 3861.8098 - val_mae: 34.8214\n",
      "Epoch 1937/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.2034 - mae: 9.6762 - val_loss: 3868.2104 - val_mae: 35.0785\n",
      "Epoch 1938/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.4316 - mae: 9.7052 - val_loss: 3735.6753 - val_mae: 34.2426\n",
      "Epoch 1939/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.4590 - mae: 9.8014 - val_loss: 3877.0967 - val_mae: 34.6572\n",
      "Epoch 1940/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.1013 - mae: 9.9031 - val_loss: 3806.7864 - val_mae: 34.7681\n",
      "Epoch 1941/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.4768 - mae: 10.0451 - val_loss: 3786.9602 - val_mae: 34.9161\n",
      "Epoch 1942/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 352.1566 - mae: 10.3992 - val_loss: 3837.6753 - val_mae: 35.3305\n",
      "Epoch 1943/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 348.8577 - mae: 10.2785 - val_loss: 3845.7764 - val_mae: 35.0106\n",
      "Epoch 1944/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.8188 - mae: 9.8627 - val_loss: 3827.0671 - val_mae: 34.4951\n",
      "Epoch 1945/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 329.5112 - mae: 10.1305 - val_loss: 3807.3179 - val_mae: 34.6817\n",
      "Epoch 1946/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.9637 - mae: 9.9844 - val_loss: 3703.2114 - val_mae: 33.8179\n",
      "Epoch 1947/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 327.5329 - mae: 10.0165 - val_loss: 3766.8215 - val_mae: 34.4056\n",
      "Epoch 1948/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 304.9048 - mae: 9.9951 - val_loss: 3883.9570 - val_mae: 34.7387\n",
      "Epoch 1949/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.3366 - mae: 9.8763 - val_loss: 3773.1191 - val_mae: 34.8702\n",
      "Epoch 1950/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.9212 - mae: 10.2355 - val_loss: 3780.2366 - val_mae: 34.4646\n",
      "Epoch 1951/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 336.1436 - mae: 10.2326 - val_loss: 3743.8306 - val_mae: 34.4187\n",
      "Epoch 1952/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.9867 - mae: 9.5112 - val_loss: 3909.9180 - val_mae: 35.4036\n",
      "Epoch 1953/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.8490 - mae: 9.6610 - val_loss: 3889.1836 - val_mae: 34.6484\n",
      "Epoch 1954/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.5492 - mae: 9.7204 - val_loss: 4061.0332 - val_mae: 35.5716\n",
      "Epoch 1955/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.4358 - mae: 9.6414 - val_loss: 3981.4622 - val_mae: 35.1010\n",
      "Epoch 1956/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.5691 - mae: 9.6758 - val_loss: 3942.2319 - val_mae: 35.1974\n",
      "Epoch 1957/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.6596 - mae: 10.0511 - val_loss: 3860.2507 - val_mae: 34.9142\n",
      "Epoch 1958/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.3176 - mae: 9.7859 - val_loss: 3919.4016 - val_mae: 35.4563\n",
      "Epoch 1959/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 294.1833 - mae: 10.0626 - val_loss: 3901.5808 - val_mae: 35.0109\n",
      "Epoch 1960/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.7526 - mae: 9.7775 - val_loss: 4007.7583 - val_mae: 35.5302\n",
      "Epoch 1961/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 299.3203 - mae: 9.8698 - val_loss: 4100.4609 - val_mae: 35.3631\n",
      "Epoch 1962/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.9459 - mae: 10.4109 - val_loss: 3973.1677 - val_mae: 35.5456\n",
      "Epoch 1963/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.7958 - mae: 9.8069 - val_loss: 4006.6963 - val_mae: 35.1421\n",
      "Epoch 1964/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 317.6301 - mae: 10.1132 - val_loss: 4039.0342 - val_mae: 35.3465\n",
      "Epoch 1965/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 258.5046 - mae: 9.6175 - val_loss: 3993.0066 - val_mae: 35.0554\n",
      "Epoch 1966/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.0534 - mae: 9.8253 - val_loss: 4064.4763 - val_mae: 35.4903\n",
      "Epoch 1967/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 273.1948 - mae: 9.6703 - val_loss: 3940.0769 - val_mae: 35.3939\n",
      "Epoch 1968/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.0867 - mae: 9.7179 - val_loss: 4021.5210 - val_mae: 35.6162\n",
      "Epoch 1969/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.1978 - mae: 9.7613 - val_loss: 4023.9067 - val_mae: 35.2506\n",
      "Epoch 1970/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.3208 - mae: 9.4339 - val_loss: 3916.6313 - val_mae: 35.5139\n",
      "Epoch 1971/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.4091 - mae: 9.5818 - val_loss: 4008.3213 - val_mae: 35.5339\n",
      "Epoch 1972/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.8113 - mae: 9.8041 - val_loss: 4055.4626 - val_mae: 36.0385\n",
      "Epoch 1973/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.2070 - mae: 9.4416 - val_loss: 3972.8276 - val_mae: 35.6463\n",
      "Epoch 1974/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.4181 - mae: 9.7254 - val_loss: 4067.0889 - val_mae: 35.9755\n",
      "Epoch 1975/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.7752 - mae: 9.4172 - val_loss: 3927.7583 - val_mae: 35.0250\n",
      "Epoch 1976/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.2659 - mae: 9.6047 - val_loss: 3873.9534 - val_mae: 34.8205\n",
      "Epoch 1977/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.9465 - mae: 9.8155 - val_loss: 3919.4136 - val_mae: 35.4474\n",
      "Epoch 1978/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.6784 - mae: 9.5995 - val_loss: 3916.5730 - val_mae: 35.4826\n",
      "Epoch 1979/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.4165 - mae: 9.7413 - val_loss: 3962.3999 - val_mae: 34.5711\n",
      "Epoch 1980/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 299.4742 - mae: 9.8503 - val_loss: 3897.0510 - val_mae: 35.0196\n",
      "Epoch 1981/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 284.8899 - mae: 9.8346 - val_loss: 3923.7048 - val_mae: 35.1845\n",
      "Epoch 1982/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.8770 - mae: 9.7397 - val_loss: 3969.6863 - val_mae: 35.6312\n",
      "Epoch 1983/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.9360 - mae: 9.8148 - val_loss: 3989.3418 - val_mae: 35.0707\n",
      "Epoch 1984/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 310.2075 - mae: 9.7682 - val_loss: 3937.8662 - val_mae: 35.5650\n",
      "Epoch 1985/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 263.1871 - mae: 9.4989 - val_loss: 3938.7917 - val_mae: 35.3087\n",
      "Epoch 1986/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 279.5560 - mae: 9.8180 - val_loss: 3884.2798 - val_mae: 34.3279\n",
      "Epoch 1987/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.0964 - mae: 9.3802 - val_loss: 3876.7861 - val_mae: 34.7659\n",
      "Epoch 1988/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.4576 - mae: 9.9924 - val_loss: 4023.6931 - val_mae: 34.8694\n",
      "Epoch 1989/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.4621 - mae: 9.8463 - val_loss: 3760.2151 - val_mae: 35.0217\n",
      "Epoch 1990/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.0906 - mae: 9.7043 - val_loss: 3952.8123 - val_mae: 34.9925\n",
      "Epoch 1991/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.3520 - mae: 9.6592 - val_loss: 3990.4563 - val_mae: 35.2827\n",
      "Epoch 1992/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 280.7756 - mae: 9.6208 - val_loss: 3913.6960 - val_mae: 36.4803\n",
      "Epoch 1993/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.1065 - mae: 9.5536 - val_loss: 3985.5002 - val_mae: 35.1020\n",
      "Epoch 1994/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.7099 - mae: 9.4800 - val_loss: 3984.9365 - val_mae: 35.7351\n",
      "Epoch 1995/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.3573 - mae: 9.5957 - val_loss: 3905.4504 - val_mae: 35.2775\n",
      "Epoch 1996/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.3719 - mae: 10.0094 - val_loss: 3886.0654 - val_mae: 34.6046\n",
      "Epoch 1997/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 289.8127 - mae: 9.9286 - val_loss: 3927.9292 - val_mae: 35.0046\n",
      "Epoch 1998/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 345.3188 - mae: 10.4980 - val_loss: 3920.9578 - val_mae: 35.0804\n",
      "Epoch 1999/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 323.1883 - mae: 10.1484 - val_loss: 4109.5640 - val_mae: 35.3433\n",
      "Epoch 2000/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.2263 - mae: 9.8120 - val_loss: 3973.7756 - val_mae: 35.3940\n",
      "Epoch 2001/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 277.3423 - mae: 9.6846 - val_loss: 3894.4124 - val_mae: 34.5593\n",
      "Epoch 2002/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.4617 - mae: 9.7586 - val_loss: 3771.9116 - val_mae: 34.2958\n",
      "Epoch 2003/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.6176 - mae: 9.3297 - val_loss: 3867.8613 - val_mae: 34.6282\n",
      "Epoch 2004/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.4902 - mae: 9.7020 - val_loss: 3928.9539 - val_mae: 35.4228\n",
      "Epoch 2005/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.2486 - mae: 9.7076 - val_loss: 3997.1743 - val_mae: 35.1499\n",
      "Epoch 2006/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.2516 - mae: 9.4461 - val_loss: 3818.9709 - val_mae: 34.7940\n",
      "Epoch 2007/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.4536 - mae: 9.7696 - val_loss: 4026.7219 - val_mae: 35.2972\n",
      "Epoch 2008/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.2624 - mae: 9.8590 - val_loss: 3915.4092 - val_mae: 34.6988\n",
      "Epoch 2009/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.5658 - mae: 9.7451 - val_loss: 3910.7891 - val_mae: 35.5316\n",
      "Epoch 2010/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.8206 - mae: 9.6010 - val_loss: 3962.2908 - val_mae: 34.8626\n",
      "Epoch 2011/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.8772 - mae: 9.3688 - val_loss: 4044.4961 - val_mae: 36.1660\n",
      "Epoch 2012/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 317.1728 - mae: 10.0470 - val_loss: 3845.2354 - val_mae: 34.2638\n",
      "Epoch 2013/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.1732 - mae: 9.2038 - val_loss: 3854.5378 - val_mae: 34.9182\n",
      "Epoch 2014/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.6655 - mae: 9.5810 - val_loss: 3890.2517 - val_mae: 34.3219\n",
      "Epoch 2015/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 302.9638 - mae: 9.9418 - val_loss: 3875.6653 - val_mae: 34.6732\n",
      "Epoch 2016/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.5587 - mae: 10.1736 - val_loss: 3865.5203 - val_mae: 34.3946\n",
      "Epoch 2017/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 298.6136 - mae: 9.8556 - val_loss: 3958.9939 - val_mae: 35.0520\n",
      "Epoch 2018/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 306.9094 - mae: 9.9798 - val_loss: 3828.0291 - val_mae: 34.9804\n",
      "Epoch 2019/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 289.6119 - mae: 9.7913 - val_loss: 4001.6345 - val_mae: 35.4536\n",
      "Epoch 2020/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 313.2138 - mae: 10.0071 - val_loss: 4016.9585 - val_mae: 35.1223\n",
      "Epoch 2021/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 302.6502 - mae: 9.8398 - val_loss: 3839.5691 - val_mae: 34.8983\n",
      "Epoch 2022/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 296.0562 - mae: 9.9778 - val_loss: 3983.9871 - val_mae: 35.4366\n",
      "Epoch 2023/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 300.4032 - mae: 9.8027 - val_loss: 4025.4839 - val_mae: 35.4068\n",
      "Epoch 2024/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.3146 - mae: 9.6226 - val_loss: 3957.6333 - val_mae: 34.8806\n",
      "Epoch 2025/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.6530 - mae: 9.5638 - val_loss: 3999.4106 - val_mae: 34.5582\n",
      "Epoch 2026/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.3059 - mae: 9.5560 - val_loss: 3899.8599 - val_mae: 34.8482\n",
      "Epoch 2027/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 262.1664 - mae: 9.5765 - val_loss: 3978.7734 - val_mae: 34.6042\n",
      "Epoch 2028/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.6334 - mae: 9.5626 - val_loss: 3951.2737 - val_mae: 35.5573\n",
      "Epoch 2029/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.7464 - mae: 9.4982 - val_loss: 4002.8291 - val_mae: 35.1690\n",
      "Epoch 2030/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.3161 - mae: 9.7421 - val_loss: 3941.2622 - val_mae: 34.7902\n",
      "Epoch 2031/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 296.1238 - mae: 9.8687 - val_loss: 3909.6504 - val_mae: 35.0193\n",
      "Epoch 2032/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.2596 - mae: 9.8435 - val_loss: 3902.5364 - val_mae: 34.9401\n",
      "Epoch 2033/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 308.5977 - mae: 9.9563 - val_loss: 3819.1184 - val_mae: 34.7210\n",
      "Epoch 2034/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 334.5051 - mae: 10.0044 - val_loss: 3895.9321 - val_mae: 34.7988\n",
      "Epoch 2035/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.9141 - mae: 9.9172 - val_loss: 3917.7947 - val_mae: 35.0634\n",
      "Epoch 2036/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 323.0727 - mae: 10.2161 - val_loss: 3867.9419 - val_mae: 34.6852\n",
      "Epoch 2037/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.2176 - mae: 9.7869 - val_loss: 3955.2520 - val_mae: 35.5703\n",
      "Epoch 2038/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 262.5046 - mae: 9.6303 - val_loss: 3982.5059 - val_mae: 34.9056\n",
      "Epoch 2039/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.9992 - mae: 9.7886 - val_loss: 3949.0366 - val_mae: 35.2213\n",
      "Epoch 2040/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 311.4588 - mae: 9.8619 - val_loss: 3929.7539 - val_mae: 35.4403\n",
      "Epoch 2041/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 314.0439 - mae: 10.1724 - val_loss: 3962.9451 - val_mae: 35.1671\n",
      "Epoch 2042/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 324.7085 - mae: 10.0317 - val_loss: 3816.5156 - val_mae: 34.1637\n",
      "Epoch 2043/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.4805 - mae: 10.0303 - val_loss: 3813.3772 - val_mae: 38.6195\n",
      "Epoch 2044/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 311.6574 - mae: 12.0683 - val_loss: 3835.4021 - val_mae: 36.1283\n",
      "Epoch 2045/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.5857 - mae: 11.2132 - val_loss: 3928.9978 - val_mae: 35.6099\n",
      "Epoch 2046/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.4626 - mae: 10.6772 - val_loss: 3932.2344 - val_mae: 35.1498\n",
      "Epoch 2047/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 338.2722 - mae: 11.2592 - val_loss: 3977.3989 - val_mae: 35.0443\n",
      "Epoch 2048/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 305.4912 - mae: 10.8339 - val_loss: 3949.2065 - val_mae: 35.4750\n",
      "Epoch 2049/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 322.2937 - mae: 10.7295 - val_loss: 3999.8970 - val_mae: 36.0262\n",
      "Epoch 2050/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 320.1018 - mae: 10.7295 - val_loss: 3999.2461 - val_mae: 35.4106\n",
      "Epoch 2051/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 339.9830 - mae: 10.8434 - val_loss: 4037.4890 - val_mae: 36.4222\n",
      "Epoch 2052/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 308.6811 - mae: 10.4880 - val_loss: 4067.7717 - val_mae: 36.4417\n",
      "Epoch 2053/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.1122 - mae: 10.6877 - val_loss: 3972.9756 - val_mae: 35.9645\n",
      "Epoch 2054/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 314.2546 - mae: 10.5529 - val_loss: 3944.4160 - val_mae: 35.8783\n",
      "Epoch 2055/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.5171 - mae: 10.1547 - val_loss: 3921.1636 - val_mae: 35.2254\n",
      "Epoch 2056/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.3934 - mae: 10.2732 - val_loss: 3993.8887 - val_mae: 36.0465\n",
      "Epoch 2057/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 319.5587 - mae: 10.2546 - val_loss: 4047.8521 - val_mae: 36.0494\n",
      "Epoch 2058/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.9736 - mae: 10.0979 - val_loss: 4099.3960 - val_mae: 36.0989\n",
      "Epoch 2059/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 289.7096 - mae: 10.1609 - val_loss: 4020.4316 - val_mae: 35.6373\n",
      "Epoch 2060/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 332.8016 - mae: 10.4631 - val_loss: 4064.6770 - val_mae: 35.2698\n",
      "Epoch 2061/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.1739 - mae: 10.1057 - val_loss: 4181.2568 - val_mae: 36.8165\n",
      "Epoch 2062/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 322.9064 - mae: 10.1557 - val_loss: 4070.6843 - val_mae: 35.9375\n",
      "Epoch 2063/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.4129 - mae: 10.1536 - val_loss: 3957.9578 - val_mae: 35.5187\n",
      "Epoch 2064/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.1923 - mae: 10.1308 - val_loss: 4140.5327 - val_mae: 36.6267\n",
      "Epoch 2065/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 300.5121 - mae: 10.3802 - val_loss: 3968.4995 - val_mae: 35.1807\n",
      "Epoch 2066/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 310.2858 - mae: 10.4426 - val_loss: 3879.8738 - val_mae: 34.8998\n",
      "Epoch 2067/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 322.6939 - mae: 10.1743 - val_loss: 3968.2166 - val_mae: 35.6823\n",
      "Epoch 2068/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.3954 - mae: 9.8183 - val_loss: 4037.2935 - val_mae: 35.2808\n",
      "Epoch 2069/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.0359 - mae: 10.0574 - val_loss: 4077.4033 - val_mae: 35.3041\n",
      "Epoch 2070/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 297.1323 - mae: 10.1839 - val_loss: 4094.8516 - val_mae: 35.1353\n",
      "Epoch 2071/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 325.2455 - mae: 10.2370 - val_loss: 3852.6018 - val_mae: 34.7395\n",
      "Epoch 2072/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 289.9302 - mae: 10.2727 - val_loss: 3941.7429 - val_mae: 35.1741\n",
      "Epoch 2073/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 313.1989 - mae: 10.3463 - val_loss: 4092.9854 - val_mae: 35.1997\n",
      "Epoch 2074/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.6927 - mae: 10.0490 - val_loss: 3920.4829 - val_mae: 34.9248\n",
      "Epoch 2075/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.7631 - mae: 10.0769 - val_loss: 3883.2239 - val_mae: 34.7420\n",
      "Epoch 2076/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 341.0835 - mae: 10.1251 - val_loss: 3955.5579 - val_mae: 35.4242\n",
      "Epoch 2077/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 314.4841 - mae: 10.2298 - val_loss: 3846.6199 - val_mae: 34.8810\n",
      "Epoch 2078/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 291.9474 - mae: 9.8179 - val_loss: 3896.7671 - val_mae: 35.2933\n",
      "Epoch 2079/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.7608 - mae: 9.6958 - val_loss: 3887.3723 - val_mae: 35.0581\n",
      "Epoch 2080/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.5539 - mae: 9.7669 - val_loss: 3946.1321 - val_mae: 35.1965\n",
      "Epoch 2081/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.9848 - mae: 9.9788 - val_loss: 4061.2886 - val_mae: 35.7157\n",
      "Epoch 2082/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 271.5045 - mae: 9.6499 - val_loss: 3958.8486 - val_mae: 35.4402\n",
      "Epoch 2083/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.6596 - mae: 9.8276 - val_loss: 3908.8445 - val_mae: 34.9738\n",
      "Epoch 2084/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 335.8379 - mae: 10.2380 - val_loss: 3860.0513 - val_mae: 34.8146\n",
      "Epoch 2085/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.8870 - mae: 9.9212 - val_loss: 3908.9431 - val_mae: 35.0746\n",
      "Epoch 2086/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.8923 - mae: 10.3294 - val_loss: 4009.8997 - val_mae: 34.7941\n",
      "Epoch 2087/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.5733 - mae: 10.0896 - val_loss: 3929.8521 - val_mae: 34.9385\n",
      "Epoch 2088/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 303.7281 - mae: 9.8068 - val_loss: 3894.5989 - val_mae: 34.7059\n",
      "Epoch 2089/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 384.0661 - mae: 10.4960 - val_loss: 4019.2961 - val_mae: 35.4474\n",
      "Epoch 2090/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.2940 - mae: 9.9451 - val_loss: 3939.5471 - val_mae: 35.0676\n",
      "Epoch 2091/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 327.8499 - mae: 10.0519 - val_loss: 3949.8088 - val_mae: 34.9171\n",
      "Epoch 2092/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 334.3917 - mae: 9.9726 - val_loss: 3898.6040 - val_mae: 34.5244\n",
      "Epoch 2093/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.1597 - mae: 9.1770 - val_loss: 3956.4448 - val_mae: 34.6468\n",
      "Epoch 2094/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 320.0943 - mae: 9.9169 - val_loss: 3927.7998 - val_mae: 34.8458\n",
      "Epoch 2095/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.7563 - mae: 9.9728 - val_loss: 4071.5442 - val_mae: 35.7297\n",
      "Epoch 2096/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.4750 - mae: 9.9792 - val_loss: 4072.9929 - val_mae: 35.1272\n",
      "Epoch 2097/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 334.5247 - mae: 10.0165 - val_loss: 4081.1458 - val_mae: 35.2493\n",
      "Epoch 2098/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 305.2752 - mae: 10.0022 - val_loss: 3999.8254 - val_mae: 35.1704\n",
      "Epoch 2099/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.7084 - mae: 9.2980 - val_loss: 3956.8455 - val_mae: 35.1934\n",
      "Epoch 2100/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 296.8646 - mae: 9.7979 - val_loss: 4015.6533 - val_mae: 35.1183\n",
      "Epoch 2101/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 315.0010 - mae: 9.9026 - val_loss: 3985.4658 - val_mae: 35.8170\n",
      "Epoch 2102/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 315.1276 - mae: 10.0420 - val_loss: 4071.8640 - val_mae: 35.1708\n",
      "Epoch 2103/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.2925 - mae: 9.3311 - val_loss: 3982.1169 - val_mae: 34.8808\n",
      "Epoch 2104/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.5358 - mae: 9.6938 - val_loss: 3953.0850 - val_mae: 35.1409\n",
      "Epoch 2105/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.2238 - mae: 9.2932 - val_loss: 4029.8108 - val_mae: 35.0005\n",
      "Epoch 2106/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.0430 - mae: 9.2105 - val_loss: 4018.9121 - val_mae: 34.7419\n",
      "Epoch 2107/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.7567 - mae: 9.5905 - val_loss: 3916.0522 - val_mae: 35.3241\n",
      "Epoch 2108/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.8300 - mae: 9.5301 - val_loss: 3967.2336 - val_mae: 35.1234\n",
      "Epoch 2109/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 297.9141 - mae: 9.4416 - val_loss: 3935.7666 - val_mae: 35.2075\n",
      "Epoch 2110/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.7101 - mae: 9.8266 - val_loss: 3858.8665 - val_mae: 34.5670\n",
      "Epoch 2111/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.9150 - mae: 9.4051 - val_loss: 3918.6902 - val_mae: 34.9617\n",
      "Epoch 2112/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.1987 - mae: 9.4449 - val_loss: 4008.1492 - val_mae: 35.2770\n",
      "Epoch 2113/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.2129 - mae: 9.3115 - val_loss: 3968.6399 - val_mae: 34.9973\n",
      "Epoch 2114/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.8962 - mae: 9.4749 - val_loss: 3872.3303 - val_mae: 34.7498\n",
      "Epoch 2115/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.7648 - mae: 9.4248 - val_loss: 3920.6213 - val_mae: 34.8978\n",
      "Epoch 2116/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.8634 - mae: 9.7726 - val_loss: 3890.4895 - val_mae: 34.5195\n",
      "Epoch 2117/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 358.6606 - mae: 9.9486 - val_loss: 3811.5447 - val_mae: 34.2048\n",
      "Epoch 2118/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 354.0856 - mae: 10.2079 - val_loss: 3794.5566 - val_mae: 34.1846\n",
      "Epoch 2119/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 327.9192 - mae: 10.0121 - val_loss: 3864.2700 - val_mae: 34.3237\n",
      "Epoch 2120/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 348.5754 - mae: 10.1982 - val_loss: 3856.4509 - val_mae: 34.9208\n",
      "Epoch 2121/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.5087 - mae: 9.7312 - val_loss: 3987.0701 - val_mae: 35.2347\n",
      "Epoch 2122/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 308.7147 - mae: 10.0207 - val_loss: 4004.2080 - val_mae: 35.5826\n",
      "Epoch 2123/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 302.4534 - mae: 9.7251 - val_loss: 3887.5522 - val_mae: 34.8143\n",
      "Epoch 2124/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 289.7679 - mae: 9.7819 - val_loss: 4053.7041 - val_mae: 35.0744\n",
      "Epoch 2125/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.9591 - mae: 9.8221 - val_loss: 3973.2981 - val_mae: 35.3426\n",
      "Epoch 2126/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.2949 - mae: 9.8689 - val_loss: 3903.6184 - val_mae: 35.1332\n",
      "Epoch 2127/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.3433 - mae: 9.7598 - val_loss: 3940.7390 - val_mae: 34.9372\n",
      "Epoch 2128/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.2862 - mae: 9.8470 - val_loss: 3816.4805 - val_mae: 34.4949\n",
      "Epoch 2129/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 294.7227 - mae: 9.9645 - val_loss: 3904.9734 - val_mae: 34.5714\n",
      "Epoch 2130/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 302.7718 - mae: 9.9574 - val_loss: 3915.4587 - val_mae: 35.0128\n",
      "Epoch 2131/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.6783 - mae: 9.8214 - val_loss: 3848.8232 - val_mae: 34.4079\n",
      "Epoch 2132/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 304.7032 - mae: 9.9690 - val_loss: 3968.4546 - val_mae: 34.9722\n",
      "Epoch 2133/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 301.4456 - mae: 10.1304 - val_loss: 3966.8364 - val_mae: 35.0687\n",
      "Epoch 2134/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 323.2145 - mae: 10.0932 - val_loss: 4041.3865 - val_mae: 35.6741\n",
      "Epoch 2135/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.6747 - mae: 10.0479 - val_loss: 4077.4456 - val_mae: 35.6341\n",
      "Epoch 2136/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 322.0258 - mae: 10.0991 - val_loss: 3968.6055 - val_mae: 35.4594\n",
      "Epoch 2137/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 274.3760 - mae: 9.7429 - val_loss: 3992.5823 - val_mae: 35.5068\n",
      "Epoch 2138/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 301.0387 - mae: 10.0989 - val_loss: 4110.9658 - val_mae: 36.0203\n",
      "Epoch 2139/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 265.6990 - mae: 9.5614 - val_loss: 4230.1968 - val_mae: 36.1927\n",
      "Epoch 2140/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 308.2196 - mae: 9.8844 - val_loss: 4013.8511 - val_mae: 35.6208\n",
      "Epoch 2141/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 329.2154 - mae: 10.0853 - val_loss: 4050.7971 - val_mae: 35.6747\n",
      "Epoch 2142/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.2635 - mae: 9.8633 - val_loss: 4102.3721 - val_mae: 35.9004\n",
      "Epoch 2143/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 347.6845 - mae: 10.1530 - val_loss: 4040.4780 - val_mae: 35.3651\n",
      "Epoch 2144/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.5160 - mae: 9.6240 - val_loss: 4006.1470 - val_mae: 35.6663\n",
      "Epoch 2145/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.5821 - mae: 9.9405 - val_loss: 4080.1895 - val_mae: 35.7712\n",
      "Epoch 2146/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 316.3931 - mae: 9.8782 - val_loss: 4102.2095 - val_mae: 36.0648\n",
      "Epoch 2147/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 305.0173 - mae: 9.7709 - val_loss: 4075.1064 - val_mae: 35.5369\n",
      "Epoch 2148/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.7672 - mae: 9.3375 - val_loss: 3919.9868 - val_mae: 35.6015\n",
      "Epoch 2149/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.3289 - mae: 9.5610 - val_loss: 4053.8047 - val_mae: 35.9791\n",
      "Epoch 2150/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.5251 - mae: 9.3899 - val_loss: 4119.6064 - val_mae: 36.3708\n",
      "Epoch 2151/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.2850 - mae: 9.4278 - val_loss: 4177.2920 - val_mae: 35.6844\n",
      "Epoch 2152/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 263.1251 - mae: 9.4716 - val_loss: 4129.0820 - val_mae: 36.1596\n",
      "Epoch 2153/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.0873 - mae: 9.5467 - val_loss: 3982.8345 - val_mae: 35.1812\n",
      "Epoch 2154/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.0728 - mae: 9.2609 - val_loss: 3902.3257 - val_mae: 34.8831\n",
      "Epoch 2155/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.1733 - mae: 9.7818 - val_loss: 3982.1860 - val_mae: 35.3253\n",
      "Epoch 2156/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.8067 - mae: 9.8487 - val_loss: 4071.8311 - val_mae: 35.3463\n",
      "Epoch 2157/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 268.7681 - mae: 9.8167 - val_loss: 3991.7651 - val_mae: 35.5641\n",
      "Epoch 2158/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 303.5117 - mae: 9.7092 - val_loss: 3947.3364 - val_mae: 34.9100\n",
      "Epoch 2159/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.7418 - mae: 9.9256 - val_loss: 3922.2520 - val_mae: 34.9044\n",
      "Epoch 2160/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 310.6967 - mae: 10.0461 - val_loss: 3963.0134 - val_mae: 34.9360\n",
      "Epoch 2161/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.6751 - mae: 9.7426 - val_loss: 3914.7810 - val_mae: 35.0530\n",
      "Epoch 2162/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 297.6358 - mae: 9.8224 - val_loss: 3937.6211 - val_mae: 34.8904\n",
      "Epoch 2163/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.7790 - mae: 9.5228 - val_loss: 3956.1460 - val_mae: 35.1357\n",
      "Epoch 2164/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.4918 - mae: 9.4155 - val_loss: 3890.2803 - val_mae: 34.8018\n",
      "Epoch 2165/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 302.3280 - mae: 9.8242 - val_loss: 3807.2427 - val_mae: 35.1415\n",
      "Epoch 2166/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 338.4064 - mae: 10.1982 - val_loss: 3839.2351 - val_mae: 34.6918\n",
      "Epoch 2167/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 343.4001 - mae: 10.2578 - val_loss: 3893.2009 - val_mae: 34.0694\n",
      "Epoch 2168/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 364.3433 - mae: 10.3362 - val_loss: 3911.7246 - val_mae: 34.6643\n",
      "Epoch 2169/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 347.1480 - mae: 10.2215 - val_loss: 3857.5083 - val_mae: 34.1297\n",
      "Epoch 2170/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 362.0770 - mae: 10.3882 - val_loss: 3963.0200 - val_mae: 35.4569\n",
      "Epoch 2171/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 346.5520 - mae: 10.1865 - val_loss: 3939.4263 - val_mae: 35.4503\n",
      "Epoch 2172/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.6419 - mae: 9.9998 - val_loss: 4059.1960 - val_mae: 36.3209\n",
      "Epoch 2173/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.9633 - mae: 9.8585 - val_loss: 4084.9771 - val_mae: 35.7153\n",
      "Epoch 2174/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.0657 - mae: 9.8684 - val_loss: 4129.4771 - val_mae: 36.5627\n",
      "Epoch 2175/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 277.1224 - mae: 9.6763 - val_loss: 4005.9409 - val_mae: 35.5815\n",
      "Epoch 2176/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 271.7090 - mae: 9.6648 - val_loss: 4052.8301 - val_mae: 36.1062\n",
      "Epoch 2177/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.9253 - mae: 9.4088 - val_loss: 4016.4966 - val_mae: 35.8638\n",
      "Epoch 2178/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.8880 - mae: 9.5075 - val_loss: 3990.6553 - val_mae: 35.4106\n",
      "Epoch 2179/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 297.4342 - mae: 9.8100 - val_loss: 4064.1218 - val_mae: 35.9286\n",
      "Epoch 2180/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 318.2680 - mae: 11.4190 - val_loss: 4106.8174 - val_mae: 36.5782\n",
      "Epoch 2181/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.2542 - mae: 9.6786 - val_loss: 4021.2061 - val_mae: 35.6609\n",
      "Epoch 2182/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.9523 - mae: 9.6868 - val_loss: 4074.0483 - val_mae: 35.3761\n",
      "Epoch 2183/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.4435 - mae: 9.4270 - val_loss: 4007.6638 - val_mae: 35.2294\n",
      "Epoch 2184/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.3527 - mae: 9.2856 - val_loss: 4101.9766 - val_mae: 35.4534\n",
      "Epoch 2185/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.4422 - mae: 9.3515 - val_loss: 3971.5852 - val_mae: 34.8801\n",
      "Epoch 2186/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.7470 - mae: 9.6584 - val_loss: 3896.8403 - val_mae: 34.8006\n",
      "Epoch 2187/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.0491 - mae: 9.7351 - val_loss: 4086.4287 - val_mae: 35.2584\n",
      "Epoch 2188/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 299.4136 - mae: 9.7925 - val_loss: 4096.8198 - val_mae: 35.8152\n",
      "Epoch 2189/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 303.4079 - mae: 9.8337 - val_loss: 4100.0684 - val_mae: 35.9448\n",
      "Epoch 2190/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.7698 - mae: 9.6917 - val_loss: 3926.1470 - val_mae: 35.4619\n",
      "Epoch 2191/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 263.5276 - mae: 9.5686 - val_loss: 3973.2717 - val_mae: 35.5271\n",
      "Epoch 2192/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 283.6064 - mae: 9.8235 - val_loss: 4020.6460 - val_mae: 35.9982\n",
      "Epoch 2193/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.4371 - mae: 9.5796 - val_loss: 3987.4255 - val_mae: 35.3270\n",
      "Epoch 2194/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.0967 - mae: 9.4844 - val_loss: 3921.6704 - val_mae: 35.5761\n",
      "Epoch 2195/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 296.1413 - mae: 9.7065 - val_loss: 4010.1658 - val_mae: 35.3424\n",
      "Epoch 2196/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.5740 - mae: 9.4972 - val_loss: 4063.8608 - val_mae: 36.0563\n",
      "Epoch 2197/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.7771 - mae: 9.5173 - val_loss: 4000.9241 - val_mae: 35.4132\n",
      "Epoch 2198/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 296.8024 - mae: 9.8339 - val_loss: 3863.9673 - val_mae: 35.1094\n",
      "Epoch 2199/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.0155 - mae: 9.7344 - val_loss: 3982.5095 - val_mae: 35.3827\n",
      "Epoch 2200/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.3207 - mae: 9.6119 - val_loss: 3946.9167 - val_mae: 35.5962\n",
      "Epoch 2201/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 273.0981 - mae: 9.5468 - val_loss: 4050.8250 - val_mae: 35.7757\n",
      "Epoch 2202/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.7745 - mae: 9.7106 - val_loss: 3960.7698 - val_mae: 35.5279\n",
      "Epoch 2203/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 344.1478 - mae: 10.2576 - val_loss: 3963.5684 - val_mae: 35.4272\n",
      "Epoch 2204/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.8907 - mae: 9.9818 - val_loss: 3924.2773 - val_mae: 35.2873\n",
      "Epoch 2205/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.9899 - mae: 9.8417 - val_loss: 3821.8367 - val_mae: 35.3481\n",
      "Epoch 2206/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 299.8681 - mae: 9.8005 - val_loss: 3834.9177 - val_mae: 35.0984\n",
      "Epoch 2207/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.4894 - mae: 9.6090 - val_loss: 3885.6392 - val_mae: 34.7393\n",
      "Epoch 2208/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.9364 - mae: 9.6577 - val_loss: 3827.7817 - val_mae: 34.6829\n",
      "Epoch 2209/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.8419 - mae: 9.0504 - val_loss: 3822.3596 - val_mae: 34.6650\n",
      "Epoch 2210/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.2678 - mae: 9.2396 - val_loss: 3924.4299 - val_mae: 34.7479\n",
      "Epoch 2211/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.4765 - mae: 9.4889 - val_loss: 3878.9028 - val_mae: 34.4941\n",
      "Epoch 2212/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 265.3976 - mae: 9.3806 - val_loss: 3975.8271 - val_mae: 35.1307\n",
      "Epoch 2213/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.9085 - mae: 9.4457 - val_loss: 3972.2859 - val_mae: 35.4048\n",
      "Epoch 2214/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.0726 - mae: 9.2663 - val_loss: 3966.8120 - val_mae: 35.0286\n",
      "Epoch 2215/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 302.1570 - mae: 9.9811 - val_loss: 4037.3945 - val_mae: 35.6915\n",
      "Epoch 2216/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 296.9459 - mae: 9.9838 - val_loss: 3891.2644 - val_mae: 34.7805\n",
      "Epoch 2217/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.6698 - mae: 9.0970 - val_loss: 4016.4880 - val_mae: 35.4118\n",
      "Epoch 2218/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.4856 - mae: 9.5502 - val_loss: 3839.9319 - val_mae: 34.6293\n",
      "Epoch 2219/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.4081 - mae: 9.7454 - val_loss: 3933.6250 - val_mae: 34.9606\n",
      "Epoch 2220/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 250.9718 - mae: 9.3765 - val_loss: 3883.8096 - val_mae: 34.8599\n",
      "Epoch 2221/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 268.2708 - mae: 9.3563 - val_loss: 3886.8279 - val_mae: 35.1737\n",
      "Epoch 2222/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.0276 - mae: 9.3762 - val_loss: 3772.0681 - val_mae: 34.7274\n",
      "Epoch 2223/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 266.9513 - mae: 9.4589 - val_loss: 3929.8020 - val_mae: 34.4238\n",
      "Epoch 2224/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 267.1431 - mae: 9.4603 - val_loss: 3851.1694 - val_mae: 34.5816\n",
      "Epoch 2225/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.7891 - mae: 9.5734 - val_loss: 3882.2830 - val_mae: 34.7781\n",
      "Epoch 2226/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.0756 - mae: 9.5433 - val_loss: 3935.2300 - val_mae: 35.3845\n",
      "Epoch 2227/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 261.5496 - mae: 9.4787 - val_loss: 4001.1931 - val_mae: 35.2841\n",
      "Epoch 2228/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.2455 - mae: 9.3824 - val_loss: 3858.8750 - val_mae: 34.8988\n",
      "Epoch 2229/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.0398 - mae: 9.5882 - val_loss: 3716.5007 - val_mae: 34.0521\n",
      "Epoch 2230/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 338.3593 - mae: 10.0093 - val_loss: 3831.8850 - val_mae: 34.3882\n",
      "Epoch 2231/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 336.4781 - mae: 10.1737 - val_loss: 3949.0090 - val_mae: 35.8040\n",
      "Epoch 2232/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 307.3882 - mae: 10.0577 - val_loss: 3943.6589 - val_mae: 35.3025\n",
      "Epoch 2233/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.2135 - mae: 9.6997 - val_loss: 3915.5347 - val_mae: 35.5672\n",
      "Epoch 2234/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.9691 - mae: 9.4074 - val_loss: 3852.1147 - val_mae: 35.1907\n",
      "Epoch 2235/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.5037 - mae: 9.9711 - val_loss: 3847.1528 - val_mae: 34.6714\n",
      "Epoch 2236/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 360.4073 - mae: 10.1206 - val_loss: 3800.5461 - val_mae: 34.4766\n",
      "Epoch 2237/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 328.5494 - mae: 10.1126 - val_loss: 3840.9292 - val_mae: 34.9671\n",
      "Epoch 2238/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 302.7815 - mae: 9.9681 - val_loss: 3876.6462 - val_mae: 35.1390\n",
      "Epoch 2239/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.7986 - mae: 9.4843 - val_loss: 3978.0535 - val_mae: 35.3513\n",
      "Epoch 2240/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 315.0865 - mae: 9.8959 - val_loss: 3916.1177 - val_mae: 35.4823\n",
      "Epoch 2241/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 288.4952 - mae: 9.5287 - val_loss: 3906.7122 - val_mae: 35.4219\n",
      "Epoch 2242/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.3813 - mae: 9.6795 - val_loss: 3962.7864 - val_mae: 35.7131\n",
      "Epoch 2243/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 301.6746 - mae: 9.7554 - val_loss: 3947.9626 - val_mae: 35.2547\n",
      "Epoch 2244/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.0807 - mae: 9.5488 - val_loss: 3742.2815 - val_mae: 34.3653\n",
      "Epoch 2245/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.5127 - mae: 9.3061 - val_loss: 3964.9658 - val_mae: 35.2384\n",
      "Epoch 2246/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 267.2989 - mae: 9.4250 - val_loss: 4030.0186 - val_mae: 35.5757\n",
      "Epoch 2247/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.7391 - mae: 9.4164 - val_loss: 4000.3369 - val_mae: 35.6531\n",
      "Epoch 2248/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.8548 - mae: 9.6721 - val_loss: 3902.4194 - val_mae: 35.6552\n",
      "Epoch 2249/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.3373 - mae: 9.3177 - val_loss: 3919.7212 - val_mae: 35.6292\n",
      "Epoch 2250/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 240.5632 - mae: 9.1257 - val_loss: 3963.8567 - val_mae: 35.6207\n",
      "Epoch 2251/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.1595 - mae: 9.1505 - val_loss: 4016.5747 - val_mae: 35.3200\n",
      "Epoch 2252/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 248.2505 - mae: 9.5232 - val_loss: 3948.8013 - val_mae: 34.9124\n",
      "Epoch 2253/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.9130 - mae: 9.2989 - val_loss: 4016.5906 - val_mae: 35.9619\n",
      "Epoch 2254/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.3227 - mae: 9.3901 - val_loss: 3925.3457 - val_mae: 35.2105\n",
      "Epoch 2255/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 307.6296 - mae: 9.9259 - val_loss: 4044.4207 - val_mae: 35.2013\n",
      "Epoch 2256/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.8477 - mae: 9.6855 - val_loss: 4066.4629 - val_mae: 35.2591\n",
      "Epoch 2257/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 305.0146 - mae: 9.7130 - val_loss: 3994.4290 - val_mae: 36.2005\n",
      "Epoch 2258/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 273.0656 - mae: 9.3242 - val_loss: 4044.8794 - val_mae: 35.7669\n",
      "Epoch 2259/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.3395 - mae: 9.1366 - val_loss: 4082.6484 - val_mae: 35.4782\n",
      "Epoch 2260/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 244.1361 - mae: 9.0921 - val_loss: 4094.1309 - val_mae: 35.2332\n",
      "Epoch 2261/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.3448 - mae: 9.5190 - val_loss: 3997.2329 - val_mae: 35.9475\n",
      "Epoch 2262/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 288.3923 - mae: 9.9758 - val_loss: 4051.5022 - val_mae: 35.9714\n",
      "Epoch 2263/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.5763 - mae: 9.2792 - val_loss: 4070.1531 - val_mae: 35.7802\n",
      "Epoch 2264/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 259.2064 - mae: 9.3977 - val_loss: 4048.9341 - val_mae: 36.0308\n",
      "Epoch 2265/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.7917 - mae: 9.4155 - val_loss: 4003.5559 - val_mae: 35.6333\n",
      "Epoch 2266/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 264.0047 - mae: 9.3066 - val_loss: 4047.9766 - val_mae: 35.2365\n",
      "Epoch 2267/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.6485 - mae: 9.6346 - val_loss: 4066.8022 - val_mae: 35.4980\n",
      "Epoch 2268/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.5811 - mae: 9.3208 - val_loss: 3993.1921 - val_mae: 35.3400\n",
      "Epoch 2269/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.3910 - mae: 9.2824 - val_loss: 3967.2170 - val_mae: 35.6537\n",
      "Epoch 2270/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 312.5312 - mae: 10.2907 - val_loss: 3956.1748 - val_mae: 35.7512\n",
      "Epoch 2271/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 285.6688 - mae: 9.6977 - val_loss: 3986.9207 - val_mae: 35.4345\n",
      "Epoch 2272/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.3932 - mae: 9.4770 - val_loss: 3929.5657 - val_mae: 35.5386\n",
      "Epoch 2273/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.1741 - mae: 9.6645 - val_loss: 3963.3540 - val_mae: 34.8296\n",
      "Epoch 2274/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.1099 - mae: 9.3945 - val_loss: 3979.6333 - val_mae: 35.2407\n",
      "Epoch 2275/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.2143 - mae: 9.1428 - val_loss: 3947.1055 - val_mae: 35.0087\n",
      "Epoch 2276/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.7409 - mae: 9.4383 - val_loss: 3938.0789 - val_mae: 35.1983\n",
      "Epoch 2277/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.3251 - mae: 9.5600 - val_loss: 3897.7273 - val_mae: 34.3200\n",
      "Epoch 2278/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.5655 - mae: 9.4805 - val_loss: 3883.4199 - val_mae: 34.7373\n",
      "Epoch 2279/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.7516 - mae: 9.3322 - val_loss: 4094.2551 - val_mae: 35.8823\n",
      "Epoch 2280/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.8943 - mae: 9.4778 - val_loss: 3874.7266 - val_mae: 35.2691\n",
      "Epoch 2281/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.5255 - mae: 9.5117 - val_loss: 4042.9380 - val_mae: 35.3229\n",
      "Epoch 2282/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.4833 - mae: 9.2796 - val_loss: 3959.2085 - val_mae: 34.9560\n",
      "Epoch 2283/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.5307 - mae: 9.2497 - val_loss: 4053.3811 - val_mae: 35.7106\n",
      "Epoch 2284/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 279.7562 - mae: 9.6974 - val_loss: 4085.2751 - val_mae: 35.8985\n",
      "Epoch 2285/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.3560 - mae: 9.3680 - val_loss: 4100.6162 - val_mae: 35.2778\n",
      "Epoch 2286/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.1835 - mae: 9.2316 - val_loss: 4076.0786 - val_mae: 35.4101\n",
      "Epoch 2287/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.3512 - mae: 9.3399 - val_loss: 3930.2556 - val_mae: 35.8952\n",
      "Epoch 2288/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.4543 - mae: 9.3161 - val_loss: 4001.3235 - val_mae: 35.4602\n",
      "Epoch 2289/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.8150 - mae: 9.6491 - val_loss: 3931.5244 - val_mae: 35.1658\n",
      "Epoch 2290/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.7675 - mae: 9.3222 - val_loss: 4059.1599 - val_mae: 35.6014\n",
      "Epoch 2291/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.0671 - mae: 9.3424 - val_loss: 3991.7004 - val_mae: 35.1284\n",
      "Epoch 2292/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.0552 - mae: 9.3205 - val_loss: 3990.9639 - val_mae: 36.0107\n",
      "Epoch 2293/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 259.1024 - mae: 9.4298 - val_loss: 3903.4380 - val_mae: 34.8881\n",
      "Epoch 2294/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.5461 - mae: 9.4332 - val_loss: 3930.4319 - val_mae: 35.0275\n",
      "Epoch 2295/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.5977 - mae: 9.1541 - val_loss: 4129.7393 - val_mae: 35.2156\n",
      "Epoch 2296/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.6658 - mae: 9.3247 - val_loss: 4051.0056 - val_mae: 35.3862\n",
      "Epoch 2297/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 274.3189 - mae: 9.5523 - val_loss: 3927.7639 - val_mae: 35.1608\n",
      "Epoch 2298/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.9315 - mae: 8.8604 - val_loss: 3851.9062 - val_mae: 34.6504\n",
      "Epoch 2299/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.4468 - mae: 9.2722 - val_loss: 3925.6782 - val_mae: 35.0186\n",
      "Epoch 2300/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.2467 - mae: 9.5076 - val_loss: 3978.6399 - val_mae: 35.5090\n",
      "Epoch 2301/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.3158 - mae: 9.3653 - val_loss: 3887.2979 - val_mae: 35.1708\n",
      "Epoch 2302/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.0653 - mae: 9.3188 - val_loss: 3999.2869 - val_mae: 35.6558\n",
      "Epoch 2303/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.4391 - mae: 9.0513 - val_loss: 3899.5356 - val_mae: 35.2548\n",
      "Epoch 2304/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.6133 - mae: 9.4821 - val_loss: 3921.2644 - val_mae: 34.9264\n",
      "Epoch 2305/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 291.7329 - mae: 9.5575 - val_loss: 4050.3323 - val_mae: 35.6019\n",
      "Epoch 2306/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.4269 - mae: 9.4826 - val_loss: 3911.2869 - val_mae: 35.4722\n",
      "Epoch 2307/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.7599 - mae: 9.5164 - val_loss: 3941.2156 - val_mae: 35.0655\n",
      "Epoch 2308/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.9573 - mae: 9.2546 - val_loss: 4065.6904 - val_mae: 36.3857\n",
      "Epoch 2309/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.7092 - mae: 9.2849 - val_loss: 3981.5818 - val_mae: 35.2247\n",
      "Epoch 2310/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 297.5716 - mae: 9.5899 - val_loss: 4021.3230 - val_mae: 35.8875\n",
      "Epoch 2311/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.7314 - mae: 9.4556 - val_loss: 3978.2292 - val_mae: 34.8577\n",
      "Epoch 2312/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.7720 - mae: 9.3769 - val_loss: 4014.3196 - val_mae: 35.9642\n",
      "Epoch 2313/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.0655 - mae: 9.2538 - val_loss: 3942.8057 - val_mae: 35.2922\n",
      "Epoch 2314/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.5311 - mae: 9.1580 - val_loss: 3907.9814 - val_mae: 35.1376\n",
      "Epoch 2315/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 344.4253 - mae: 10.0185 - val_loss: 3922.7012 - val_mae: 35.1430\n",
      "Epoch 2316/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.1212 - mae: 9.5178 - val_loss: 3900.4915 - val_mae: 34.5329\n",
      "Epoch 2317/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 305.9333 - mae: 9.7839 - val_loss: 3912.0601 - val_mae: 34.7152\n",
      "Epoch 2318/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 311.3317 - mae: 9.6865 - val_loss: 3820.0449 - val_mae: 34.6294\n",
      "Epoch 2319/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.0607 - mae: 9.5902 - val_loss: 3902.8616 - val_mae: 34.5930\n",
      "Epoch 2320/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 268.5587 - mae: 9.4439 - val_loss: 3922.7173 - val_mae: 34.9690\n",
      "Epoch 2321/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 271.5198 - mae: 9.4041 - val_loss: 3912.5183 - val_mae: 34.5840\n",
      "Epoch 2322/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.4910 - mae: 9.5329 - val_loss: 3892.9353 - val_mae: 34.5620\n",
      "Epoch 2323/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.0066 - mae: 9.3671 - val_loss: 3906.9248 - val_mae: 34.5518\n",
      "Epoch 2324/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.7349 - mae: 9.2544 - val_loss: 3958.0315 - val_mae: 35.0072\n",
      "Epoch 2325/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.0921 - mae: 9.4702 - val_loss: 3958.7253 - val_mae: 34.6348\n",
      "Epoch 2326/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.5507 - mae: 9.4367 - val_loss: 3940.4607 - val_mae: 35.1227\n",
      "Epoch 2327/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.3141 - mae: 9.7870 - val_loss: 3917.8650 - val_mae: 35.1675\n",
      "Epoch 2328/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.1062 - mae: 9.4640 - val_loss: 3925.6104 - val_mae: 35.1291\n",
      "Epoch 2329/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 296.9014 - mae: 9.6557 - val_loss: 3995.8235 - val_mae: 35.1294\n",
      "Epoch 2330/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.2922 - mae: 9.1466 - val_loss: 3975.4014 - val_mae: 35.4791\n",
      "Epoch 2331/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.8196 - mae: 9.2514 - val_loss: 3953.8032 - val_mae: 34.9842\n",
      "Epoch 2332/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.7191 - mae: 9.6401 - val_loss: 3909.4565 - val_mae: 34.4707\n",
      "Epoch 2333/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.7968 - mae: 9.5352 - val_loss: 3729.0820 - val_mae: 36.1467\n",
      "Epoch 2334/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 306.7925 - mae: 9.8817 - val_loss: 3909.2642 - val_mae: 34.8227\n",
      "Epoch 2335/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.8169 - mae: 9.5034 - val_loss: 3997.6628 - val_mae: 35.7758\n",
      "Epoch 2336/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 319.9939 - mae: 9.8780 - val_loss: 3957.9641 - val_mae: 34.7712\n",
      "Epoch 2337/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 283.6125 - mae: 9.4866 - val_loss: 3973.9587 - val_mae: 34.9097\n",
      "Epoch 2338/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 283.2795 - mae: 9.7507 - val_loss: 3958.8047 - val_mae: 34.8609\n",
      "Epoch 2339/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.4778 - mae: 9.2796 - val_loss: 3943.3555 - val_mae: 34.9550\n",
      "Epoch 2340/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.6563 - mae: 9.3844 - val_loss: 4001.3201 - val_mae: 35.6265\n",
      "Epoch 2341/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 334.4793 - mae: 10.0043 - val_loss: 4019.3147 - val_mae: 35.5008\n",
      "Epoch 2342/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.5943 - mae: 9.5797 - val_loss: 3941.1277 - val_mae: 35.3404\n",
      "Epoch 2343/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 264.5063 - mae: 9.4669 - val_loss: 3947.8450 - val_mae: 35.3332\n",
      "Epoch 2344/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.7033 - mae: 8.9990 - val_loss: 3830.2500 - val_mae: 35.1855\n",
      "Epoch 2345/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 314.2678 - mae: 9.6829 - val_loss: 3908.5923 - val_mae: 35.2537\n",
      "Epoch 2346/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.4388 - mae: 9.2609 - val_loss: 4077.6267 - val_mae: 35.6865\n",
      "Epoch 2347/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.2468 - mae: 9.0069 - val_loss: 4070.8101 - val_mae: 36.1589\n",
      "Epoch 2348/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.2986 - mae: 9.1187 - val_loss: 4051.6243 - val_mae: 36.0626\n",
      "Epoch 2349/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.8831 - mae: 9.2014 - val_loss: 4028.9983 - val_mae: 35.7578\n",
      "Epoch 2350/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.4743 - mae: 9.4367 - val_loss: 4020.2268 - val_mae: 35.8299\n",
      "Epoch 2351/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.6985 - mae: 9.2182 - val_loss: 4164.6133 - val_mae: 35.9797\n",
      "Epoch 2352/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.4889 - mae: 9.3956 - val_loss: 4020.3770 - val_mae: 35.7275\n",
      "Epoch 2353/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.4034 - mae: 9.7233 - val_loss: 3989.8972 - val_mae: 35.7760\n",
      "Epoch 2354/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.5413 - mae: 9.4314 - val_loss: 3957.0166 - val_mae: 34.8937\n",
      "Epoch 2355/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.9070 - mae: 9.3478 - val_loss: 3980.7053 - val_mae: 35.0077\n",
      "Epoch 2356/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 315.2795 - mae: 9.9226 - val_loss: 4035.4890 - val_mae: 35.7627\n",
      "Epoch 2357/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.2782 - mae: 9.3196 - val_loss: 4047.7012 - val_mae: 35.7956\n",
      "Epoch 2358/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.5189 - mae: 9.4054 - val_loss: 4019.1040 - val_mae: 35.2694\n",
      "Epoch 2359/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.7225 - mae: 8.8717 - val_loss: 4070.5811 - val_mae: 36.2479\n",
      "Epoch 2360/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 277.8976 - mae: 9.3180 - val_loss: 4048.8821 - val_mae: 35.8010\n",
      "Epoch 2361/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.8304 - mae: 8.9895 - val_loss: 3915.0752 - val_mae: 35.0188\n",
      "Epoch 2362/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.4818 - mae: 9.2634 - val_loss: 4041.1511 - val_mae: 35.7291\n",
      "Epoch 2363/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 305.3769 - mae: 9.8195 - val_loss: 4074.9446 - val_mae: 35.2466\n",
      "Epoch 2364/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.3395 - mae: 9.3215 - val_loss: 4039.3188 - val_mae: 35.2089\n",
      "Epoch 2365/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.9258 - mae: 9.1714 - val_loss: 4028.8792 - val_mae: 35.4941\n",
      "Epoch 2366/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.3369 - mae: 9.1817 - val_loss: 3950.4302 - val_mae: 35.7082\n",
      "Epoch 2367/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.5237 - mae: 9.3789 - val_loss: 4051.0767 - val_mae: 35.8684\n",
      "Epoch 2368/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.5609 - mae: 9.2556 - val_loss: 3952.6938 - val_mae: 35.5107\n",
      "Epoch 2369/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.0603 - mae: 9.1360 - val_loss: 4046.1079 - val_mae: 35.2372\n",
      "Epoch 2370/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.0080 - mae: 9.4108 - val_loss: 3994.1023 - val_mae: 35.6031\n",
      "Epoch 2371/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.6891 - mae: 9.4188 - val_loss: 3949.8184 - val_mae: 34.5930\n",
      "Epoch 2372/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.5570 - mae: 9.2955 - val_loss: 4005.6121 - val_mae: 35.2679\n",
      "Epoch 2373/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.9257 - mae: 9.2206 - val_loss: 4099.4565 - val_mae: 35.4410\n",
      "Epoch 2374/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 320.1777 - mae: 9.5686 - val_loss: 3997.3376 - val_mae: 35.2073\n",
      "Epoch 2375/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.3081 - mae: 9.2735 - val_loss: 4028.4390 - val_mae: 35.2892\n",
      "Epoch 2376/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.5662 - mae: 9.5830 - val_loss: 3933.9937 - val_mae: 35.0488\n",
      "Epoch 2377/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 310.2602 - mae: 9.4762 - val_loss: 4026.5920 - val_mae: 35.6893\n",
      "Epoch 2378/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 280.3736 - mae: 9.3912 - val_loss: 4037.0090 - val_mae: 35.5593\n",
      "Epoch 2379/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.1523 - mae: 9.4977 - val_loss: 4117.6431 - val_mae: 35.9121\n",
      "Epoch 2380/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.1937 - mae: 8.8596 - val_loss: 4061.1531 - val_mae: 35.8583\n",
      "Epoch 2381/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 305.2887 - mae: 9.6413 - val_loss: 4017.7209 - val_mae: 35.7999\n",
      "Epoch 2382/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.6263 - mae: 9.3083 - val_loss: 3904.3560 - val_mae: 35.3176\n",
      "Epoch 2383/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.5041 - mae: 9.0808 - val_loss: 4006.6016 - val_mae: 35.3980\n",
      "Epoch 2384/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.6562 - mae: 8.9602 - val_loss: 4047.8853 - val_mae: 36.1195\n",
      "Epoch 2385/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 286.3590 - mae: 9.4297 - val_loss: 3934.2568 - val_mae: 35.5432\n",
      "Epoch 2386/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.3381 - mae: 9.2375 - val_loss: 3948.8770 - val_mae: 35.3167\n",
      "Epoch 2387/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.0771 - mae: 9.1208 - val_loss: 4082.6499 - val_mae: 35.8362\n",
      "Epoch 2388/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.1521 - mae: 9.3421 - val_loss: 3925.6370 - val_mae: 34.9723\n",
      "Epoch 2389/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.1814 - mae: 9.4167 - val_loss: 4029.5652 - val_mae: 35.6948\n",
      "Epoch 2390/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.1562 - mae: 9.4579 - val_loss: 3938.2903 - val_mae: 35.0142\n",
      "Epoch 2391/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.1903 - mae: 9.0400 - val_loss: 3882.6602 - val_mae: 34.7370\n",
      "Epoch 2392/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.3902 - mae: 8.9618 - val_loss: 3875.8701 - val_mae: 34.7533\n",
      "Epoch 2393/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.0780 - mae: 9.0202 - val_loss: 3973.6753 - val_mae: 35.5971\n",
      "Epoch 2394/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.4221 - mae: 9.0569 - val_loss: 3874.9885 - val_mae: 35.3690\n",
      "Epoch 2395/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.2515 - mae: 9.2688 - val_loss: 3815.6709 - val_mae: 34.4040\n",
      "Epoch 2396/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.8938 - mae: 9.5684 - val_loss: 3971.6729 - val_mae: 34.5667\n",
      "Epoch 2397/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.6965 - mae: 9.3390 - val_loss: 3881.3086 - val_mae: 34.5477\n",
      "Epoch 2398/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 310.0338 - mae: 9.8781 - val_loss: 3902.0820 - val_mae: 35.8224\n",
      "Epoch 2399/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 329.3015 - mae: 9.9961 - val_loss: 3963.7781 - val_mae: 34.4485\n",
      "Epoch 2400/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 318.2416 - mae: 9.5042 - val_loss: 3939.8301 - val_mae: 34.7885\n",
      "Epoch 2401/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 297.6451 - mae: 10.6608 - val_loss: 3865.0254 - val_mae: 35.9096\n",
      "Epoch 2402/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 280.3126 - mae: 9.6909 - val_loss: 4016.3235 - val_mae: 35.3940\n",
      "Epoch 2403/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.4689 - mae: 9.2691 - val_loss: 3920.5212 - val_mae: 35.2404\n",
      "Epoch 2404/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 290.3973 - mae: 9.3880 - val_loss: 3953.2959 - val_mae: 34.2488\n",
      "Epoch 2405/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.3262 - mae: 9.4184 - val_loss: 3940.1287 - val_mae: 34.5548\n",
      "Epoch 2406/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.8309 - mae: 9.1678 - val_loss: 3978.9355 - val_mae: 35.0118\n",
      "Epoch 2407/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 259.9547 - mae: 9.1661 - val_loss: 3987.7502 - val_mae: 35.0435\n",
      "Epoch 2408/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.2576 - mae: 9.0979 - val_loss: 3990.0977 - val_mae: 34.8498\n",
      "Epoch 2409/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 268.6197 - mae: 9.1241 - val_loss: 3937.7781 - val_mae: 35.0645\n",
      "Epoch 2410/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.3389 - mae: 9.1925 - val_loss: 3950.2051 - val_mae: 34.9344\n",
      "Epoch 2411/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.7628 - mae: 9.1975 - val_loss: 3892.2266 - val_mae: 35.0743\n",
      "Epoch 2412/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.0310 - mae: 8.9478 - val_loss: 4012.8159 - val_mae: 35.0928\n",
      "Epoch 2413/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.9814 - mae: 9.8098 - val_loss: 3917.6213 - val_mae: 35.4192\n",
      "Epoch 2414/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.9132 - mae: 9.2681 - val_loss: 3841.0330 - val_mae: 34.6711\n",
      "Epoch 2415/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.7118 - mae: 8.8053 - val_loss: 3987.4197 - val_mae: 35.2922\n",
      "Epoch 2416/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.7768 - mae: 8.9898 - val_loss: 3972.8669 - val_mae: 35.4368\n",
      "Epoch 2417/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 240.2030 - mae: 9.2285 - val_loss: 3887.6824 - val_mae: 34.8257\n",
      "Epoch 2418/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.0033 - mae: 8.8047 - val_loss: 3982.1655 - val_mae: 35.1760\n",
      "Epoch 2419/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.8822 - mae: 9.0383 - val_loss: 3834.3308 - val_mae: 34.5998\n",
      "Epoch 2420/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.6645 - mae: 9.0643 - val_loss: 3903.7195 - val_mae: 34.3055\n",
      "Epoch 2421/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.4626 - mae: 8.8948 - val_loss: 3918.5164 - val_mae: 34.8372\n",
      "Epoch 2422/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.7787 - mae: 9.1345 - val_loss: 3953.1050 - val_mae: 34.6398\n",
      "Epoch 2423/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.8622 - mae: 8.8257 - val_loss: 3924.2510 - val_mae: 34.7991\n",
      "Epoch 2424/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 306.4572 - mae: 9.4099 - val_loss: 3870.6257 - val_mae: 34.4302\n",
      "Epoch 2425/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.5832 - mae: 9.2257 - val_loss: 3874.6489 - val_mae: 35.0578\n",
      "Epoch 2426/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.6566 - mae: 9.1000 - val_loss: 4011.4941 - val_mae: 35.4970\n",
      "Epoch 2427/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 331.6270 - mae: 9.9761 - val_loss: 4019.9443 - val_mae: 34.9148\n",
      "Epoch 2428/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.5949 - mae: 9.2608 - val_loss: 4111.5625 - val_mae: 35.3873\n",
      "Epoch 2429/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.9731 - mae: 9.6473 - val_loss: 4021.5066 - val_mae: 34.3978\n",
      "Epoch 2430/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.9657 - mae: 9.2123 - val_loss: 3981.0364 - val_mae: 34.7925\n",
      "Epoch 2431/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.5195 - mae: 8.9867 - val_loss: 3925.2383 - val_mae: 35.0336\n",
      "Epoch 2432/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 318.6962 - mae: 9.8653 - val_loss: 3961.3481 - val_mae: 35.2839\n",
      "Epoch 2433/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 298.7471 - mae: 9.4373 - val_loss: 4113.1279 - val_mae: 35.2445\n",
      "Epoch 2434/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.0775 - mae: 9.2928 - val_loss: 4023.5449 - val_mae: 35.4145\n",
      "Epoch 2435/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.9312 - mae: 9.3113 - val_loss: 4033.6472 - val_mae: 35.8353\n",
      "Epoch 2436/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.5600 - mae: 9.5475 - val_loss: 4014.8296 - val_mae: 35.3580\n",
      "Epoch 2437/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.0285 - mae: 9.4099 - val_loss: 3909.2498 - val_mae: 34.5556\n",
      "Epoch 2438/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.8778 - mae: 9.2328 - val_loss: 3918.2297 - val_mae: 34.9328\n",
      "Epoch 2439/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.9350 - mae: 9.1574 - val_loss: 3960.3137 - val_mae: 35.5290\n",
      "Epoch 2440/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.6021 - mae: 9.1009 - val_loss: 4048.8794 - val_mae: 35.5938\n",
      "Epoch 2441/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.9737 - mae: 9.2309 - val_loss: 3973.9216 - val_mae: 35.9858\n",
      "Epoch 2442/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.9339 - mae: 9.0790 - val_loss: 4056.5481 - val_mae: 36.4436\n",
      "Epoch 2443/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.1577 - mae: 9.1964 - val_loss: 4034.4590 - val_mae: 35.6455\n",
      "Epoch 2444/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.9917 - mae: 9.5538 - val_loss: 3913.3577 - val_mae: 34.3247\n",
      "Epoch 2445/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.5428 - mae: 9.0995 - val_loss: 3923.2234 - val_mae: 34.8273\n",
      "Epoch 2446/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.3435 - mae: 9.0326 - val_loss: 3912.0735 - val_mae: 34.4234\n",
      "Epoch 2447/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.0891 - mae: 9.2372 - val_loss: 4039.6755 - val_mae: 35.6672\n",
      "Epoch 2448/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.4481 - mae: 9.3277 - val_loss: 3939.3882 - val_mae: 35.6164\n",
      "Epoch 2449/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.2483 - mae: 9.3965 - val_loss: 3940.1567 - val_mae: 35.0569\n",
      "Epoch 2450/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.3023 - mae: 9.3784 - val_loss: 3913.8730 - val_mae: 34.9124\n",
      "Epoch 2451/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.7259 - mae: 9.4086 - val_loss: 3953.6001 - val_mae: 35.4031\n",
      "Epoch 2452/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.1727 - mae: 9.4077 - val_loss: 3976.7271 - val_mae: 35.1437\n",
      "Epoch 2453/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.9560 - mae: 9.1381 - val_loss: 4002.1699 - val_mae: 34.9196\n",
      "Epoch 2454/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.2953 - mae: 9.2643 - val_loss: 4050.9194 - val_mae: 35.6549\n",
      "Epoch 2455/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.4548 - mae: 9.1591 - val_loss: 3984.7632 - val_mae: 34.9320\n",
      "Epoch 2456/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.5475 - mae: 9.0293 - val_loss: 4078.3584 - val_mae: 35.7253\n",
      "Epoch 2457/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.5494 - mae: 9.4357 - val_loss: 4082.9404 - val_mae: 35.2544\n",
      "Epoch 2458/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.1076 - mae: 9.0679 - val_loss: 3972.2917 - val_mae: 35.0318\n",
      "Epoch 2459/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.2733 - mae: 9.1350 - val_loss: 4076.0151 - val_mae: 35.4065\n",
      "Epoch 2460/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.8163 - mae: 9.5376 - val_loss: 4154.5566 - val_mae: 35.3771\n",
      "Epoch 2461/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.1146 - mae: 9.2400 - val_loss: 4016.5149 - val_mae: 34.6705\n",
      "Epoch 2462/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.4402 - mae: 9.4029 - val_loss: 3978.4861 - val_mae: 34.6984\n",
      "Epoch 2463/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.4732 - mae: 9.2095 - val_loss: 3925.0137 - val_mae: 35.0467\n",
      "Epoch 2464/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.1083 - mae: 9.3633 - val_loss: 4007.9106 - val_mae: 35.0617\n",
      "Epoch 2465/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.5320 - mae: 9.2927 - val_loss: 3900.8279 - val_mae: 34.3005\n",
      "Epoch 2466/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.8913 - mae: 9.7102 - val_loss: 4068.9753 - val_mae: 35.2296\n",
      "Epoch 2467/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 264.0159 - mae: 9.4370 - val_loss: 3945.4426 - val_mae: 34.9819\n",
      "Epoch 2468/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.3831 - mae: 9.2866 - val_loss: 3911.0769 - val_mae: 34.6641\n",
      "Epoch 2469/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.1522 - mae: 9.2598 - val_loss: 4038.2007 - val_mae: 35.6010\n",
      "Epoch 2470/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.1206 - mae: 9.1909 - val_loss: 3957.9963 - val_mae: 35.0157\n",
      "Epoch 2471/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 311.9539 - mae: 9.5227 - val_loss: 4067.0791 - val_mae: 35.8284\n",
      "Epoch 2472/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.0130 - mae: 9.4540 - val_loss: 3923.9841 - val_mae: 34.9681\n",
      "Epoch 2473/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.9861 - mae: 9.2831 - val_loss: 3970.1702 - val_mae: 34.7497\n",
      "Epoch 2474/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 318.6271 - mae: 9.6133 - val_loss: 3988.5208 - val_mae: 34.5910\n",
      "Epoch 2475/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 387.2181 - mae: 9.9930 - val_loss: 4020.4912 - val_mae: 35.1444\n",
      "Epoch 2476/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.8578 - mae: 9.4989 - val_loss: 3901.7842 - val_mae: 34.4020\n",
      "Epoch 2477/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.8709 - mae: 9.3561 - val_loss: 4008.9109 - val_mae: 35.1777\n",
      "Epoch 2478/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 243.0241 - mae: 9.2160 - val_loss: 4055.6809 - val_mae: 35.5942\n",
      "Epoch 2479/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.9053 - mae: 8.7852 - val_loss: 4046.8547 - val_mae: 35.2513\n",
      "Epoch 2480/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.8257 - mae: 8.9896 - val_loss: 3891.6401 - val_mae: 35.0430\n",
      "Epoch 2481/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.0281 - mae: 9.3841 - val_loss: 3833.6248 - val_mae: 34.5954\n",
      "Epoch 2482/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.8145 - mae: 8.9893 - val_loss: 4097.2437 - val_mae: 35.3229\n",
      "Epoch 2483/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.7693 - mae: 8.8420 - val_loss: 4075.1650 - val_mae: 35.0610\n",
      "Epoch 2484/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.7893 - mae: 9.1508 - val_loss: 3962.7214 - val_mae: 34.8170\n",
      "Epoch 2485/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 250.9603 - mae: 9.5925 - val_loss: 3995.3179 - val_mae: 35.9372\n",
      "Epoch 2486/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.6628 - mae: 9.1308 - val_loss: 4085.9387 - val_mae: 35.4200\n",
      "Epoch 2487/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.9299 - mae: 8.7634 - val_loss: 4154.0508 - val_mae: 35.9863\n",
      "Epoch 2488/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.9253 - mae: 9.1220 - val_loss: 4193.4668 - val_mae: 35.9819\n",
      "Epoch 2489/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.6059 - mae: 8.9558 - val_loss: 4165.5425 - val_mae: 35.8323\n",
      "Epoch 2490/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.9540 - mae: 9.1887 - val_loss: 4109.4893 - val_mae: 35.0157\n",
      "Epoch 2491/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.8237 - mae: 9.3315 - val_loss: 4066.6636 - val_mae: 35.2415\n",
      "Epoch 2492/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.8318 - mae: 9.2690 - val_loss: 4026.1123 - val_mae: 35.0983\n",
      "Epoch 2493/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.8147 - mae: 8.9658 - val_loss: 4114.6006 - val_mae: 35.4830\n",
      "Epoch 2494/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.3117 - mae: 8.8116 - val_loss: 4171.3384 - val_mae: 36.1439\n",
      "Epoch 2495/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.6920 - mae: 9.8865 - val_loss: 4204.3154 - val_mae: 35.1050\n",
      "Epoch 2496/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.8514 - mae: 9.1021 - val_loss: 4039.9795 - val_mae: 35.0808\n",
      "Epoch 2497/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.1365 - mae: 8.8709 - val_loss: 4068.9502 - val_mae: 35.4213\n",
      "Epoch 2498/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.8918 - mae: 8.7592 - val_loss: 4016.1372 - val_mae: 35.5447\n",
      "Epoch 2499/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.5131 - mae: 8.8252 - val_loss: 4153.7153 - val_mae: 35.6260\n",
      "Epoch 2500/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.2509 - mae: 9.0655 - val_loss: 4087.2336 - val_mae: 35.5225\n",
      "Epoch 2501/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 300.9198 - mae: 9.4592 - val_loss: 4018.9939 - val_mae: 35.0206\n",
      "Epoch 2502/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.4783 - mae: 9.2839 - val_loss: 4175.0977 - val_mae: 36.2076\n",
      "Epoch 2503/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.5174 - mae: 9.0885 - val_loss: 4041.0518 - val_mae: 35.4361\n",
      "Epoch 2504/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.9342 - mae: 9.0243 - val_loss: 3990.2690 - val_mae: 35.3216\n",
      "Epoch 2505/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.2704 - mae: 9.3197 - val_loss: 4080.1733 - val_mae: 35.9656\n",
      "Epoch 2506/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.1549 - mae: 9.4194 - val_loss: 4161.4165 - val_mae: 35.7848\n",
      "Epoch 2507/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.9496 - mae: 9.7836 - val_loss: 4063.9780 - val_mae: 35.8155\n",
      "Epoch 2508/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.9893 - mae: 9.0835 - val_loss: 4143.0205 - val_mae: 36.0641\n",
      "Epoch 2509/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.2204 - mae: 9.1821 - val_loss: 3982.3616 - val_mae: 35.2758\n",
      "Epoch 2510/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.6719 - mae: 9.1398 - val_loss: 4068.5791 - val_mae: 35.7078\n",
      "Epoch 2511/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 313.4882 - mae: 9.6462 - val_loss: 4168.1094 - val_mae: 35.5534\n",
      "Epoch 2512/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 309.6658 - mae: 9.6139 - val_loss: 4139.2974 - val_mae: 35.7298\n",
      "Epoch 2513/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.2513 - mae: 9.3713 - val_loss: 4061.0337 - val_mae: 35.5704\n",
      "Epoch 2514/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.7759 - mae: 9.0818 - val_loss: 4047.7786 - val_mae: 34.9025\n",
      "Epoch 2515/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 337.6287 - mae: 9.7812 - val_loss: 3990.3242 - val_mae: 35.5142\n",
      "Epoch 2516/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.8190 - mae: 8.9310 - val_loss: 4066.0435 - val_mae: 35.2287\n",
      "Epoch 2517/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 259.3055 - mae: 9.2949 - val_loss: 3981.0754 - val_mae: 35.0800\n",
      "Epoch 2518/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.1843 - mae: 9.2069 - val_loss: 4035.8152 - val_mae: 35.6514\n",
      "Epoch 2519/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.9435 - mae: 9.1836 - val_loss: 4076.9548 - val_mae: 35.1389\n",
      "Epoch 2520/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.9560 - mae: 9.1876 - val_loss: 4074.7898 - val_mae: 35.5801\n",
      "Epoch 2521/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.8517 - mae: 9.0866 - val_loss: 4013.5415 - val_mae: 35.6992\n",
      "Epoch 2522/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.7200 - mae: 9.2558 - val_loss: 4052.9194 - val_mae: 35.5752\n",
      "Epoch 2523/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.5534 - mae: 8.9364 - val_loss: 4073.7051 - val_mae: 35.4439\n",
      "Epoch 2524/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 286.6723 - mae: 9.2296 - val_loss: 4027.5745 - val_mae: 35.8055\n",
      "Epoch 2525/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.7667 - mae: 9.2260 - val_loss: 4032.9707 - val_mae: 35.6637\n",
      "Epoch 2526/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.1974 - mae: 9.0585 - val_loss: 4050.7988 - val_mae: 35.7627\n",
      "Epoch 2527/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.8541 - mae: 8.9091 - val_loss: 3987.9453 - val_mae: 35.3769\n",
      "Epoch 2528/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.7037 - mae: 9.1190 - val_loss: 3936.8992 - val_mae: 34.9541\n",
      "Epoch 2529/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.5917 - mae: 9.0477 - val_loss: 4044.6738 - val_mae: 35.5958\n",
      "Epoch 2530/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.1002 - mae: 8.9345 - val_loss: 3978.6309 - val_mae: 34.9409\n",
      "Epoch 2531/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.4722 - mae: 9.1465 - val_loss: 4109.2285 - val_mae: 35.3076\n",
      "Epoch 2532/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.8312 - mae: 9.2751 - val_loss: 4055.1636 - val_mae: 35.9800\n",
      "Epoch 2533/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.6064 - mae: 8.7077 - val_loss: 3936.5132 - val_mae: 35.2126\n",
      "Epoch 2534/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.7428 - mae: 9.3575 - val_loss: 4078.1230 - val_mae: 35.9988\n",
      "Epoch 2535/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.9237 - mae: 9.3954 - val_loss: 4112.4146 - val_mae: 35.8186\n",
      "Epoch 2536/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.6698 - mae: 9.2937 - val_loss: 4106.6616 - val_mae: 35.9773\n",
      "Epoch 2537/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.8189 - mae: 8.7728 - val_loss: 4122.5591 - val_mae: 35.9487\n",
      "Epoch 2538/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 296.8519 - mae: 9.2530 - val_loss: 4021.1069 - val_mae: 35.0402\n",
      "Epoch 2539/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.5860 - mae: 8.6979 - val_loss: 4102.4629 - val_mae: 35.3140\n",
      "Epoch 2540/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 222.1440 - mae: 8.9928 - val_loss: 4191.6128 - val_mae: 35.9114\n",
      "Epoch 2541/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.3614 - mae: 8.9088 - val_loss: 4201.2466 - val_mae: 36.0440\n",
      "Epoch 2542/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.9742 - mae: 9.0402 - val_loss: 4029.8901 - val_mae: 35.2919\n",
      "Epoch 2543/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 286.4464 - mae: 9.4834 - val_loss: 3980.5969 - val_mae: 35.6659\n",
      "Epoch 2544/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.8389 - mae: 9.0233 - val_loss: 4007.2544 - val_mae: 35.2060\n",
      "Epoch 2545/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 291.4966 - mae: 9.2962 - val_loss: 3968.0933 - val_mae: 34.6360\n",
      "Epoch 2546/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.5229 - mae: 9.2374 - val_loss: 4064.7327 - val_mae: 35.7443\n",
      "Epoch 2547/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.2277 - mae: 9.1775 - val_loss: 4105.1641 - val_mae: 35.6967\n",
      "Epoch 2548/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 319.2024 - mae: 9.7559 - val_loss: 3956.8733 - val_mae: 35.3894\n",
      "Epoch 2549/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.4383 - mae: 8.8260 - val_loss: 4018.9304 - val_mae: 35.7902\n",
      "Epoch 2550/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.0687 - mae: 9.0732 - val_loss: 3997.1289 - val_mae: 35.6611\n",
      "Epoch 2551/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.1245 - mae: 8.8565 - val_loss: 4085.1970 - val_mae: 35.6566\n",
      "Epoch 2552/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.8951 - mae: 9.2531 - val_loss: 4061.7258 - val_mae: 34.9850\n",
      "Epoch 2553/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.9878 - mae: 8.9800 - val_loss: 3945.1768 - val_mae: 35.2549\n",
      "Epoch 2554/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.3607 - mae: 9.1055 - val_loss: 3988.3181 - val_mae: 35.3465\n",
      "Epoch 2555/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.7476 - mae: 9.2153 - val_loss: 4018.3950 - val_mae: 36.1420\n",
      "Epoch 2556/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.6818 - mae: 9.3290 - val_loss: 3937.8918 - val_mae: 35.0122\n",
      "Epoch 2557/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.1080 - mae: 9.2864 - val_loss: 3887.3870 - val_mae: 35.4349\n",
      "Epoch 2558/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.3049 - mae: 9.1218 - val_loss: 3969.6252 - val_mae: 35.3345\n",
      "Epoch 2559/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.2755 - mae: 9.4627 - val_loss: 3970.9153 - val_mae: 35.0447\n",
      "Epoch 2560/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 302.3267 - mae: 9.5691 - val_loss: 4155.3691 - val_mae: 36.2113\n",
      "Epoch 2561/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.3538 - mae: 9.1056 - val_loss: 4095.9043 - val_mae: 35.4782\n",
      "Epoch 2562/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.7339 - mae: 9.2520 - val_loss: 4076.0327 - val_mae: 35.6739\n",
      "Epoch 2563/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.6069 - mae: 9.0397 - val_loss: 4092.9414 - val_mae: 36.0399\n",
      "Epoch 2564/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.0311 - mae: 8.9827 - val_loss: 4075.9038 - val_mae: 35.4095\n",
      "Epoch 2565/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.9760 - mae: 8.9092 - val_loss: 4051.8242 - val_mae: 35.6413\n",
      "Epoch 2566/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.5028 - mae: 9.7138 - val_loss: 4194.3882 - val_mae: 36.1332\n",
      "Epoch 2567/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.4853 - mae: 9.2239 - val_loss: 4111.6675 - val_mae: 36.2579\n",
      "Epoch 2568/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 273.9780 - mae: 9.3984 - val_loss: 4059.9146 - val_mae: 36.3056\n",
      "Epoch 2569/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.3163 - mae: 9.6550 - val_loss: 4176.5815 - val_mae: 36.1230\n",
      "Epoch 2570/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 280.2209 - mae: 9.4352 - val_loss: 4112.1465 - val_mae: 36.0840\n",
      "Epoch 2571/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 342.0593 - mae: 9.8704 - val_loss: 4160.4448 - val_mae: 36.2054\n",
      "Epoch 2572/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.1545 - mae: 9.8178 - val_loss: 4200.2520 - val_mae: 35.8942\n",
      "Epoch 2573/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.8493 - mae: 8.7796 - val_loss: 4106.9365 - val_mae: 35.9408\n",
      "Epoch 2574/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.3786 - mae: 9.2099 - val_loss: 3997.4963 - val_mae: 35.3446\n",
      "Epoch 2575/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.6575 - mae: 9.1508 - val_loss: 3983.0078 - val_mae: 35.3939\n",
      "Epoch 2576/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.9974 - mae: 9.3422 - val_loss: 3988.0991 - val_mae: 34.9051\n",
      "Epoch 2577/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.5046 - mae: 9.0713 - val_loss: 4030.0999 - val_mae: 35.1039\n",
      "Epoch 2578/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.0516 - mae: 9.1893 - val_loss: 4014.8848 - val_mae: 35.4005\n",
      "Epoch 2579/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.3574 - mae: 9.1297 - val_loss: 3981.8445 - val_mae: 34.8120\n",
      "Epoch 2580/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.6939 - mae: 9.0718 - val_loss: 3970.2727 - val_mae: 35.2266\n",
      "Epoch 2581/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.6410 - mae: 9.0199 - val_loss: 4029.2888 - val_mae: 35.2025\n",
      "Epoch 2582/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.9099 - mae: 8.6437 - val_loss: 4025.4995 - val_mae: 34.9027\n",
      "Epoch 2583/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.2509 - mae: 9.0166 - val_loss: 4027.4241 - val_mae: 34.3859\n",
      "Epoch 2584/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.9124 - mae: 9.0372 - val_loss: 4098.5796 - val_mae: 35.5267\n",
      "Epoch 2585/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.1928 - mae: 9.1553 - val_loss: 3987.3879 - val_mae: 35.1125\n",
      "Epoch 2586/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.6991 - mae: 9.1695 - val_loss: 4048.2385 - val_mae: 35.7265\n",
      "Epoch 2587/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.0132 - mae: 8.9240 - val_loss: 4122.6323 - val_mae: 35.8217\n",
      "Epoch 2588/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.0689 - mae: 8.9782 - val_loss: 3980.8311 - val_mae: 34.7960\n",
      "Epoch 2589/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.6816 - mae: 9.0534 - val_loss: 4107.8013 - val_mae: 35.1253\n",
      "Epoch 2590/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.0064 - mae: 9.2038 - val_loss: 3977.7410 - val_mae: 35.0434\n",
      "Epoch 2591/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.5638 - mae: 8.9646 - val_loss: 4128.8516 - val_mae: 35.5852\n",
      "Epoch 2592/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.5311 - mae: 8.9930 - val_loss: 4099.2935 - val_mae: 35.9476\n",
      "Epoch 2593/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.7157 - mae: 9.1355 - val_loss: 4105.0684 - val_mae: 35.1464\n",
      "Epoch 2594/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.9788 - mae: 9.1995 - val_loss: 4012.5420 - val_mae: 35.5947\n",
      "Epoch 2595/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 282.9351 - mae: 9.3914 - val_loss: 3949.4243 - val_mae: 34.6008\n",
      "Epoch 2596/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 248.7384 - mae: 8.8893 - val_loss: 4031.4490 - val_mae: 35.2166\n",
      "Epoch 2597/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.6259 - mae: 9.2766 - val_loss: 3999.1589 - val_mae: 35.0785\n",
      "Epoch 2598/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 289.1898 - mae: 9.3391 - val_loss: 3915.1172 - val_mae: 34.8680\n",
      "Epoch 2599/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.5668 - mae: 9.3913 - val_loss: 4031.2839 - val_mae: 35.5609\n",
      "Epoch 2600/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.7422 - mae: 9.4053 - val_loss: 4013.3809 - val_mae: 35.0594\n",
      "Epoch 2601/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.0978 - mae: 9.6049 - val_loss: 3968.9272 - val_mae: 35.2854\n",
      "Epoch 2602/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 320.7782 - mae: 9.4881 - val_loss: 3947.9729 - val_mae: 34.9269\n",
      "Epoch 2603/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 317.7852 - mae: 9.6257 - val_loss: 3968.5657 - val_mae: 34.9530\n",
      "Epoch 2604/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.2644 - mae: 9.0093 - val_loss: 3849.5928 - val_mae: 34.6698\n",
      "Epoch 2605/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 294.3083 - mae: 9.3138 - val_loss: 3886.6372 - val_mae: 34.7769\n",
      "Epoch 2606/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 308.6921 - mae: 9.6782 - val_loss: 3916.6113 - val_mae: 34.3311\n",
      "Epoch 2607/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 248.9238 - mae: 9.2529 - val_loss: 3963.1577 - val_mae: 34.7565\n",
      "Epoch 2608/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 280.9209 - mae: 9.3859 - val_loss: 3921.7405 - val_mae: 34.9186\n",
      "Epoch 2609/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 284.7139 - mae: 9.2110 - val_loss: 3849.1748 - val_mae: 34.3532\n",
      "Epoch 2610/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 264.6150 - mae: 9.0068 - val_loss: 3939.1084 - val_mae: 35.1099\n",
      "Epoch 2611/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.2517 - mae: 9.0547 - val_loss: 3996.2483 - val_mae: 35.4704\n",
      "Epoch 2612/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.3281 - mae: 9.4812 - val_loss: 4099.8291 - val_mae: 35.4380\n",
      "Epoch 2613/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.1655 - mae: 9.1182 - val_loss: 4094.4756 - val_mae: 35.7950\n",
      "Epoch 2614/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.4394 - mae: 9.0293 - val_loss: 4009.2498 - val_mae: 35.6158\n",
      "Epoch 2615/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.7006 - mae: 9.0188 - val_loss: 3978.0217 - val_mae: 35.2022\n",
      "Epoch 2616/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.1170 - mae: 9.1351 - val_loss: 3967.7651 - val_mae: 35.2615\n",
      "Epoch 2617/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.5169 - mae: 8.8893 - val_loss: 3967.1082 - val_mae: 35.1313\n",
      "Epoch 2618/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.5942 - mae: 9.0754 - val_loss: 4037.0149 - val_mae: 35.2868\n",
      "Epoch 2619/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.6095 - mae: 9.1703 - val_loss: 3888.3350 - val_mae: 34.8017\n",
      "Epoch 2620/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.2893 - mae: 9.2081 - val_loss: 4046.4573 - val_mae: 36.4848\n",
      "Epoch 2621/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.8608 - mae: 8.8810 - val_loss: 4117.4136 - val_mae: 35.9018\n",
      "Epoch 2622/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.9943 - mae: 9.0633 - val_loss: 4017.9836 - val_mae: 35.1521\n",
      "Epoch 2623/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.3080 - mae: 9.2515 - val_loss: 3994.6697 - val_mae: 34.6665\n",
      "Epoch 2624/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.2648 - mae: 9.0497 - val_loss: 4131.4033 - val_mae: 35.4141\n",
      "Epoch 2625/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.1545 - mae: 9.3038 - val_loss: 4147.0356 - val_mae: 35.6484\n",
      "Epoch 2626/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.8920 - mae: 9.2703 - val_loss: 4142.2798 - val_mae: 35.7876\n",
      "Epoch 2627/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.5287 - mae: 8.9141 - val_loss: 3978.2959 - val_mae: 35.0897\n",
      "Epoch 2628/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.5595 - mae: 8.8258 - val_loss: 4179.4868 - val_mae: 35.9334\n",
      "Epoch 2629/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.1467 - mae: 9.2541 - val_loss: 4079.5159 - val_mae: 35.4763\n",
      "Epoch 2630/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.1236 - mae: 9.1793 - val_loss: 3969.7078 - val_mae: 35.0855\n",
      "Epoch 2631/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.4423 - mae: 8.8194 - val_loss: 4111.3110 - val_mae: 35.7962\n",
      "Epoch 2632/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.5265 - mae: 8.9612 - val_loss: 3990.7107 - val_mae: 35.7988\n",
      "Epoch 2633/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.5644 - mae: 8.9732 - val_loss: 4113.6587 - val_mae: 35.6413\n",
      "Epoch 2634/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.3624 - mae: 8.7139 - val_loss: 4050.7063 - val_mae: 35.5289\n",
      "Epoch 2635/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.8253 - mae: 8.6353 - val_loss: 4053.3416 - val_mae: 35.5516\n",
      "Epoch 2636/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2317 - mae: 8.7996 - val_loss: 3990.1885 - val_mae: 35.4315\n",
      "Epoch 2637/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.3661 - mae: 9.0620 - val_loss: 3990.5906 - val_mae: 35.0767\n",
      "Epoch 2638/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.7286 - mae: 8.6997 - val_loss: 3914.7737 - val_mae: 34.9216\n",
      "Epoch 2639/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.9519 - mae: 8.6777 - val_loss: 4130.3940 - val_mae: 36.4965\n",
      "Epoch 2640/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.6391 - mae: 8.9659 - val_loss: 4194.3857 - val_mae: 36.4237\n",
      "Epoch 2641/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.0699 - mae: 8.9556 - val_loss: 4117.5420 - val_mae: 35.9529\n",
      "Epoch 2642/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.2122 - mae: 8.7656 - val_loss: 4088.7883 - val_mae: 35.9199\n",
      "Epoch 2643/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.7495 - mae: 8.6793 - val_loss: 3931.7656 - val_mae: 35.0273\n",
      "Epoch 2644/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.3991 - mae: 8.9315 - val_loss: 4140.9077 - val_mae: 35.9692\n",
      "Epoch 2645/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.8402 - mae: 8.3215 - val_loss: 4053.3743 - val_mae: 35.8119\n",
      "Epoch 2646/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.0789 - mae: 8.7234 - val_loss: 4148.8574 - val_mae: 36.7070\n",
      "Epoch 2647/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 244.2079 - mae: 8.9890 - val_loss: 3987.4441 - val_mae: 35.7349\n",
      "Epoch 2648/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.6699 - mae: 8.6283 - val_loss: 4079.4895 - val_mae: 35.8309\n",
      "Epoch 2649/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.1612 - mae: 8.7762 - val_loss: 4113.0342 - val_mae: 36.1534\n",
      "Epoch 2650/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.7537 - mae: 8.8132 - val_loss: 4169.4336 - val_mae: 36.1471\n",
      "Epoch 2651/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.1264 - mae: 8.7657 - val_loss: 4096.1089 - val_mae: 36.1144\n",
      "Epoch 2652/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.3686 - mae: 8.6519 - val_loss: 4096.5708 - val_mae: 36.3415\n",
      "Epoch 2653/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.5194 - mae: 9.0292 - val_loss: 4148.5405 - val_mae: 35.8664\n",
      "Epoch 2654/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.7351 - mae: 8.6483 - val_loss: 4099.4316 - val_mae: 35.6946\n",
      "Epoch 2655/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.5608 - mae: 8.8448 - val_loss: 4172.2188 - val_mae: 36.1438\n",
      "Epoch 2656/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.9256 - mae: 8.9141 - val_loss: 4160.0488 - val_mae: 36.2272\n",
      "Epoch 2657/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.5598 - mae: 8.8218 - val_loss: 4037.4189 - val_mae: 36.0133\n",
      "Epoch 2658/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.5881 - mae: 9.0880 - val_loss: 4222.0615 - val_mae: 35.9180\n",
      "Epoch 2659/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.7194 - mae: 9.0397 - val_loss: 4144.0454 - val_mae: 35.7884\n",
      "Epoch 2660/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.9387 - mae: 8.8871 - val_loss: 4022.3723 - val_mae: 35.6809\n",
      "Epoch 2661/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.4028 - mae: 8.5232 - val_loss: 4034.7749 - val_mae: 35.5214\n",
      "Epoch 2662/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 206.6317 - mae: 8.7086 - val_loss: 3972.5442 - val_mae: 35.5251\n",
      "Epoch 2663/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.5688 - mae: 9.0872 - val_loss: 4085.1201 - val_mae: 35.8667\n",
      "Epoch 2664/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.8750 - mae: 8.8109 - val_loss: 4216.3257 - val_mae: 36.0451\n",
      "Epoch 2665/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 243.9862 - mae: 8.9435 - val_loss: 4165.0464 - val_mae: 36.0479\n",
      "Epoch 2666/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.5377 - mae: 9.0645 - val_loss: 4087.0671 - val_mae: 35.9426\n",
      "Epoch 2667/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.7639 - mae: 9.4768 - val_loss: 4138.0405 - val_mae: 37.6792\n",
      "Epoch 2668/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.0205 - mae: 9.4364 - val_loss: 4183.4805 - val_mae: 36.1674\n",
      "Epoch 2669/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.6216 - mae: 8.9580 - val_loss: 4096.2173 - val_mae: 36.2334\n",
      "Epoch 2670/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.1064 - mae: 8.8456 - val_loss: 4149.2998 - val_mae: 36.0856\n",
      "Epoch 2671/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.9861 - mae: 8.5454 - val_loss: 4000.9028 - val_mae: 35.7362\n",
      "Epoch 2672/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.9086 - mae: 8.7710 - val_loss: 4245.6699 - val_mae: 36.1320\n",
      "Epoch 2673/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.1868 - mae: 8.7054 - val_loss: 3997.6680 - val_mae: 35.3919\n",
      "Epoch 2674/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.1209 - mae: 8.5599 - val_loss: 4134.2812 - val_mae: 35.6779\n",
      "Epoch 2675/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.9826 - mae: 8.3878 - val_loss: 4198.4209 - val_mae: 36.1326\n",
      "Epoch 2676/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.4741 - mae: 8.9120 - val_loss: 4133.7646 - val_mae: 36.0188\n",
      "Epoch 2677/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.8903 - mae: 8.7312 - val_loss: 4265.2979 - val_mae: 36.3593\n",
      "Epoch 2678/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.2350 - mae: 9.2127 - val_loss: 4096.7095 - val_mae: 35.4829\n",
      "Epoch 2679/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 324.6097 - mae: 9.8179 - val_loss: 4091.7429 - val_mae: 35.8758\n",
      "Epoch 2680/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 277.0368 - mae: 9.3430 - val_loss: 4022.4697 - val_mae: 35.9128\n",
      "Epoch 2681/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 281.3060 - mae: 9.3643 - val_loss: 4038.5706 - val_mae: 35.6149\n",
      "Epoch 2682/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.5102 - mae: 8.8238 - val_loss: 4176.6924 - val_mae: 35.7963\n",
      "Epoch 2683/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.0271 - mae: 8.6828 - val_loss: 4016.6292 - val_mae: 35.6476\n",
      "Epoch 2684/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.2028 - mae: 8.8446 - val_loss: 4203.9614 - val_mae: 36.1597\n",
      "Epoch 2685/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 221.6284 - mae: 8.5487 - val_loss: 4001.5862 - val_mae: 35.3504\n",
      "Epoch 2686/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.3874 - mae: 8.6705 - val_loss: 4133.1704 - val_mae: 35.9671\n",
      "Epoch 2687/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.8397 - mae: 8.5861 - val_loss: 3966.9368 - val_mae: 35.0479\n",
      "Epoch 2688/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.6241 - mae: 8.9097 - val_loss: 4016.8535 - val_mae: 35.2171\n",
      "Epoch 2689/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.7727 - mae: 8.7196 - val_loss: 4061.5203 - val_mae: 35.5572\n",
      "Epoch 2690/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.5072 - mae: 8.8427 - val_loss: 4034.5754 - val_mae: 34.7717\n",
      "Epoch 2691/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 222.7619 - mae: 8.5107 - val_loss: 3972.7588 - val_mae: 35.3787\n",
      "Epoch 2692/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.4482 - mae: 8.6699 - val_loss: 4062.1216 - val_mae: 35.1087\n",
      "Epoch 2693/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.3959 - mae: 8.7795 - val_loss: 4044.9753 - val_mae: 35.6530\n",
      "Epoch 2694/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.3897 - mae: 9.1266 - val_loss: 4059.2339 - val_mae: 36.2846\n",
      "Epoch 2695/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 225.7690 - mae: 8.8515 - val_loss: 4102.4146 - val_mae: 36.1763\n",
      "Epoch 2696/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 274.8065 - mae: 9.2050 - val_loss: 4058.7871 - val_mae: 35.7565\n",
      "Epoch 2697/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.5291 - mae: 8.7889 - val_loss: 4040.1824 - val_mae: 35.2316\n",
      "Epoch 2698/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.3242 - mae: 9.0747 - val_loss: 4125.3315 - val_mae: 35.4417\n",
      "Epoch 2699/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.8979 - mae: 9.1341 - val_loss: 3960.3872 - val_mae: 35.2246\n",
      "Epoch 2700/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.6822 - mae: 8.7425 - val_loss: 3883.0784 - val_mae: 34.8491\n",
      "Epoch 2701/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.8873 - mae: 9.5799 - val_loss: 4117.6064 - val_mae: 35.7962\n",
      "Epoch 2702/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.8089 - mae: 8.8515 - val_loss: 4037.9243 - val_mae: 35.1655\n",
      "Epoch 2703/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 286.5802 - mae: 9.9217 - val_loss: 3943.3914 - val_mae: 36.5419\n",
      "Epoch 2704/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.7551 - mae: 10.0089 - val_loss: 4000.2778 - val_mae: 35.9030\n",
      "Epoch 2705/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.5215 - mae: 8.9504 - val_loss: 4076.2046 - val_mae: 35.4962\n",
      "Epoch 2706/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.8043 - mae: 9.0377 - val_loss: 3985.6401 - val_mae: 35.5366\n",
      "Epoch 2707/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.5595 - mae: 9.3112 - val_loss: 3973.3059 - val_mae: 35.1860\n",
      "Epoch 2708/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 259.6784 - mae: 9.2588 - val_loss: 3951.9324 - val_mae: 35.2002\n",
      "Epoch 2709/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.4265 - mae: 8.7505 - val_loss: 3949.2307 - val_mae: 35.3209\n",
      "Epoch 2710/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 274.5818 - mae: 9.2397 - val_loss: 4054.8499 - val_mae: 36.4522\n",
      "Epoch 2711/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 313.3888 - mae: 9.6214 - val_loss: 4045.7734 - val_mae: 35.6051\n",
      "Epoch 2712/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.9764 - mae: 8.7749 - val_loss: 4039.0791 - val_mae: 35.5959\n",
      "Epoch 2713/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.7076 - mae: 8.7663 - val_loss: 4052.4006 - val_mae: 36.0790\n",
      "Epoch 2714/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.1830 - mae: 8.7683 - val_loss: 4020.2568 - val_mae: 35.8616\n",
      "Epoch 2715/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.8790 - mae: 8.9327 - val_loss: 4076.3630 - val_mae: 36.0071\n",
      "Epoch 2716/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.0811 - mae: 8.8334 - val_loss: 3965.0657 - val_mae: 35.5473\n",
      "Epoch 2717/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.6259 - mae: 8.7530 - val_loss: 3920.1667 - val_mae: 35.4743\n",
      "Epoch 2718/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.2647 - mae: 8.7974 - val_loss: 4051.6045 - val_mae: 35.7935\n",
      "Epoch 2719/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.5480 - mae: 8.7004 - val_loss: 3977.0229 - val_mae: 36.3209\n",
      "Epoch 2720/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.0956 - mae: 8.9563 - val_loss: 4117.7090 - val_mae: 35.8105\n",
      "Epoch 2721/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.2752 - mae: 8.6420 - val_loss: 4147.2036 - val_mae: 36.0283\n",
      "Epoch 2722/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.7809 - mae: 8.6213 - val_loss: 4173.1997 - val_mae: 35.9784\n",
      "Epoch 2723/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.1330 - mae: 8.4440 - val_loss: 4116.2241 - val_mae: 35.8453\n",
      "Epoch 2724/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.0230 - mae: 8.8587 - val_loss: 4074.6079 - val_mae: 35.6259\n",
      "Epoch 2725/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.2011 - mae: 9.2135 - val_loss: 4089.9709 - val_mae: 36.5718\n",
      "Epoch 2726/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.9688 - mae: 9.0193 - val_loss: 4088.3335 - val_mae: 35.6461\n",
      "Epoch 2727/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.6451 - mae: 9.0367 - val_loss: 4039.8315 - val_mae: 35.8599\n",
      "Epoch 2728/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.5455 - mae: 8.6997 - val_loss: 4090.1646 - val_mae: 35.8928\n",
      "Epoch 2729/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.9686 - mae: 8.8190 - val_loss: 4185.8296 - val_mae: 36.2009\n",
      "Epoch 2730/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.8924 - mae: 9.0140 - val_loss: 4041.7878 - val_mae: 35.9451\n",
      "Epoch 2731/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.6753 - mae: 8.6945 - val_loss: 4153.7271 - val_mae: 36.0686\n",
      "Epoch 2732/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.6857 - mae: 8.8043 - val_loss: 4129.9287 - val_mae: 36.2728\n",
      "Epoch 2733/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.7591 - mae: 8.7415 - val_loss: 4076.8906 - val_mae: 35.5821\n",
      "Epoch 2734/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.3686 - mae: 8.7682 - val_loss: 4118.9995 - val_mae: 35.9635\n",
      "Epoch 2735/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.0342 - mae: 8.8283 - val_loss: 4118.8877 - val_mae: 35.9459\n",
      "Epoch 2736/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2451 - mae: 8.6486 - val_loss: 4129.4077 - val_mae: 35.9083\n",
      "Epoch 2737/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.5712 - mae: 8.8911 - val_loss: 4135.7119 - val_mae: 36.1746\n",
      "Epoch 2738/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.9886 - mae: 8.5689 - val_loss: 4089.4880 - val_mae: 36.1433\n",
      "Epoch 2739/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.1881 - mae: 8.9249 - val_loss: 4091.7573 - val_mae: 36.4282\n",
      "Epoch 2740/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.8665 - mae: 8.5717 - val_loss: 4037.0071 - val_mae: 35.7324\n",
      "Epoch 2741/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.6690 - mae: 8.6957 - val_loss: 4068.8599 - val_mae: 36.1801\n",
      "Epoch 2742/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.2982 - mae: 8.5536 - val_loss: 4128.3423 - val_mae: 36.8659\n",
      "Epoch 2743/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.5421 - mae: 9.1483 - val_loss: 3990.3669 - val_mae: 35.7352\n",
      "Epoch 2744/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 263.5422 - mae: 9.1981 - val_loss: 4115.6655 - val_mae: 35.9176\n",
      "Epoch 2745/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.4799 - mae: 8.7857 - val_loss: 4179.6245 - val_mae: 35.9828\n",
      "Epoch 2746/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.6784 - mae: 9.2457 - val_loss: 4148.1426 - val_mae: 36.3225\n",
      "Epoch 2747/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 225.6785 - mae: 8.9383 - val_loss: 4131.6279 - val_mae: 35.9307\n",
      "Epoch 2748/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.3695 - mae: 8.7204 - val_loss: 4075.1609 - val_mae: 35.5735\n",
      "Epoch 2749/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.1285 - mae: 8.6779 - val_loss: 4170.3911 - val_mae: 35.7963\n",
      "Epoch 2750/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.2265 - mae: 8.8705 - val_loss: 4130.4771 - val_mae: 35.3096\n",
      "Epoch 2751/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 345.6912 - mae: 9.9158 - val_loss: 4114.6265 - val_mae: 35.8181\n",
      "Epoch 2752/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 300.7148 - mae: 9.6919 - val_loss: 4221.2607 - val_mae: 35.7631\n",
      "Epoch 2753/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 351.5727 - mae: 9.9573 - val_loss: 4078.2627 - val_mae: 35.2537\n",
      "Epoch 2754/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 287.8965 - mae: 9.3610 - val_loss: 4226.8916 - val_mae: 36.0333\n",
      "Epoch 2755/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.7179 - mae: 9.3055 - val_loss: 4109.4165 - val_mae: 35.6013\n",
      "Epoch 2756/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 306.0258 - mae: 9.6167 - val_loss: 4242.0527 - val_mae: 35.7350\n",
      "Epoch 2757/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 309.2936 - mae: 10.3046 - val_loss: 4073.9478 - val_mae: 37.4484\n",
      "Epoch 2758/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 279.2820 - mae: 9.9291 - val_loss: 4234.1885 - val_mae: 36.0778\n",
      "Epoch 2759/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 290.4884 - mae: 9.3534 - val_loss: 4042.0889 - val_mae: 35.8667\n",
      "Epoch 2760/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.1774 - mae: 9.3284 - val_loss: 4175.2295 - val_mae: 35.7323\n",
      "Epoch 2761/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 344.0966 - mae: 9.4381 - val_loss: 4178.8911 - val_mae: 36.6839\n",
      "Epoch 2762/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 288.1088 - mae: 9.6486 - val_loss: 4180.7495 - val_mae: 36.6342\n",
      "Epoch 2763/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 283.3672 - mae: 9.4432 - val_loss: 4113.0820 - val_mae: 36.0895\n",
      "Epoch 2764/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.5451 - mae: 8.6911 - val_loss: 4162.2236 - val_mae: 36.1745\n",
      "Epoch 2765/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.7578 - mae: 9.2529 - val_loss: 4131.4863 - val_mae: 35.8626\n",
      "Epoch 2766/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.8866 - mae: 9.0968 - val_loss: 4110.4741 - val_mae: 36.3017\n",
      "Epoch 2767/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.1691 - mae: 9.3549 - val_loss: 4063.0781 - val_mae: 35.4524\n",
      "Epoch 2768/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.6410 - mae: 9.2299 - val_loss: 3966.1443 - val_mae: 34.7060\n",
      "Epoch 2769/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.6317 - mae: 9.1265 - val_loss: 3995.9636 - val_mae: 35.1168\n",
      "Epoch 2770/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.2615 - mae: 8.8151 - val_loss: 3970.5005 - val_mae: 34.7830\n",
      "Epoch 2771/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.1680 - mae: 9.0147 - val_loss: 3915.4854 - val_mae: 34.4238\n",
      "Epoch 2772/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.3648 - mae: 8.7065 - val_loss: 3991.6130 - val_mae: 34.3585\n",
      "Epoch 2773/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.3128 - mae: 9.1811 - val_loss: 3953.4990 - val_mae: 34.7383\n",
      "Epoch 2774/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.3058 - mae: 8.8338 - val_loss: 3938.1755 - val_mae: 34.7820\n",
      "Epoch 2775/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.7733 - mae: 8.8246 - val_loss: 4000.9866 - val_mae: 35.0220\n",
      "Epoch 2776/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 228.2294 - mae: 8.7967 - val_loss: 4072.1731 - val_mae: 35.1254\n",
      "Epoch 2777/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.2924 - mae: 9.1740 - val_loss: 4050.8179 - val_mae: 35.4327\n",
      "Epoch 2778/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.6461 - mae: 9.0809 - val_loss: 4132.6128 - val_mae: 35.2251\n",
      "Epoch 2779/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.3820 - mae: 9.1487 - val_loss: 4086.3506 - val_mae: 35.8011\n",
      "Epoch 2780/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.3505 - mae: 8.9251 - val_loss: 3986.2114 - val_mae: 35.0800\n",
      "Epoch 2781/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.9612 - mae: 8.6323 - val_loss: 4191.2896 - val_mae: 36.3441\n",
      "Epoch 2782/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.8097 - mae: 9.1141 - val_loss: 4121.2021 - val_mae: 35.7997\n",
      "Epoch 2783/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 277.2807 - mae: 9.1666 - val_loss: 4193.5938 - val_mae: 36.3316\n",
      "Epoch 2784/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 293.0318 - mae: 9.4397 - val_loss: 4219.6714 - val_mae: 35.9293\n",
      "Epoch 2785/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.3623 - mae: 8.8949 - val_loss: 4187.2642 - val_mae: 36.2557\n",
      "Epoch 2786/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.5033 - mae: 8.9015 - val_loss: 4117.5791 - val_mae: 36.2215\n",
      "Epoch 2787/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.4836 - mae: 8.7993 - val_loss: 4142.8027 - val_mae: 36.0449\n",
      "Epoch 2788/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.2628 - mae: 8.7242 - val_loss: 4163.3945 - val_mae: 36.1699\n",
      "Epoch 2789/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.3832 - mae: 8.8283 - val_loss: 4221.4072 - val_mae: 36.1887\n",
      "Epoch 2790/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 264.0645 - mae: 9.1488 - val_loss: 4263.9536 - val_mae: 36.1874\n",
      "Epoch 2791/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.5047 - mae: 9.0932 - val_loss: 4206.9429 - val_mae: 36.1517\n",
      "Epoch 2792/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.1532 - mae: 8.8730 - val_loss: 4200.9033 - val_mae: 36.2485\n",
      "Epoch 2793/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.2966 - mae: 8.7292 - val_loss: 4230.0117 - val_mae: 36.2895\n",
      "Epoch 2794/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.9368 - mae: 8.6710 - val_loss: 4086.6394 - val_mae: 35.9552\n",
      "Epoch 2795/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.2601 - mae: 8.7828 - val_loss: 4152.9404 - val_mae: 35.6697\n",
      "Epoch 2796/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 294.5704 - mae: 9.2581 - val_loss: 4202.1211 - val_mae: 36.8581\n",
      "Epoch 2797/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 266.6038 - mae: 9.2430 - val_loss: 4185.4712 - val_mae: 35.9765\n",
      "Epoch 2798/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.3948 - mae: 8.9185 - val_loss: 4320.5088 - val_mae: 36.3972\n",
      "Epoch 2799/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.5511 - mae: 9.0544 - val_loss: 4164.4937 - val_mae: 35.5108\n",
      "Epoch 2800/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 212.2249 - mae: 8.5998 - val_loss: 4246.5171 - val_mae: 36.4435\n",
      "Epoch 2801/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.6056 - mae: 9.7715 - val_loss: 4105.7891 - val_mae: 35.9319\n",
      "Epoch 2802/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.7440 - mae: 9.0138 - val_loss: 4164.3296 - val_mae: 35.6757\n",
      "Epoch 2803/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.8719 - mae: 8.5645 - val_loss: 4156.8047 - val_mae: 35.9058\n",
      "Epoch 2804/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.9289 - mae: 8.5650 - val_loss: 4211.7524 - val_mae: 36.2249\n",
      "Epoch 2805/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.3032 - mae: 8.4639 - val_loss: 4237.7207 - val_mae: 36.3782\n",
      "Epoch 2806/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.5299 - mae: 8.8662 - val_loss: 4174.6387 - val_mae: 35.7227\n",
      "Epoch 2807/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.8767 - mae: 8.8164 - val_loss: 4144.3447 - val_mae: 35.3825\n",
      "Epoch 2808/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.5563 - mae: 8.5450 - val_loss: 4192.5088 - val_mae: 35.4510\n",
      "Epoch 2809/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.3492 - mae: 8.5761 - val_loss: 4184.9341 - val_mae: 35.9053\n",
      "Epoch 2810/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.7734 - mae: 8.6646 - val_loss: 4171.1094 - val_mae: 35.8679\n",
      "Epoch 2811/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.8356 - mae: 8.8329 - val_loss: 4149.0996 - val_mae: 35.7324\n",
      "Epoch 2812/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.9531 - mae: 8.5438 - val_loss: 4153.1313 - val_mae: 36.2955\n",
      "Epoch 2813/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.6792 - mae: 8.8469 - val_loss: 4031.5598 - val_mae: 36.3414\n",
      "Epoch 2814/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.2625 - mae: 8.7129 - val_loss: 4038.4001 - val_mae: 35.7355\n",
      "Epoch 2815/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.6920 - mae: 8.7129 - val_loss: 4104.5063 - val_mae: 35.7516\n",
      "Epoch 2816/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.1356 - mae: 8.5598 - val_loss: 4079.4905 - val_mae: 35.0879\n",
      "Epoch 2817/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.1302 - mae: 9.1594 - val_loss: 3943.5886 - val_mae: 35.1120\n",
      "Epoch 2818/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 216.3642 - mae: 8.6511 - val_loss: 3952.3181 - val_mae: 35.4156\n",
      "Epoch 2819/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.5343 - mae: 8.7218 - val_loss: 3946.0061 - val_mae: 34.8494\n",
      "Epoch 2820/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.5357 - mae: 8.9968 - val_loss: 4011.0215 - val_mae: 36.1607\n",
      "Epoch 2821/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.3744 - mae: 8.7836 - val_loss: 4080.8750 - val_mae: 35.9393\n",
      "Epoch 2822/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.9844 - mae: 9.0286 - val_loss: 4124.3564 - val_mae: 36.0473\n",
      "Epoch 2823/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.0253 - mae: 8.6090 - val_loss: 3966.8176 - val_mae: 35.7967\n",
      "Epoch 2824/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.2416 - mae: 8.7332 - val_loss: 3994.7029 - val_mae: 35.3824\n",
      "Epoch 2825/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.2155 - mae: 8.7229 - val_loss: 4047.0916 - val_mae: 35.5953\n",
      "Epoch 2826/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.3017 - mae: 9.0730 - val_loss: 4105.3574 - val_mae: 35.1407\n",
      "Epoch 2827/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.7661 - mae: 8.7173 - val_loss: 4090.3992 - val_mae: 35.7218\n",
      "Epoch 2828/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.3879 - mae: 9.0252 - val_loss: 4241.0913 - val_mae: 36.5745\n",
      "Epoch 2829/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.6494 - mae: 8.5301 - val_loss: 4038.6062 - val_mae: 35.3255\n",
      "Epoch 2830/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 240.5656 - mae: 8.7751 - val_loss: 3983.0254 - val_mae: 35.4527\n",
      "Epoch 2831/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.7807 - mae: 8.8013 - val_loss: 4098.3828 - val_mae: 35.8383\n",
      "Epoch 2832/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 222.7112 - mae: 8.5709 - val_loss: 4106.8379 - val_mae: 35.4908\n",
      "Epoch 2833/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.0778 - mae: 8.8824 - val_loss: 3997.8213 - val_mae: 35.1208\n",
      "Epoch 2834/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.9382 - mae: 8.5997 - val_loss: 4108.6123 - val_mae: 35.9166\n",
      "Epoch 2835/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.4766 - mae: 8.5177 - val_loss: 3975.4058 - val_mae: 35.7063\n",
      "Epoch 2836/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.6231 - mae: 8.8397 - val_loss: 4205.9766 - val_mae: 35.6889\n",
      "Epoch 2837/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.2270 - mae: 8.5881 - val_loss: 4020.1218 - val_mae: 35.7981\n",
      "Epoch 2838/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.4044 - mae: 8.7029 - val_loss: 3974.0671 - val_mae: 35.6206\n",
      "Epoch 2839/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.6711 - mae: 8.5274 - val_loss: 4020.7700 - val_mae: 35.3388\n",
      "Epoch 2840/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.8914 - mae: 8.8460 - val_loss: 3947.3179 - val_mae: 35.3045\n",
      "Epoch 2841/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.8008 - mae: 8.6240 - val_loss: 4011.1421 - val_mae: 35.2196\n",
      "Epoch 2842/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.2653 - mae: 9.1014 - val_loss: 3997.8040 - val_mae: 35.0577\n",
      "Epoch 2843/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.6483 - mae: 8.9295 - val_loss: 4066.1362 - val_mae: 35.4808\n",
      "Epoch 2844/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.8306 - mae: 8.8329 - val_loss: 3967.9836 - val_mae: 34.9984\n",
      "Epoch 2845/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.9607 - mae: 8.6694 - val_loss: 4074.8489 - val_mae: 35.6940\n",
      "Epoch 2846/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.2946 - mae: 8.6821 - val_loss: 3954.7046 - val_mae: 35.1706\n",
      "Epoch 2847/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.2293 - mae: 8.5030 - val_loss: 3989.1118 - val_mae: 35.6399\n",
      "Epoch 2848/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.2509 - mae: 8.8700 - val_loss: 4030.9358 - val_mae: 35.3759\n",
      "Epoch 2849/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.6122 - mae: 8.5871 - val_loss: 4064.6165 - val_mae: 35.2068\n",
      "Epoch 2850/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.5220 - mae: 9.2851 - val_loss: 4173.4873 - val_mae: 36.1464\n",
      "Epoch 2851/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.2836 - mae: 8.8297 - val_loss: 4004.2444 - val_mae: 35.5882\n",
      "Epoch 2852/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.5907 - mae: 8.3956 - val_loss: 4066.5061 - val_mae: 35.6640\n",
      "Epoch 2853/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.2853 - mae: 8.7543 - val_loss: 4040.0574 - val_mae: 35.3891\n",
      "Epoch 2854/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.7825 - mae: 8.6628 - val_loss: 4045.6162 - val_mae: 35.3955\n",
      "Epoch 2855/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.2479 - mae: 8.5425 - val_loss: 4163.2266 - val_mae: 35.4375\n",
      "Epoch 2856/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.4970 - mae: 8.6434 - val_loss: 3906.7073 - val_mae: 34.9138\n",
      "Epoch 2857/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.4942 - mae: 8.4856 - val_loss: 4028.1355 - val_mae: 35.2339\n",
      "Epoch 2858/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.4921 - mae: 8.4536 - val_loss: 3981.1055 - val_mae: 35.5214\n",
      "Epoch 2859/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.5757 - mae: 9.0512 - val_loss: 3969.3989 - val_mae: 34.7809\n",
      "Epoch 2860/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.6851 - mae: 8.9131 - val_loss: 3983.0962 - val_mae: 35.0641\n",
      "Epoch 2861/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.7525 - mae: 8.7276 - val_loss: 4017.2397 - val_mae: 34.9117\n",
      "Epoch 2862/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.7123 - mae: 8.7948 - val_loss: 3893.7520 - val_mae: 35.0766\n",
      "Epoch 2863/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.6245 - mae: 8.7869 - val_loss: 4015.8494 - val_mae: 35.7414\n",
      "Epoch 2864/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.5502 - mae: 8.6365 - val_loss: 4007.5181 - val_mae: 35.5885\n",
      "Epoch 2865/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2555 - mae: 8.7749 - val_loss: 4054.3770 - val_mae: 35.5171\n",
      "Epoch 2866/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.1233 - mae: 8.8672 - val_loss: 3899.6240 - val_mae: 35.0038\n",
      "Epoch 2867/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.4708 - mae: 8.7768 - val_loss: 4012.4158 - val_mae: 34.9907\n",
      "Epoch 2868/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.2697 - mae: 8.8759 - val_loss: 4086.2686 - val_mae: 35.3980\n",
      "Epoch 2869/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.2041 - mae: 8.6521 - val_loss: 3971.2639 - val_mae: 35.1374\n",
      "Epoch 2870/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.8484 - mae: 8.8744 - val_loss: 3853.6797 - val_mae: 34.5948\n",
      "Epoch 2871/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.0830 - mae: 9.1685 - val_loss: 3904.8535 - val_mae: 34.8510\n",
      "Epoch 2872/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.5678 - mae: 9.0649 - val_loss: 3993.5161 - val_mae: 34.9156\n",
      "Epoch 2873/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.0418 - mae: 9.0592 - val_loss: 3952.0681 - val_mae: 35.1184\n",
      "Epoch 2874/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.5882 - mae: 8.9016 - val_loss: 3879.4851 - val_mae: 34.7288\n",
      "Epoch 2875/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.2630 - mae: 8.8836 - val_loss: 3943.0088 - val_mae: 35.5108\n",
      "Epoch 2876/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.9352 - mae: 8.8705 - val_loss: 3950.0835 - val_mae: 35.2649\n",
      "Epoch 2877/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 297.1338 - mae: 9.2720 - val_loss: 3906.9058 - val_mae: 35.0576\n",
      "Epoch 2878/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2530 - mae: 8.6309 - val_loss: 3963.5840 - val_mae: 34.4075\n",
      "Epoch 2879/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.4494 - mae: 8.8840 - val_loss: 3975.3291 - val_mae: 34.9845\n",
      "Epoch 2880/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.0372 - mae: 9.0659 - val_loss: 3726.1970 - val_mae: 33.8954\n",
      "Epoch 2881/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.0588 - mae: 8.8800 - val_loss: 3909.6301 - val_mae: 35.3965\n",
      "Epoch 2882/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 243.9603 - mae: 8.9740 - val_loss: 3976.8713 - val_mae: 35.5629\n",
      "Epoch 2883/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.7202 - mae: 8.9067 - val_loss: 3994.3967 - val_mae: 35.3344\n",
      "Epoch 2884/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.7428 - mae: 8.7059 - val_loss: 4044.7041 - val_mae: 35.5816\n",
      "Epoch 2885/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.8647 - mae: 8.7175 - val_loss: 3863.7007 - val_mae: 36.4485\n",
      "Epoch 2886/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.3175 - mae: 8.8982 - val_loss: 3893.2090 - val_mae: 35.1999\n",
      "Epoch 2887/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 225.7836 - mae: 8.6646 - val_loss: 3910.7451 - val_mae: 35.8487\n",
      "Epoch 2888/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.2248 - mae: 8.9680 - val_loss: 4001.3516 - val_mae: 35.3967\n",
      "Epoch 2889/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.3047 - mae: 8.7455 - val_loss: 3920.8123 - val_mae: 35.0079\n",
      "Epoch 2890/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.0506 - mae: 8.5294 - val_loss: 4028.8967 - val_mae: 35.7775\n",
      "Epoch 2891/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 269.5334 - mae: 8.9261 - val_loss: 3983.3247 - val_mae: 35.5558\n",
      "Epoch 2892/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.8032 - mae: 8.8454 - val_loss: 3859.6663 - val_mae: 34.8358\n",
      "Epoch 2893/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.1179 - mae: 8.5884 - val_loss: 3906.7969 - val_mae: 34.9044\n",
      "Epoch 2894/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.4905 - mae: 9.1413 - val_loss: 4013.2661 - val_mae: 35.1850\n",
      "Epoch 2895/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.9661 - mae: 9.3107 - val_loss: 3869.7209 - val_mae: 34.3413\n",
      "Epoch 2896/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.4319 - mae: 8.6175 - val_loss: 3814.4395 - val_mae: 34.4338\n",
      "Epoch 2897/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.5833 - mae: 8.3978 - val_loss: 3859.3057 - val_mae: 34.5387\n",
      "Epoch 2898/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.2757 - mae: 8.5390 - val_loss: 3812.2991 - val_mae: 34.6681\n",
      "Epoch 2899/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.8205 - mae: 8.5599 - val_loss: 3849.2874 - val_mae: 34.7296\n",
      "Epoch 2900/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.9433 - mae: 8.6058 - val_loss: 3783.1443 - val_mae: 33.9880\n",
      "Epoch 2901/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.6846 - mae: 8.7022 - val_loss: 3864.5620 - val_mae: 35.0578\n",
      "Epoch 2902/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.6210 - mae: 8.8239 - val_loss: 3825.0615 - val_mae: 34.0020\n",
      "Epoch 2903/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.9442 - mae: 8.3986 - val_loss: 4018.5842 - val_mae: 35.1504\n",
      "Epoch 2904/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.7205 - mae: 8.5111 - val_loss: 4092.5044 - val_mae: 35.9597\n",
      "Epoch 2905/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.8733 - mae: 9.0090 - val_loss: 4017.8591 - val_mae: 36.0984\n",
      "Epoch 2906/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.6305 - mae: 8.9388 - val_loss: 4058.3269 - val_mae: 35.6913\n",
      "Epoch 2907/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.3678 - mae: 8.6881 - val_loss: 4081.0754 - val_mae: 36.0831\n",
      "Epoch 2908/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.1573 - mae: 9.3443 - val_loss: 3970.1562 - val_mae: 35.1726\n",
      "Epoch 2909/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.3479 - mae: 8.7719 - val_loss: 4084.3069 - val_mae: 36.1797\n",
      "Epoch 2910/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.2610 - mae: 8.6096 - val_loss: 4032.9954 - val_mae: 35.5324\n",
      "Epoch 2911/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.6295 - mae: 8.8645 - val_loss: 3970.8042 - val_mae: 35.4919\n",
      "Epoch 2912/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.9438 - mae: 8.5601 - val_loss: 4120.5908 - val_mae: 36.3030\n",
      "Epoch 2913/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.7218 - mae: 8.7692 - val_loss: 4019.0754 - val_mae: 35.1368\n",
      "Epoch 2914/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.6647 - mae: 8.4376 - val_loss: 3886.3916 - val_mae: 34.9381\n",
      "Epoch 2915/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.7936 - mae: 8.7817 - val_loss: 4062.4768 - val_mae: 35.7314\n",
      "Epoch 2916/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.8893 - mae: 8.6380 - val_loss: 4011.5249 - val_mae: 35.2293\n",
      "Epoch 2917/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.7782 - mae: 8.6524 - val_loss: 3885.6028 - val_mae: 34.8908\n",
      "Epoch 2918/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.4480 - mae: 8.3668 - val_loss: 3985.2798 - val_mae: 35.1255\n",
      "Epoch 2919/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 181.3021 - mae: 8.1533 - val_loss: 4018.5659 - val_mae: 35.1134\n",
      "Epoch 2920/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.8314 - mae: 8.5174 - val_loss: 3982.0916 - val_mae: 34.5961\n",
      "Epoch 2921/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.8675 - mae: 8.2343 - val_loss: 3921.3311 - val_mae: 35.1462\n",
      "Epoch 2922/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.6021 - mae: 8.3376 - val_loss: 3999.1697 - val_mae: 35.5675\n",
      "Epoch 2923/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.3316 - mae: 8.3962 - val_loss: 4142.0176 - val_mae: 36.3989\n",
      "Epoch 2924/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 302.9769 - mae: 9.2251 - val_loss: 4060.9426 - val_mae: 35.8132\n",
      "Epoch 2925/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.0511 - mae: 8.9533 - val_loss: 4013.8755 - val_mae: 35.6042\n",
      "Epoch 2926/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.0831 - mae: 8.9138 - val_loss: 3998.9456 - val_mae: 35.2761\n",
      "Epoch 2927/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.0073 - mae: 8.9043 - val_loss: 4068.6995 - val_mae: 35.6209\n",
      "Epoch 2928/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.6642 - mae: 8.9908 - val_loss: 4207.0210 - val_mae: 36.5779\n",
      "Epoch 2929/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.5272 - mae: 8.8941 - val_loss: 4028.5420 - val_mae: 35.1061\n",
      "Epoch 2930/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 263.4668 - mae: 9.0889 - val_loss: 3980.3328 - val_mae: 34.9623\n",
      "Epoch 2931/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 274.1381 - mae: 9.0662 - val_loss: 4051.2974 - val_mae: 35.2644\n",
      "Epoch 2932/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.1260 - mae: 8.9617 - val_loss: 4198.8911 - val_mae: 35.8594\n",
      "Epoch 2933/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.8647 - mae: 8.7327 - val_loss: 4108.7964 - val_mae: 35.6196\n",
      "Epoch 2934/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.5519 - mae: 8.8656 - val_loss: 3959.6836 - val_mae: 34.6908\n",
      "Epoch 2935/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.0366 - mae: 8.8439 - val_loss: 4115.1084 - val_mae: 35.5109\n",
      "Epoch 2936/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.1563 - mae: 8.6109 - val_loss: 4063.3037 - val_mae: 35.2499\n",
      "Epoch 2937/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.6464 - mae: 9.0552 - val_loss: 3994.1328 - val_mae: 35.0390\n",
      "Epoch 2938/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.2864 - mae: 8.9698 - val_loss: 4069.2805 - val_mae: 35.4242\n",
      "Epoch 2939/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.9037 - mae: 8.6168 - val_loss: 4011.5056 - val_mae: 35.2153\n",
      "Epoch 2940/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.3171 - mae: 8.7870 - val_loss: 4016.2651 - val_mae: 35.5903\n",
      "Epoch 2941/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.8833 - mae: 8.8279 - val_loss: 4079.5115 - val_mae: 35.1796\n",
      "Epoch 2942/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 372.2105 - mae: 9.2671 - val_loss: 3896.5273 - val_mae: 34.4265\n",
      "Epoch 2943/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 339.3470 - mae: 9.7140 - val_loss: 3947.9946 - val_mae: 35.3028\n",
      "Epoch 2944/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 271.0385 - mae: 9.0822 - val_loss: 3985.3757 - val_mae: 34.6445\n",
      "Epoch 2945/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.3795 - mae: 9.1383 - val_loss: 4001.5149 - val_mae: 35.1353\n",
      "Epoch 2946/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.7421 - mae: 8.3977 - val_loss: 4044.0183 - val_mae: 35.1344\n",
      "Epoch 2947/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.1654 - mae: 8.5265 - val_loss: 4080.5581 - val_mae: 35.8699\n",
      "Epoch 2948/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.9048 - mae: 8.5475 - val_loss: 4039.1377 - val_mae: 35.2196\n",
      "Epoch 2949/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.8520 - mae: 8.5567 - val_loss: 4088.9697 - val_mae: 35.4946\n",
      "Epoch 2950/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.9550 - mae: 8.5503 - val_loss: 4041.8909 - val_mae: 35.5269\n",
      "Epoch 2951/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.9163 - mae: 8.6676 - val_loss: 4107.5635 - val_mae: 35.4506\n",
      "Epoch 2952/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.1968 - mae: 8.6291 - val_loss: 4060.4739 - val_mae: 35.9989\n",
      "Epoch 2953/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.7086 - mae: 8.6319 - val_loss: 4054.1580 - val_mae: 35.6477\n",
      "Epoch 2954/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.1689 - mae: 8.7856 - val_loss: 4104.6309 - val_mae: 35.6628\n",
      "Epoch 2955/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.6733 - mae: 8.5322 - val_loss: 4033.0920 - val_mae: 35.3577\n",
      "Epoch 2956/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.1478 - mae: 8.3451 - val_loss: 4043.3464 - val_mae: 35.2747\n",
      "Epoch 2957/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.2877 - mae: 8.5177 - val_loss: 4018.8147 - val_mae: 35.3695\n",
      "Epoch 2958/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.9998 - mae: 8.6101 - val_loss: 4066.2754 - val_mae: 35.1637\n",
      "Epoch 2959/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.0170 - mae: 8.6377 - val_loss: 4005.9939 - val_mae: 35.2904\n",
      "Epoch 2960/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.5714 - mae: 8.2639 - val_loss: 4070.0366 - val_mae: 35.2423\n",
      "Epoch 2961/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.9938 - mae: 8.3238 - val_loss: 4053.1096 - val_mae: 35.1437\n",
      "Epoch 2962/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.2876 - mae: 8.6439 - val_loss: 3969.2788 - val_mae: 35.3063\n",
      "Epoch 2963/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.8474 - mae: 8.8562 - val_loss: 4145.6826 - val_mae: 35.4595\n",
      "Epoch 2964/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.2745 - mae: 8.8351 - val_loss: 3885.7729 - val_mae: 35.0472\n",
      "Epoch 2965/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.8350 - mae: 8.7828 - val_loss: 3991.8259 - val_mae: 35.5422\n",
      "Epoch 2966/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.9843 - mae: 8.8430 - val_loss: 3940.1968 - val_mae: 34.8587\n",
      "Epoch 2967/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.7095 - mae: 8.6872 - val_loss: 3815.5078 - val_mae: 34.8190\n",
      "Epoch 2968/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.9621 - mae: 8.9969 - val_loss: 3813.1104 - val_mae: 34.3233\n",
      "Epoch 2969/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.2336 - mae: 8.4992 - val_loss: 3766.9180 - val_mae: 33.6190\n",
      "Epoch 2970/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.4333 - mae: 8.5260 - val_loss: 3995.4661 - val_mae: 35.2038\n",
      "Epoch 2971/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.8687 - mae: 8.4227 - val_loss: 3824.0457 - val_mae: 35.0273\n",
      "Epoch 2972/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.7021 - mae: 8.5712 - val_loss: 3867.1484 - val_mae: 34.4232\n",
      "Epoch 2973/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.5053 - mae: 8.6762 - val_loss: 3849.2102 - val_mae: 34.8439\n",
      "Epoch 2974/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.4400 - mae: 8.7507 - val_loss: 4005.9082 - val_mae: 35.1794\n",
      "Epoch 2975/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.2683 - mae: 8.5760 - val_loss: 3919.5073 - val_mae: 34.9346\n",
      "Epoch 2976/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.7415 - mae: 8.3598 - val_loss: 3992.5254 - val_mae: 35.2081\n",
      "Epoch 2977/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 244.0705 - mae: 8.7581 - val_loss: 3993.6069 - val_mae: 35.4804\n",
      "Epoch 2978/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 182.1126 - mae: 8.3059 - val_loss: 4009.0886 - val_mae: 35.2749\n",
      "Epoch 2979/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.3424 - mae: 8.4070 - val_loss: 4130.1841 - val_mae: 35.1902\n",
      "Epoch 2980/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.9865 - mae: 8.6816 - val_loss: 3939.7344 - val_mae: 34.8835\n",
      "Epoch 2981/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.9762 - mae: 8.8030 - val_loss: 3997.1414 - val_mae: 35.5478\n",
      "Epoch 2982/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 308.2314 - mae: 10.7498 - val_loss: 3975.5449 - val_mae: 35.9028\n",
      "Epoch 2983/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.8394 - mae: 10.3499 - val_loss: 3990.8296 - val_mae: 35.1335\n",
      "Epoch 2984/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.5312 - mae: 9.7235 - val_loss: 3978.5801 - val_mae: 35.3220\n",
      "Epoch 2985/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.7255 - mae: 8.9925 - val_loss: 4020.0828 - val_mae: 35.2709\n",
      "Epoch 2986/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.7707 - mae: 9.0672 - val_loss: 3980.8970 - val_mae: 35.7440\n",
      "Epoch 2987/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 311.5936 - mae: 9.6917 - val_loss: 4151.2720 - val_mae: 35.9342\n",
      "Epoch 2988/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.8706 - mae: 8.8978 - val_loss: 4130.0200 - val_mae: 35.5385\n",
      "Epoch 2989/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.0796 - mae: 8.8450 - val_loss: 4255.6206 - val_mae: 36.1241\n",
      "Epoch 2990/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 317.9676 - mae: 9.4877 - val_loss: 4057.8879 - val_mae: 35.7266\n",
      "Epoch 2991/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.1960 - mae: 8.9724 - val_loss: 3911.0503 - val_mae: 35.5051\n",
      "Epoch 2992/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.1056 - mae: 9.2611 - val_loss: 3986.1084 - val_mae: 35.4396\n",
      "Epoch 2993/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.2709 - mae: 9.0105 - val_loss: 4051.8877 - val_mae: 35.3265\n",
      "Epoch 2994/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 221.9819 - mae: 8.7265 - val_loss: 4023.2905 - val_mae: 35.6566\n",
      "Epoch 2995/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.4154 - mae: 8.7888 - val_loss: 4070.3313 - val_mae: 35.2079\n",
      "Epoch 2996/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.9299 - mae: 8.7592 - val_loss: 3976.3809 - val_mae: 35.4131\n",
      "Epoch 2997/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.0924 - mae: 8.8383 - val_loss: 3991.9121 - val_mae: 34.9845\n",
      "Epoch 2998/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.6004 - mae: 9.0286 - val_loss: 4072.6772 - val_mae: 35.1818\n",
      "Epoch 2999/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.4543 - mae: 8.7229 - val_loss: 4098.8086 - val_mae: 35.3190\n",
      "Epoch 3000/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.2763 - mae: 8.6628 - val_loss: 4035.4463 - val_mae: 34.9240\n",
      "Epoch 3001/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.4962 - mae: 8.7755 - val_loss: 4047.7935 - val_mae: 35.5088\n",
      "Epoch 3002/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.3906 - mae: 8.7953 - val_loss: 4175.9214 - val_mae: 36.0048\n",
      "Epoch 3003/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.3895 - mae: 8.4545 - val_loss: 4025.3557 - val_mae: 35.1575\n",
      "Epoch 3004/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.7789 - mae: 8.8376 - val_loss: 4134.1475 - val_mae: 35.6817\n",
      "Epoch 3005/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.6390 - mae: 8.6793 - val_loss: 4204.3667 - val_mae: 35.5928\n",
      "Epoch 3006/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.8903 - mae: 8.6672 - val_loss: 4072.1055 - val_mae: 35.7731\n",
      "Epoch 3007/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.2180 - mae: 9.4740 - val_loss: 4099.9551 - val_mae: 35.4230\n",
      "Epoch 3008/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 267.9793 - mae: 8.8885 - val_loss: 3944.3489 - val_mae: 34.8831\n",
      "Epoch 3009/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.6617 - mae: 8.7110 - val_loss: 3972.3459 - val_mae: 34.8064\n",
      "Epoch 3010/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.5257 - mae: 8.3119 - val_loss: 3944.4834 - val_mae: 34.8936\n",
      "Epoch 3011/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.3816 - mae: 8.4462 - val_loss: 4024.4258 - val_mae: 34.5876\n",
      "Epoch 3012/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.0710 - mae: 8.8155 - val_loss: 4096.3276 - val_mae: 35.0012\n",
      "Epoch 3013/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.4446 - mae: 8.5344 - val_loss: 4035.8435 - val_mae: 34.7580\n",
      "Epoch 3014/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.3330 - mae: 8.5812 - val_loss: 3994.9604 - val_mae: 35.0344\n",
      "Epoch 3015/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.5533 - mae: 8.5128 - val_loss: 3966.9287 - val_mae: 34.7423\n",
      "Epoch 3016/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.2808 - mae: 8.3718 - val_loss: 4024.1428 - val_mae: 35.0643\n",
      "Epoch 3017/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.1944 - mae: 8.4037 - val_loss: 4061.9834 - val_mae: 35.4003\n",
      "Epoch 3018/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.9618 - mae: 8.5543 - val_loss: 4014.7964 - val_mae: 35.1727\n",
      "Epoch 3019/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.1615 - mae: 8.4784 - val_loss: 4070.2773 - val_mae: 35.2057\n",
      "Epoch 3020/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.7689 - mae: 8.6886 - val_loss: 4044.3269 - val_mae: 35.1176\n",
      "Epoch 3021/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.7863 - mae: 8.7197 - val_loss: 4039.1318 - val_mae: 35.4606\n",
      "Epoch 3022/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.6100 - mae: 8.8070 - val_loss: 4084.2542 - val_mae: 35.2581\n",
      "Epoch 3023/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.8690 - mae: 9.0084 - val_loss: 4059.5352 - val_mae: 35.6072\n",
      "Epoch 3024/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.5010 - mae: 8.8047 - val_loss: 4119.5083 - val_mae: 35.4640\n",
      "Epoch 3025/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.3395 - mae: 8.9168 - val_loss: 4179.6455 - val_mae: 36.0358\n",
      "Epoch 3026/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.1267 - mae: 9.0776 - val_loss: 3898.7722 - val_mae: 34.6198\n",
      "Epoch 3027/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.8263 - mae: 8.4836 - val_loss: 3991.9104 - val_mae: 34.9898\n",
      "Epoch 3028/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.6193 - mae: 8.5420 - val_loss: 4224.7441 - val_mae: 35.6578\n",
      "Epoch 3029/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.2203 - mae: 8.3904 - val_loss: 4165.2388 - val_mae: 35.3559\n",
      "Epoch 3030/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.7481 - mae: 8.5802 - val_loss: 4114.0493 - val_mae: 35.1788\n",
      "Epoch 3031/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.3426 - mae: 8.4865 - val_loss: 3990.3794 - val_mae: 34.8170\n",
      "Epoch 3032/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.4157 - mae: 9.0425 - val_loss: 3999.0259 - val_mae: 34.6330\n",
      "Epoch 3033/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.0611 - mae: 8.9273 - val_loss: 3911.7239 - val_mae: 34.5233\n",
      "Epoch 3034/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.5842 - mae: 8.8145 - val_loss: 4173.7524 - val_mae: 35.5093\n",
      "Epoch 3035/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 265.3012 - mae: 9.0462 - val_loss: 4140.4463 - val_mae: 35.4845\n",
      "Epoch 3036/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.0437 - mae: 8.5023 - val_loss: 3987.8337 - val_mae: 34.5352\n",
      "Epoch 3037/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.7934 - mae: 8.5561 - val_loss: 4132.9604 - val_mae: 35.0950\n",
      "Epoch 3038/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.7209 - mae: 8.9417 - val_loss: 4086.2268 - val_mae: 34.9293\n",
      "Epoch 3039/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.6829 - mae: 8.5764 - val_loss: 3886.6624 - val_mae: 34.3033\n",
      "Epoch 3040/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.1376 - mae: 8.4933 - val_loss: 3980.7043 - val_mae: 34.6758\n",
      "Epoch 3041/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.4396 - mae: 8.5799 - val_loss: 3921.7166 - val_mae: 34.0142\n",
      "Epoch 3042/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 252.2467 - mae: 8.6822 - val_loss: 4030.7412 - val_mae: 34.5925\n",
      "Epoch 3043/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.3226 - mae: 8.5982 - val_loss: 4109.6318 - val_mae: 35.0505\n",
      "Epoch 3044/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.4378 - mae: 8.3416 - val_loss: 4121.7305 - val_mae: 35.1237\n",
      "Epoch 3045/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.7897 - mae: 8.3941 - val_loss: 4048.5229 - val_mae: 35.1625\n",
      "Epoch 3046/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.9306 - mae: 8.4761 - val_loss: 4273.2446 - val_mae: 35.6956\n",
      "Epoch 3047/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.7363 - mae: 8.6051 - val_loss: 4230.7109 - val_mae: 35.6253\n",
      "Epoch 3048/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.5797 - mae: 8.5332 - val_loss: 4149.8091 - val_mae: 35.5222\n",
      "Epoch 3049/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.2794 - mae: 8.3521 - val_loss: 4078.4397 - val_mae: 35.0376\n",
      "Epoch 3050/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.0508 - mae: 9.0071 - val_loss: 4265.8540 - val_mae: 36.2270\n",
      "Epoch 3051/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.2572 - mae: 8.5346 - val_loss: 4056.0166 - val_mae: 35.2067\n",
      "Epoch 3052/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.8264 - mae: 8.5194 - val_loss: 3979.4668 - val_mae: 34.9667\n",
      "Epoch 3053/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.7600 - mae: 8.3413 - val_loss: 4007.4043 - val_mae: 35.2024\n",
      "Epoch 3054/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.3056 - mae: 8.6658 - val_loss: 3965.8967 - val_mae: 34.7045\n",
      "Epoch 3055/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.3202 - mae: 8.7573 - val_loss: 3914.7473 - val_mae: 34.5232\n",
      "Epoch 3056/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.9052 - mae: 8.5217 - val_loss: 3937.7166 - val_mae: 34.3331\n",
      "Epoch 3057/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.9940 - mae: 8.8414 - val_loss: 3916.9707 - val_mae: 34.1561\n",
      "Epoch 3058/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.6137 - mae: 8.5580 - val_loss: 3959.7395 - val_mae: 34.2997\n",
      "Epoch 3059/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.4361 - mae: 8.5902 - val_loss: 3961.9778 - val_mae: 34.4940\n",
      "Epoch 3060/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.2571 - mae: 8.7629 - val_loss: 4009.7449 - val_mae: 34.6463\n",
      "Epoch 3061/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.7831 - mae: 8.7328 - val_loss: 3965.7734 - val_mae: 35.0867\n",
      "Epoch 3062/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.9339 - mae: 8.6238 - val_loss: 3964.6094 - val_mae: 34.8051\n",
      "Epoch 3063/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.6807 - mae: 8.3993 - val_loss: 4149.2305 - val_mae: 35.4665\n",
      "Epoch 3064/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.9327 - mae: 8.3829 - val_loss: 3979.6133 - val_mae: 34.9418\n",
      "Epoch 3065/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.8342 - mae: 8.2608 - val_loss: 4013.6433 - val_mae: 35.1254\n",
      "Epoch 3066/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.0079 - mae: 8.5077 - val_loss: 4042.6790 - val_mae: 35.2146\n",
      "Epoch 3067/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.5390 - mae: 8.6535 - val_loss: 4033.6565 - val_mae: 34.9588\n",
      "Epoch 3068/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.7706 - mae: 8.4217 - val_loss: 3966.2231 - val_mae: 34.9118\n",
      "Epoch 3069/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.9283 - mae: 8.8381 - val_loss: 3978.1262 - val_mae: 34.8150\n",
      "Epoch 3070/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.6377 - mae: 8.8113 - val_loss: 4031.5557 - val_mae: 35.2518\n",
      "Epoch 3071/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.2346 - mae: 8.4839 - val_loss: 4102.9126 - val_mae: 35.2787\n",
      "Epoch 3072/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.6431 - mae: 8.2796 - val_loss: 4017.6145 - val_mae: 34.9078\n",
      "Epoch 3073/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.9543 - mae: 8.5071 - val_loss: 3949.0579 - val_mae: 35.0002\n",
      "Epoch 3074/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.9558 - mae: 8.7586 - val_loss: 4038.0945 - val_mae: 35.0306\n",
      "Epoch 3075/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.6040 - mae: 8.5062 - val_loss: 4049.0637 - val_mae: 35.2749\n",
      "Epoch 3076/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7065 - mae: 8.3715 - val_loss: 4123.9487 - val_mae: 35.6280\n",
      "Epoch 3077/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.7707 - mae: 8.2514 - val_loss: 4087.0129 - val_mae: 35.5767\n",
      "Epoch 3078/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.0675 - mae: 8.1255 - val_loss: 4095.1973 - val_mae: 35.1488\n",
      "Epoch 3079/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.5708 - mae: 8.6180 - val_loss: 4039.4946 - val_mae: 35.3989\n",
      "Epoch 3080/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.8068 - mae: 8.7421 - val_loss: 4148.3203 - val_mae: 35.9205\n",
      "Epoch 3081/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.2966 - mae: 8.3528 - val_loss: 4144.6914 - val_mae: 35.9857\n",
      "Epoch 3082/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.7698 - mae: 9.0498 - val_loss: 3995.8428 - val_mae: 35.5162\n",
      "Epoch 3083/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.8001 - mae: 8.7853 - val_loss: 4104.1968 - val_mae: 35.7413\n",
      "Epoch 3084/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.4834 - mae: 8.7521 - val_loss: 4012.5513 - val_mae: 35.4344\n",
      "Epoch 3085/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.8329 - mae: 8.6036 - val_loss: 3962.5581 - val_mae: 35.0366\n",
      "Epoch 3086/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.7507 - mae: 8.4456 - val_loss: 4031.2646 - val_mae: 35.9313\n",
      "Epoch 3087/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.1243 - mae: 8.5707 - val_loss: 4014.1545 - val_mae: 35.8456\n",
      "Epoch 3088/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 341.8685 - mae: 9.3289 - val_loss: 4052.5173 - val_mae: 35.5193\n",
      "Epoch 3089/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.2500 - mae: 9.2277 - val_loss: 4142.8813 - val_mae: 35.8620\n",
      "Epoch 3090/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 292.5247 - mae: 9.1216 - val_loss: 4155.1011 - val_mae: 36.2726\n",
      "Epoch 3091/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.1667 - mae: 8.9845 - val_loss: 4210.6816 - val_mae: 35.8704\n",
      "Epoch 3092/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.6635 - mae: 8.8725 - val_loss: 4431.1343 - val_mae: 36.4771\n",
      "Epoch 3093/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 250.8653 - mae: 8.8420 - val_loss: 4295.3613 - val_mae: 35.7048\n",
      "Epoch 3094/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.5563 - mae: 9.3971 - val_loss: 4115.2920 - val_mae: 35.5140\n",
      "Epoch 3095/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.6294 - mae: 8.9422 - val_loss: 4305.4146 - val_mae: 36.0894\n",
      "Epoch 3096/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.6836 - mae: 8.6947 - val_loss: 4241.7520 - val_mae: 36.0326\n",
      "Epoch 3097/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.6178 - mae: 8.8819 - val_loss: 4303.7983 - val_mae: 36.1669\n",
      "Epoch 3098/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.8714 - mae: 8.7845 - val_loss: 4200.0322 - val_mae: 35.8778\n",
      "Epoch 3099/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.1856 - mae: 8.9056 - val_loss: 4157.4819 - val_mae: 35.8137\n",
      "Epoch 3100/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.6587 - mae: 8.6395 - val_loss: 4271.6602 - val_mae: 36.7680\n",
      "Epoch 3101/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.9616 - mae: 8.9613 - val_loss: 4156.5034 - val_mae: 36.0764\n",
      "Epoch 3102/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.3068 - mae: 8.3716 - val_loss: 4247.8882 - val_mae: 35.9816\n",
      "Epoch 3103/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.2231 - mae: 8.7222 - val_loss: 4306.9668 - val_mae: 36.2976\n",
      "Epoch 3104/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.9572 - mae: 8.2582 - val_loss: 4275.7129 - val_mae: 36.2214\n",
      "Epoch 3105/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.6716 - mae: 8.5985 - val_loss: 4337.2466 - val_mae: 36.5177\n",
      "Epoch 3106/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2589 - mae: 8.3367 - val_loss: 4185.3096 - val_mae: 35.8755\n",
      "Epoch 3107/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.0284 - mae: 8.2329 - val_loss: 4306.5059 - val_mae: 36.0382\n",
      "Epoch 3108/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.4187 - mae: 8.3191 - val_loss: 4314.6411 - val_mae: 36.6856\n",
      "Epoch 3109/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 282.2022 - mae: 8.8823 - val_loss: 4240.0361 - val_mae: 36.2308\n",
      "Epoch 3110/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.1674 - mae: 8.5756 - val_loss: 4241.3579 - val_mae: 36.3643\n",
      "Epoch 3111/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.8210 - mae: 8.6601 - val_loss: 4144.8638 - val_mae: 35.9199\n",
      "Epoch 3112/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.1248 - mae: 8.6752 - val_loss: 4164.6533 - val_mae: 36.1713\n",
      "Epoch 3113/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.9408 - mae: 8.5489 - val_loss: 4231.6045 - val_mae: 36.2758\n",
      "Epoch 3114/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.0513 - mae: 8.4608 - val_loss: 4132.0518 - val_mae: 35.4212\n",
      "Epoch 3115/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.7513 - mae: 8.6454 - val_loss: 4209.6582 - val_mae: 36.2862\n",
      "Epoch 3116/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.8424 - mae: 8.7323 - val_loss: 4253.8223 - val_mae: 36.1158\n",
      "Epoch 3117/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.4133 - mae: 8.7989 - val_loss: 4089.8435 - val_mae: 35.9236\n",
      "Epoch 3118/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.1134 - mae: 8.3545 - val_loss: 4087.0879 - val_mae: 35.4815\n",
      "Epoch 3119/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.9152 - mae: 8.3745 - val_loss: 4234.2373 - val_mae: 36.0790\n",
      "Epoch 3120/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.4564 - mae: 8.4048 - val_loss: 4142.5957 - val_mae: 35.8992\n",
      "Epoch 3121/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.1315 - mae: 8.1636 - val_loss: 4184.7393 - val_mae: 36.0521\n",
      "Epoch 3122/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.6853 - mae: 8.3184 - val_loss: 4200.4185 - val_mae: 36.5759\n",
      "Epoch 3123/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.1027 - mae: 8.2488 - val_loss: 4076.3203 - val_mae: 35.4785\n",
      "Epoch 3124/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.8538 - mae: 8.3436 - val_loss: 4089.5459 - val_mae: 35.8398\n",
      "Epoch 3125/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.2680 - mae: 8.5488 - val_loss: 3968.4231 - val_mae: 35.1682\n",
      "Epoch 3126/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.8727 - mae: 8.5558 - val_loss: 4105.1611 - val_mae: 35.6331\n",
      "Epoch 3127/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.0287 - mae: 8.7056 - val_loss: 4059.2659 - val_mae: 35.3778\n",
      "Epoch 3128/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.8162 - mae: 9.1158 - val_loss: 4129.0762 - val_mae: 35.2741\n",
      "Epoch 3129/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.6422 - mae: 8.6975 - val_loss: 4132.0469 - val_mae: 35.3920\n",
      "Epoch 3130/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.7312 - mae: 8.5284 - val_loss: 4106.3472 - val_mae: 35.3419\n",
      "Epoch 3131/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.8445 - mae: 8.6848 - val_loss: 3905.6497 - val_mae: 34.4741\n",
      "Epoch 3132/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.1617 - mae: 8.9136 - val_loss: 3985.4319 - val_mae: 35.0105\n",
      "Epoch 3133/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.8923 - mae: 8.1263 - val_loss: 3984.5686 - val_mae: 34.7365\n",
      "Epoch 3134/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.9713 - mae: 8.4556 - val_loss: 4133.4521 - val_mae: 35.5679\n",
      "Epoch 3135/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.1739 - mae: 8.6093 - val_loss: 3995.1184 - val_mae: 35.1412\n",
      "Epoch 3136/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.9393 - mae: 8.8495 - val_loss: 4023.8738 - val_mae: 35.0966\n",
      "Epoch 3137/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.6875 - mae: 8.6727 - val_loss: 4111.5874 - val_mae: 35.2704\n",
      "Epoch 3138/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.7301 - mae: 8.3606 - val_loss: 4125.5859 - val_mae: 35.4317\n",
      "Epoch 3139/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.2721 - mae: 8.4370 - val_loss: 4129.9565 - val_mae: 35.8055\n",
      "Epoch 3140/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.0129 - mae: 8.5504 - val_loss: 4133.4473 - val_mae: 35.4237\n",
      "Epoch 3141/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.4201 - mae: 8.3010 - val_loss: 4119.6992 - val_mae: 35.7713\n",
      "Epoch 3142/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.2412 - mae: 8.3636 - val_loss: 4066.5752 - val_mae: 35.0994\n",
      "Epoch 3143/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.3484 - mae: 8.7150 - val_loss: 4079.9136 - val_mae: 35.6260\n",
      "Epoch 3144/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.3152 - mae: 8.6302 - val_loss: 4211.5542 - val_mae: 35.9758\n",
      "Epoch 3145/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.7363 - mae: 8.4310 - val_loss: 4409.2744 - val_mae: 36.3613\n",
      "Epoch 3146/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.0426 - mae: 8.8338 - val_loss: 4153.3960 - val_mae: 35.6205\n",
      "Epoch 3147/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.1437 - mae: 8.4899 - val_loss: 4195.1309 - val_mae: 36.0894\n",
      "Epoch 3148/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.0766 - mae: 8.7116 - val_loss: 4241.8618 - val_mae: 36.4234\n",
      "Epoch 3149/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.6792 - mae: 8.9366 - val_loss: 4176.8677 - val_mae: 36.1358\n",
      "Epoch 3150/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.3698 - mae: 8.7341 - val_loss: 4318.2466 - val_mae: 36.7174\n",
      "Epoch 3151/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.8226 - mae: 8.5881 - val_loss: 4244.9922 - val_mae: 36.2924\n",
      "Epoch 3152/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.6724 - mae: 8.5186 - val_loss: 4336.7915 - val_mae: 36.9481\n",
      "Epoch 3153/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.4498 - mae: 8.6201 - val_loss: 4288.5215 - val_mae: 36.8687\n",
      "Epoch 3154/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.3879 - mae: 8.8150 - val_loss: 4277.0688 - val_mae: 37.1504\n",
      "Epoch 3155/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.9318 - mae: 8.8760 - val_loss: 4270.3149 - val_mae: 36.3207\n",
      "Epoch 3156/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.5933 - mae: 8.7876 - val_loss: 4318.6016 - val_mae: 36.6751\n",
      "Epoch 3157/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 349.2290 - mae: 9.5862 - val_loss: 4380.2876 - val_mae: 36.4397\n",
      "Epoch 3158/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.9693 - mae: 9.0225 - val_loss: 4290.0366 - val_mae: 36.1102\n",
      "Epoch 3159/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.0217 - mae: 8.9999 - val_loss: 4232.5981 - val_mae: 36.2580\n",
      "Epoch 3160/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.5671 - mae: 9.0768 - val_loss: 4158.7832 - val_mae: 36.5019\n",
      "Epoch 3161/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.2799 - mae: 8.8197 - val_loss: 4166.8892 - val_mae: 36.2621\n",
      "Epoch 3162/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.7010 - mae: 8.8597 - val_loss: 4299.7422 - val_mae: 36.6860\n",
      "Epoch 3163/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.8776 - mae: 8.7739 - val_loss: 4165.1865 - val_mae: 36.2732\n",
      "Epoch 3164/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.0346 - mae: 8.8542 - val_loss: 4156.9722 - val_mae: 35.3809\n",
      "Epoch 3165/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.2748 - mae: 8.5670 - val_loss: 4092.9702 - val_mae: 35.2205\n",
      "Epoch 3166/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.4581 - mae: 8.7522 - val_loss: 4078.3901 - val_mae: 35.6080\n",
      "Epoch 3167/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.8495 - mae: 8.5499 - val_loss: 4134.1138 - val_mae: 35.5655\n",
      "Epoch 3168/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.9955 - mae: 8.4723 - val_loss: 4146.1792 - val_mae: 35.3780\n",
      "Epoch 3169/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.5719 - mae: 8.5255 - val_loss: 4140.5972 - val_mae: 35.8818\n",
      "Epoch 3170/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.6100 - mae: 9.1161 - val_loss: 4190.1963 - val_mae: 35.8954\n",
      "Epoch 3171/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.2778 - mae: 8.8852 - val_loss: 4076.8711 - val_mae: 34.7444\n",
      "Epoch 3172/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.6204 - mae: 8.6469 - val_loss: 4139.6372 - val_mae: 35.0310\n",
      "Epoch 3173/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.2184 - mae: 8.5249 - val_loss: 4075.8418 - val_mae: 35.3177\n",
      "Epoch 3174/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.4187 - mae: 8.8867 - val_loss: 4087.4492 - val_mae: 35.4163\n",
      "Epoch 3175/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.1265 - mae: 9.4165 - val_loss: 4086.2898 - val_mae: 35.3948\n",
      "Epoch 3176/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.3817 - mae: 8.7786 - val_loss: 4112.8477 - val_mae: 35.3940\n",
      "Epoch 3177/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.4026 - mae: 8.6606 - val_loss: 4145.1265 - val_mae: 35.3894\n",
      "Epoch 3178/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.4969 - mae: 8.5289 - val_loss: 4170.0786 - val_mae: 35.0061\n",
      "Epoch 3179/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.3297 - mae: 8.6784 - val_loss: 4180.1074 - val_mae: 35.6325\n",
      "Epoch 3180/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.3846 - mae: 8.2979 - val_loss: 4139.6670 - val_mae: 35.6897\n",
      "Epoch 3181/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.5189 - mae: 8.7732 - val_loss: 4313.0610 - val_mae: 36.1613\n",
      "Epoch 3182/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.0428 - mae: 8.5395 - val_loss: 4156.5210 - val_mae: 35.5311\n",
      "Epoch 3183/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.6149 - mae: 8.3172 - val_loss: 4188.7676 - val_mae: 35.8869\n",
      "Epoch 3184/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.3426 - mae: 8.5487 - val_loss: 4029.0691 - val_mae: 35.3397\n",
      "Epoch 3185/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.7463 - mae: 8.5060 - val_loss: 4142.0645 - val_mae: 35.6425\n",
      "Epoch 3186/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.4319 - mae: 8.4013 - val_loss: 4278.1758 - val_mae: 36.0959\n",
      "Epoch 3187/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.4237 - mae: 8.2818 - val_loss: 4148.6797 - val_mae: 35.9771\n",
      "Epoch 3188/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.3065 - mae: 8.3129 - val_loss: 4190.9805 - val_mae: 35.6904\n",
      "Epoch 3189/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.6907 - mae: 8.3139 - val_loss: 4095.0715 - val_mae: 35.2029\n",
      "Epoch 3190/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.8519 - mae: 8.4304 - val_loss: 4059.2622 - val_mae: 34.8269\n",
      "Epoch 3191/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.9349 - mae: 8.2572 - val_loss: 4127.6162 - val_mae: 35.5829\n",
      "Epoch 3192/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 174.2145 - mae: 8.1172 - val_loss: 4212.3379 - val_mae: 36.1083\n",
      "Epoch 3193/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.6145 - mae: 8.2271 - val_loss: 4140.1553 - val_mae: 35.5455\n",
      "Epoch 3194/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.0732 - mae: 8.5029 - val_loss: 4250.1826 - val_mae: 36.2409\n",
      "Epoch 3195/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.9250 - mae: 8.6127 - val_loss: 4110.3350 - val_mae: 36.0455\n",
      "Epoch 3196/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.5574 - mae: 8.4524 - val_loss: 4212.2114 - val_mae: 36.1196\n",
      "Epoch 3197/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.1217 - mae: 8.4709 - val_loss: 4141.8838 - val_mae: 35.6578\n",
      "Epoch 3198/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.4882 - mae: 8.4358 - val_loss: 4086.3755 - val_mae: 35.8259\n",
      "Epoch 3199/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.4684 - mae: 8.5844 - val_loss: 4159.1450 - val_mae: 36.0234\n",
      "Epoch 3200/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.1944 - mae: 8.6633 - val_loss: 4179.1074 - val_mae: 35.7375\n",
      "Epoch 3201/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.5199 - mae: 8.0596 - val_loss: 4186.6646 - val_mae: 36.1014\n",
      "Epoch 3202/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.6180 - mae: 8.3542 - val_loss: 4168.9922 - val_mae: 35.8758\n",
      "Epoch 3203/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 248.4825 - mae: 8.9021 - val_loss: 4182.0518 - val_mae: 36.0198\n",
      "Epoch 3204/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 291.1440 - mae: 9.0286 - val_loss: 4080.0427 - val_mae: 35.2866\n",
      "Epoch 3205/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.0087 - mae: 8.8674 - val_loss: 4059.4758 - val_mae: 35.0144\n",
      "Epoch 3206/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.3365 - mae: 9.0436 - val_loss: 4020.9131 - val_mae: 35.2071\n",
      "Epoch 3207/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.0420 - mae: 8.4628 - val_loss: 4069.1143 - val_mae: 35.2825\n",
      "Epoch 3208/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.1565 - mae: 8.9432 - val_loss: 4095.5623 - val_mae: 35.1310\n",
      "Epoch 3209/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.0900 - mae: 8.4111 - val_loss: 4133.3623 - val_mae: 35.7721\n",
      "Epoch 3210/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.5315 - mae: 8.7110 - val_loss: 4077.9426 - val_mae: 35.3652\n",
      "Epoch 3211/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 536.8561 - mae: 8.9873 - val_loss: 4111.1279 - val_mae: 35.6104\n",
      "Epoch 3212/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 284.1924 - mae: 9.0950 - val_loss: 4043.4785 - val_mae: 35.8446\n",
      "Epoch 3213/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 276.0049 - mae: 8.9873 - val_loss: 4035.2209 - val_mae: 35.4911\n",
      "Epoch 3214/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.6248 - mae: 9.0319 - val_loss: 4083.2043 - val_mae: 35.6281\n",
      "Epoch 3215/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 256.8072 - mae: 9.1186 - val_loss: 4134.1094 - val_mae: 35.8472\n",
      "Epoch 3216/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.1192 - mae: 8.9967 - val_loss: 4110.1240 - val_mae: 35.3538\n",
      "Epoch 3217/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.7877 - mae: 8.5939 - val_loss: 4132.0991 - val_mae: 35.4426\n",
      "Epoch 3218/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.0739 - mae: 8.8016 - val_loss: 4140.1650 - val_mae: 35.6467\n",
      "Epoch 3219/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.6591 - mae: 8.6124 - val_loss: 4153.6289 - val_mae: 35.9699\n",
      "Epoch 3220/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.4153 - mae: 8.6540 - val_loss: 4161.3735 - val_mae: 35.8687\n",
      "Epoch 3221/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 286.9915 - mae: 9.0264 - val_loss: 4078.6650 - val_mae: 35.7469\n",
      "Epoch 3222/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.6464 - mae: 8.6710 - val_loss: 4085.3088 - val_mae: 35.8063\n",
      "Epoch 3223/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.3704 - mae: 8.3774 - val_loss: 4075.7473 - val_mae: 35.6900\n",
      "Epoch 3224/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.7057 - mae: 8.5837 - val_loss: 3982.7356 - val_mae: 35.3935\n",
      "Epoch 3225/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.1706 - mae: 8.6276 - val_loss: 4144.0879 - val_mae: 35.6673\n",
      "Epoch 3226/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 326.2172 - mae: 8.8801 - val_loss: 4141.3618 - val_mae: 35.6844\n",
      "Epoch 3227/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.3589 - mae: 8.5171 - val_loss: 4097.7383 - val_mae: 35.4110\n",
      "Epoch 3228/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 209.1463 - mae: 8.4608 - val_loss: 4070.3540 - val_mae: 35.1854\n",
      "Epoch 3229/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.0670 - mae: 8.4841 - val_loss: 4112.2275 - val_mae: 35.4593\n",
      "Epoch 3230/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.5592 - mae: 8.5366 - val_loss: 4035.0095 - val_mae: 35.4239\n",
      "Epoch 3231/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.4501 - mae: 8.2879 - val_loss: 3926.9319 - val_mae: 35.1476\n",
      "Epoch 3232/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.3988 - mae: 8.4456 - val_loss: 4043.7432 - val_mae: 35.6788\n",
      "Epoch 3233/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.4857 - mae: 8.6871 - val_loss: 4144.4453 - val_mae: 35.9102\n",
      "Epoch 3234/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.8419 - mae: 8.4303 - val_loss: 4088.8828 - val_mae: 35.6920\n",
      "Epoch 3235/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.7828 - mae: 8.3654 - val_loss: 4166.7407 - val_mae: 35.7941\n",
      "Epoch 3236/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.9032 - mae: 8.6482 - val_loss: 3950.3687 - val_mae: 34.8724\n",
      "Epoch 3237/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.0250 - mae: 8.5955 - val_loss: 4080.7810 - val_mae: 35.0584\n",
      "Epoch 3238/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 289.3910 - mae: 9.0046 - val_loss: 3987.8267 - val_mae: 35.0108\n",
      "Epoch 3239/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2495 - mae: 8.4656 - val_loss: 3882.7585 - val_mae: 34.6994\n",
      "Epoch 3240/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.5377 - mae: 8.5973 - val_loss: 4048.5254 - val_mae: 35.1754\n",
      "Epoch 3241/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 228.1048 - mae: 8.2314 - val_loss: 3974.1741 - val_mae: 34.7670\n",
      "Epoch 3242/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.2675 - mae: 8.4761 - val_loss: 4058.5293 - val_mae: 35.7990\n",
      "Epoch 3243/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.9880 - mae: 8.5646 - val_loss: 4093.9656 - val_mae: 35.4753\n",
      "Epoch 3244/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.1566 - mae: 8.5925 - val_loss: 4072.3853 - val_mae: 35.0188\n",
      "Epoch 3245/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.6067 - mae: 8.4586 - val_loss: 4072.3767 - val_mae: 35.1635\n",
      "Epoch 3246/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.5570 - mae: 8.4960 - val_loss: 4161.4702 - val_mae: 36.1866\n",
      "Epoch 3247/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 216.2751 - mae: 8.3973 - val_loss: 4082.1787 - val_mae: 35.8811\n",
      "Epoch 3248/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.3377 - mae: 8.3466 - val_loss: 4120.6196 - val_mae: 35.7132\n",
      "Epoch 3249/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.2170 - mae: 8.6873 - val_loss: 4145.3354 - val_mae: 35.7539\n",
      "Epoch 3250/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.0945 - mae: 8.2025 - val_loss: 4051.1643 - val_mae: 35.5011\n",
      "Epoch 3251/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.2491 - mae: 8.1743 - val_loss: 4097.3076 - val_mae: 35.6550\n",
      "Epoch 3252/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 206.8904 - mae: 8.2818 - val_loss: 4021.9578 - val_mae: 34.9915\n",
      "Epoch 3253/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.7320 - mae: 8.2363 - val_loss: 4006.9006 - val_mae: 35.3802\n",
      "Epoch 3254/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 240.9261 - mae: 8.5793 - val_loss: 3939.0229 - val_mae: 35.3837\n",
      "Epoch 3255/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.2711 - mae: 8.2261 - val_loss: 3992.6072 - val_mae: 34.9936\n",
      "Epoch 3256/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.4612 - mae: 8.2004 - val_loss: 4115.5923 - val_mae: 35.5225\n",
      "Epoch 3257/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.4516 - mae: 8.3520 - val_loss: 4156.5835 - val_mae: 36.1904\n",
      "Epoch 3258/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.0262 - mae: 8.2602 - val_loss: 4074.1365 - val_mae: 35.8740\n",
      "Epoch 3259/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.5363 - mae: 8.8215 - val_loss: 4058.7236 - val_mae: 35.2867\n",
      "Epoch 3260/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 292.7182 - mae: 9.1862 - val_loss: 4115.2827 - val_mae: 35.7688\n",
      "Epoch 3261/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.8833 - mae: 8.9457 - val_loss: 4109.8638 - val_mae: 36.2320\n",
      "Epoch 3262/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.9648 - mae: 8.8680 - val_loss: 4101.6382 - val_mae: 36.1544\n",
      "Epoch 3263/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.5980 - mae: 8.7169 - val_loss: 4035.7480 - val_mae: 34.7477\n",
      "Epoch 3264/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.0096 - mae: 8.3393 - val_loss: 4158.4429 - val_mae: 35.7308\n",
      "Epoch 3265/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.1625 - mae: 8.5652 - val_loss: 4148.2290 - val_mae: 35.7265\n",
      "Epoch 3266/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.9922 - mae: 8.6454 - val_loss: 4141.6455 - val_mae: 35.5183\n",
      "Epoch 3267/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.8440 - mae: 8.9925 - val_loss: 4145.3179 - val_mae: 35.7279\n",
      "Epoch 3268/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.6457 - mae: 8.8816 - val_loss: 4157.6694 - val_mae: 35.9233\n",
      "Epoch 3269/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.5259 - mae: 8.5441 - val_loss: 4230.6533 - val_mae: 36.1207\n",
      "Epoch 3270/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.6736 - mae: 8.2329 - val_loss: 4195.9009 - val_mae: 36.2855\n",
      "Epoch 3271/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.4749 - mae: 7.9178 - val_loss: 4222.2915 - val_mae: 36.1798\n",
      "Epoch 3272/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.6189 - mae: 8.8469 - val_loss: 4084.0532 - val_mae: 35.3233\n",
      "Epoch 3273/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.0209 - mae: 8.3938 - val_loss: 4090.2205 - val_mae: 35.8243\n",
      "Epoch 3274/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.5560 - mae: 8.7425 - val_loss: 4101.2881 - val_mae: 35.5000\n",
      "Epoch 3275/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.2882 - mae: 8.3870 - val_loss: 4253.4839 - val_mae: 36.6021\n",
      "Epoch 3276/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.3974 - mae: 8.8757 - val_loss: 4105.2427 - val_mae: 35.7943\n",
      "Epoch 3277/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.9155 - mae: 9.1325 - val_loss: 4151.2925 - val_mae: 35.7815\n",
      "Epoch 3278/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.1064 - mae: 8.8075 - val_loss: 4100.3804 - val_mae: 35.6151\n",
      "Epoch 3279/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.0800 - mae: 8.8105 - val_loss: 4221.3213 - val_mae: 35.8571\n",
      "Epoch 3280/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.3351 - mae: 8.8006 - val_loss: 4082.6404 - val_mae: 35.4580\n",
      "Epoch 3281/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 248.3243 - mae: 8.9011 - val_loss: 4195.0127 - val_mae: 36.0986\n",
      "Epoch 3282/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.8008 - mae: 8.7311 - val_loss: 4126.8120 - val_mae: 35.9731\n",
      "Epoch 3283/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.9656 - mae: 8.7162 - val_loss: 4066.5027 - val_mae: 35.7986\n",
      "Epoch 3284/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.6870 - mae: 8.3177 - val_loss: 4106.1011 - val_mae: 36.1449\n",
      "Epoch 3285/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.6672 - mae: 8.4367 - val_loss: 4159.6660 - val_mae: 36.1252\n",
      "Epoch 3286/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.2488 - mae: 8.8761 - val_loss: 4114.1187 - val_mae: 36.1505\n",
      "Epoch 3287/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 246.7351 - mae: 9.0038 - val_loss: 4172.2124 - val_mae: 36.1343\n",
      "Epoch 3288/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.7153 - mae: 8.6494 - val_loss: 4144.6060 - val_mae: 35.6910\n",
      "Epoch 3289/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.1544 - mae: 8.8100 - val_loss: 4112.9727 - val_mae: 36.1334\n",
      "Epoch 3290/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 209.8476 - mae: 8.5296 - val_loss: 4017.9224 - val_mae: 35.5198\n",
      "Epoch 3291/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.1607 - mae: 8.7618 - val_loss: 4065.3291 - val_mae: 35.8659\n",
      "Epoch 3292/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 263.8294 - mae: 8.8387 - val_loss: 4039.0815 - val_mae: 35.7252\n",
      "Epoch 3293/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.7402 - mae: 8.4190 - val_loss: 3992.4858 - val_mae: 34.3753\n",
      "Epoch 3294/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.5446 - mae: 9.0501 - val_loss: 3971.2231 - val_mae: 35.2391\n",
      "Epoch 3295/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.9644 - mae: 8.4077 - val_loss: 3968.0537 - val_mae: 34.8864\n",
      "Epoch 3296/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.3417 - mae: 8.7241 - val_loss: 4054.5447 - val_mae: 35.9441\n",
      "Epoch 3297/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.3378 - mae: 8.4687 - val_loss: 4125.4575 - val_mae: 35.5147\n",
      "Epoch 3298/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.1082 - mae: 8.6832 - val_loss: 3969.0029 - val_mae: 35.2506\n",
      "Epoch 3299/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.8390 - mae: 8.3912 - val_loss: 4119.0288 - val_mae: 35.9850\n",
      "Epoch 3300/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.5842 - mae: 8.6220 - val_loss: 4137.9175 - val_mae: 35.8914\n",
      "Epoch 3301/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.7475 - mae: 8.6354 - val_loss: 4230.2363 - val_mae: 36.3137\n",
      "Epoch 3302/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.5957 - mae: 8.6844 - val_loss: 3982.2686 - val_mae: 35.4788\n",
      "Epoch 3303/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 243.1539 - mae: 8.8252 - val_loss: 4035.0786 - val_mae: 34.9548\n",
      "Epoch 3304/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.9872 - mae: 8.4990 - val_loss: 3982.3962 - val_mae: 34.9181\n",
      "Epoch 3305/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 191.0042 - mae: 8.2906 - val_loss: 4028.2915 - val_mae: 35.4284\n",
      "Epoch 3306/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.2298 - mae: 9.3862 - val_loss: 3993.8484 - val_mae: 35.7438\n",
      "Epoch 3307/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.4338 - mae: 8.6857 - val_loss: 4049.3813 - val_mae: 35.1289\n",
      "Epoch 3308/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.1058 - mae: 8.7620 - val_loss: 4111.6787 - val_mae: 36.0400\n",
      "Epoch 3309/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.1113 - mae: 8.6924 - val_loss: 4183.0742 - val_mae: 35.5171\n",
      "Epoch 3310/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.2036 - mae: 8.8916 - val_loss: 4054.2007 - val_mae: 34.5293\n",
      "Epoch 3311/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 296.7859 - mae: 8.9763 - val_loss: 4053.2188 - val_mae: 34.5740\n",
      "Epoch 3312/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.8535 - mae: 8.9437 - val_loss: 4008.2913 - val_mae: 34.8070\n",
      "Epoch 3313/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 271.7102 - mae: 9.1485 - val_loss: 4098.0361 - val_mae: 35.0261\n",
      "Epoch 3314/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.1369 - mae: 8.6720 - val_loss: 4092.1123 - val_mae: 35.0430\n",
      "Epoch 3315/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 285.9792 - mae: 9.0119 - val_loss: 4086.1758 - val_mae: 35.3611\n",
      "Epoch 3316/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.4423 - mae: 8.3744 - val_loss: 4189.5815 - val_mae: 35.7702\n",
      "Epoch 3317/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.7723 - mae: 8.3599 - val_loss: 4136.5835 - val_mae: 35.1586\n",
      "Epoch 3318/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.0141 - mae: 8.5123 - val_loss: 3924.5386 - val_mae: 34.7576\n",
      "Epoch 3319/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.1101 - mae: 8.2799 - val_loss: 4181.5620 - val_mae: 35.9890\n",
      "Epoch 3320/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.8591 - mae: 8.2840 - val_loss: 4145.4175 - val_mae: 35.4002\n",
      "Epoch 3321/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.7726 - mae: 8.8251 - val_loss: 3990.8250 - val_mae: 34.7027\n",
      "Epoch 3322/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.1105 - mae: 8.6544 - val_loss: 4089.4048 - val_mae: 35.4167\n",
      "Epoch 3323/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.6073 - mae: 8.5513 - val_loss: 4067.9844 - val_mae: 34.9874\n",
      "Epoch 3324/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.9157 - mae: 8.6083 - val_loss: 3991.2236 - val_mae: 35.3666\n",
      "Epoch 3325/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.0807 - mae: 8.2713 - val_loss: 4123.7114 - val_mae: 35.4776\n",
      "Epoch 3326/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.2990 - mae: 8.2866 - val_loss: 4254.2129 - val_mae: 36.4181\n",
      "Epoch 3327/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.4648 - mae: 8.3197 - val_loss: 4127.4609 - val_mae: 35.5318\n",
      "Epoch 3328/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.0846 - mae: 8.3599 - val_loss: 4125.8506 - val_mae: 35.3528\n",
      "Epoch 3329/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.9637 - mae: 8.8016 - val_loss: 4156.1177 - val_mae: 35.4844\n",
      "Epoch 3330/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.5461 - mae: 8.5908 - val_loss: 4070.5464 - val_mae: 35.6092\n",
      "Epoch 3331/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.7249 - mae: 8.5509 - val_loss: 4096.9043 - val_mae: 35.1933\n",
      "Epoch 3332/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.3518 - mae: 8.8140 - val_loss: 4003.5051 - val_mae: 35.1692\n",
      "Epoch 3333/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.5185 - mae: 8.7296 - val_loss: 3985.7009 - val_mae: 35.0523\n",
      "Epoch 3334/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.5721 - mae: 8.4897 - val_loss: 4015.4985 - val_mae: 35.0243\n",
      "Epoch 3335/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.5392 - mae: 8.5436 - val_loss: 4075.2063 - val_mae: 35.6912\n",
      "Epoch 3336/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.8103 - mae: 8.5413 - val_loss: 4185.5488 - val_mae: 35.5615\n",
      "Epoch 3337/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.7014 - mae: 8.3778 - val_loss: 4180.0200 - val_mae: 35.5667\n",
      "Epoch 3338/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.0782 - mae: 8.3099 - val_loss: 4077.8394 - val_mae: 35.1514\n",
      "Epoch 3339/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.7249 - mae: 8.3391 - val_loss: 4232.0986 - val_mae: 36.4512\n",
      "Epoch 3340/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.7610 - mae: 8.5801 - val_loss: 4088.3877 - val_mae: 35.8869\n",
      "Epoch 3341/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.6286 - mae: 8.6466 - val_loss: 4106.3340 - val_mae: 35.5592\n",
      "Epoch 3342/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.3750 - mae: 8.1757 - val_loss: 4098.3745 - val_mae: 35.5267\n",
      "Epoch 3343/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.1395 - mae: 8.2613 - val_loss: 4146.0171 - val_mae: 35.4527\n",
      "Epoch 3344/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.3211 - mae: 8.6930 - val_loss: 4168.5000 - val_mae: 36.0224\n",
      "Epoch 3345/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.3451 - mae: 8.7120 - val_loss: 4083.4819 - val_mae: 35.7244\n",
      "Epoch 3346/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.8226 - mae: 8.5165 - val_loss: 3976.5767 - val_mae: 35.2879\n",
      "Epoch 3347/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.6274 - mae: 8.5072 - val_loss: 4032.6802 - val_mae: 35.3701\n",
      "Epoch 3348/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.5125 - mae: 8.6007 - val_loss: 3922.4631 - val_mae: 35.2028\n",
      "Epoch 3349/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.2452 - mae: 8.6488 - val_loss: 3961.1531 - val_mae: 34.8083\n",
      "Epoch 3350/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.4520 - mae: 8.2815 - val_loss: 4086.8040 - val_mae: 35.3403\n",
      "Epoch 3351/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.1100 - mae: 8.5423 - val_loss: 4128.1997 - val_mae: 35.6142\n",
      "Epoch 3352/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.6350 - mae: 8.8229 - val_loss: 4075.7952 - val_mae: 35.2327\n",
      "Epoch 3353/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.6563 - mae: 8.8148 - val_loss: 4011.8728 - val_mae: 34.9920\n",
      "Epoch 3354/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.8593 - mae: 8.7645 - val_loss: 3989.3533 - val_mae: 35.0402\n",
      "Epoch 3355/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.0150 - mae: 8.5195 - val_loss: 3967.0068 - val_mae: 34.9797\n",
      "Epoch 3356/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.1163 - mae: 8.5958 - val_loss: 3917.1262 - val_mae: 34.8053\n",
      "Epoch 3357/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.8049 - mae: 8.7906 - val_loss: 3858.5381 - val_mae: 34.4211\n",
      "Epoch 3358/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.5946 - mae: 8.4149 - val_loss: 3909.5088 - val_mae: 34.7480\n",
      "Epoch 3359/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.7130 - mae: 8.4603 - val_loss: 3972.4382 - val_mae: 34.7713\n",
      "Epoch 3360/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.2219 - mae: 8.4693 - val_loss: 3962.3660 - val_mae: 35.0256\n",
      "Epoch 3361/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.3655 - mae: 8.8011 - val_loss: 4020.6643 - val_mae: 35.1494\n",
      "Epoch 3362/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 263.9902 - mae: 8.5302 - val_loss: 4027.2129 - val_mae: 35.6636\n",
      "Epoch 3363/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.5166 - mae: 8.5611 - val_loss: 4054.6497 - val_mae: 35.1800\n",
      "Epoch 3364/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.8067 - mae: 8.5310 - val_loss: 4071.8743 - val_mae: 35.7523\n",
      "Epoch 3365/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.7616 - mae: 8.5441 - val_loss: 4180.6206 - val_mae: 35.6855\n",
      "Epoch 3366/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.8786 - mae: 7.9527 - val_loss: 4100.0659 - val_mae: 35.7668\n",
      "Epoch 3367/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.0432 - mae: 8.1846 - val_loss: 4137.6396 - val_mae: 36.0864\n",
      "Epoch 3368/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.2162 - mae: 8.5116 - val_loss: 4104.2285 - val_mae: 35.5757\n",
      "Epoch 3369/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.1793 - mae: 8.7901 - val_loss: 4103.9907 - val_mae: 35.5673\n",
      "Epoch 3370/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.9434 - mae: 8.5637 - val_loss: 4046.5137 - val_mae: 35.6239\n",
      "Epoch 3371/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 254.1033 - mae: 8.9425 - val_loss: 4022.4297 - val_mae: 35.2784\n",
      "Epoch 3372/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.5477 - mae: 8.4727 - val_loss: 4115.7222 - val_mae: 35.6195\n",
      "Epoch 3373/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.6077 - mae: 8.5143 - val_loss: 4083.0811 - val_mae: 35.7183\n",
      "Epoch 3374/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.7220 - mae: 8.3650 - val_loss: 4042.1479 - val_mae: 35.5562\n",
      "Epoch 3375/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.6562 - mae: 8.3730 - val_loss: 4017.5107 - val_mae: 35.4489\n",
      "Epoch 3376/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 186.0556 - mae: 8.1767 - val_loss: 4011.6721 - val_mae: 35.4771\n",
      "Epoch 3377/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.2651 - mae: 8.2949 - val_loss: 4077.4165 - val_mae: 36.2228\n",
      "Epoch 3378/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 209.0413 - mae: 8.2728 - val_loss: 4199.0259 - val_mae: 35.8640\n",
      "Epoch 3379/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.9902 - mae: 8.6758 - val_loss: 4229.0562 - val_mae: 36.0220\n",
      "Epoch 3380/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.5485 - mae: 8.2517 - val_loss: 4008.7683 - val_mae: 36.0592\n",
      "Epoch 3381/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 270.2972 - mae: 8.9761 - val_loss: 4133.4209 - val_mae: 36.0280\n",
      "Epoch 3382/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.3639 - mae: 8.8651 - val_loss: 4077.8750 - val_mae: 35.9871\n",
      "Epoch 3383/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.4669 - mae: 8.5198 - val_loss: 4158.7915 - val_mae: 36.3430\n",
      "Epoch 3384/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 228.0325 - mae: 8.4790 - val_loss: 4216.1377 - val_mae: 36.6961\n",
      "Epoch 3385/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 252.9636 - mae: 8.8300 - val_loss: 4036.9670 - val_mae: 35.2487\n",
      "Epoch 3386/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.4930 - mae: 8.3789 - val_loss: 4109.6489 - val_mae: 36.3971\n",
      "Epoch 3387/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 206.5095 - mae: 8.4768 - val_loss: 4012.6245 - val_mae: 35.5676\n",
      "Epoch 3388/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 204.7260 - mae: 8.4689 - val_loss: 4031.3762 - val_mae: 35.7899\n",
      "Epoch 3389/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.2675 - mae: 8.5702 - val_loss: 3961.3342 - val_mae: 35.0198\n",
      "Epoch 3390/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.8159 - mae: 8.3710 - val_loss: 3991.3215 - val_mae: 35.3869\n",
      "Epoch 3391/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.1160 - mae: 8.4248 - val_loss: 4018.7937 - val_mae: 35.4261\n",
      "Epoch 3392/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.6250 - mae: 8.2468 - val_loss: 3988.0481 - val_mae: 35.3719\n",
      "Epoch 3393/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 201.8308 - mae: 8.2045 - val_loss: 4015.5864 - val_mae: 35.8138\n",
      "Epoch 3394/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.2190 - mae: 8.1689 - val_loss: 4022.5635 - val_mae: 35.6198\n",
      "Epoch 3395/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.8844 - mae: 8.5605 - val_loss: 4187.5190 - val_mae: 36.4139\n",
      "Epoch 3396/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.9523 - mae: 8.5624 - val_loss: 4077.0833 - val_mae: 35.8607\n",
      "Epoch 3397/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.4803 - mae: 8.2011 - val_loss: 4149.0396 - val_mae: 35.6656\n",
      "Epoch 3398/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.7096 - mae: 8.3166 - val_loss: 4065.1797 - val_mae: 35.7874\n",
      "Epoch 3399/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.3999 - mae: 8.1964 - val_loss: 4108.7666 - val_mae: 36.0367\n",
      "Epoch 3400/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.1022 - mae: 8.4466 - val_loss: 4081.6946 - val_mae: 36.0391\n",
      "Epoch 3401/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 221.8961 - mae: 8.5840 - val_loss: 4221.7056 - val_mae: 36.3746\n",
      "Epoch 3402/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.0719 - mae: 8.2028 - val_loss: 4140.3301 - val_mae: 36.1012\n",
      "Epoch 3403/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 181.9002 - mae: 8.3496 - val_loss: 4146.5068 - val_mae: 36.2062\n",
      "Epoch 3404/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.4365 - mae: 8.5121 - val_loss: 4233.9253 - val_mae: 36.6588\n",
      "Epoch 3405/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 175.7329 - mae: 8.0218 - val_loss: 4218.1738 - val_mae: 36.2352\n",
      "Epoch 3406/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.7339 - mae: 8.2360 - val_loss: 4230.8926 - val_mae: 36.7352\n",
      "Epoch 3407/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.3961 - mae: 8.3369 - val_loss: 4269.5376 - val_mae: 36.8953\n",
      "Epoch 3408/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.6612 - mae: 8.2896 - val_loss: 4098.3369 - val_mae: 35.9392\n",
      "Epoch 3409/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.5946 - mae: 8.3485 - val_loss: 4132.3125 - val_mae: 36.2510\n",
      "Epoch 3410/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 212.6337 - mae: 8.4313 - val_loss: 4183.6875 - val_mae: 36.6846\n",
      "Epoch 3411/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.4808 - mae: 8.8296 - val_loss: 4069.4458 - val_mae: 35.8226\n",
      "Epoch 3412/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.9726 - mae: 8.4444 - val_loss: 4028.3767 - val_mae: 35.9486\n",
      "Epoch 3413/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.2745 - mae: 8.1029 - val_loss: 4135.5254 - val_mae: 35.9432\n",
      "Epoch 3414/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.2319 - mae: 8.6144 - val_loss: 4155.5835 - val_mae: 35.9237\n",
      "Epoch 3415/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.0774 - mae: 8.2227 - val_loss: 3995.9216 - val_mae: 35.3659\n",
      "Epoch 3416/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.7657 - mae: 8.3285 - val_loss: 4039.1440 - val_mae: 35.7269\n",
      "Epoch 3417/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.9321 - mae: 8.5470 - val_loss: 4099.9580 - val_mae: 35.9785\n",
      "Epoch 3418/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.4231 - mae: 8.6098 - val_loss: 4220.0332 - val_mae: 36.5159\n",
      "Epoch 3419/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 225.9601 - mae: 8.4952 - val_loss: 4063.8489 - val_mae: 35.3390\n",
      "Epoch 3420/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.2089 - mae: 8.6328 - val_loss: 4175.3018 - val_mae: 35.5270\n",
      "Epoch 3421/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.9863 - mae: 8.6672 - val_loss: 4036.4692 - val_mae: 35.4033\n",
      "Epoch 3422/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 261.2756 - mae: 8.7697 - val_loss: 4159.0894 - val_mae: 36.0068\n",
      "Epoch 3423/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.2227 - mae: 8.4843 - val_loss: 4072.3667 - val_mae: 35.9510\n",
      "Epoch 3424/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.8341 - mae: 8.7700 - val_loss: 4050.3748 - val_mae: 35.4382\n",
      "Epoch 3425/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.0618 - mae: 8.2313 - val_loss: 4008.4292 - val_mae: 35.5872\n",
      "Epoch 3426/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 216.6136 - mae: 8.5012 - val_loss: 4054.3506 - val_mae: 35.3128\n",
      "Epoch 3427/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.0842 - mae: 8.4422 - val_loss: 4101.7510 - val_mae: 35.3906\n",
      "Epoch 3428/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.3821 - mae: 8.1624 - val_loss: 4015.8342 - val_mae: 35.7056\n",
      "Epoch 3429/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 189.4141 - mae: 8.2293 - val_loss: 3895.9094 - val_mae: 34.5178\n",
      "Epoch 3430/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.3409 - mae: 8.6495 - val_loss: 3876.3706 - val_mae: 34.6051\n",
      "Epoch 3431/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.1772 - mae: 8.2282 - val_loss: 3996.6062 - val_mae: 34.8420\n",
      "Epoch 3432/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.4175 - mae: 7.9226 - val_loss: 3922.8635 - val_mae: 34.6275\n",
      "Epoch 3433/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.1869 - mae: 8.4805 - val_loss: 3985.3755 - val_mae: 35.5324\n",
      "Epoch 3434/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.3547 - mae: 8.3639 - val_loss: 3992.6624 - val_mae: 35.8454\n",
      "Epoch 3435/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.8981 - mae: 8.8267 - val_loss: 3970.4385 - val_mae: 35.3395\n",
      "Epoch 3436/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.0309 - mae: 8.1695 - val_loss: 3981.2520 - val_mae: 35.4002\n",
      "Epoch 3437/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 172.6842 - mae: 7.8900 - val_loss: 4098.2891 - val_mae: 35.6037\n",
      "Epoch 3438/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.7122 - mae: 8.0888 - val_loss: 4000.1199 - val_mae: 35.3961\n",
      "Epoch 3439/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 187.0824 - mae: 7.9315 - val_loss: 3966.3711 - val_mae: 35.2855\n",
      "Epoch 3440/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.0992 - mae: 8.5761 - val_loss: 3891.3022 - val_mae: 34.7798\n",
      "Epoch 3441/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.3118 - mae: 8.1852 - val_loss: 4012.7205 - val_mae: 35.4201\n",
      "Epoch 3442/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.9792 - mae: 8.2582 - val_loss: 3958.9893 - val_mae: 34.9706\n",
      "Epoch 3443/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2265 - mae: 8.2066 - val_loss: 4005.7288 - val_mae: 35.5104\n",
      "Epoch 3444/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.2588 - mae: 8.2834 - val_loss: 4052.6555 - val_mae: 35.4802\n",
      "Epoch 3445/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.6680 - mae: 8.5384 - val_loss: 4020.0183 - val_mae: 35.4505\n",
      "Epoch 3446/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 204.3024 - mae: 8.1920 - val_loss: 4119.7627 - val_mae: 35.1510\n",
      "Epoch 3447/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 204.5289 - mae: 8.3619 - val_loss: 4057.3306 - val_mae: 35.2676\n",
      "Epoch 3448/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.3022 - mae: 8.0223 - val_loss: 3990.7793 - val_mae: 35.0075\n",
      "Epoch 3449/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.6839 - mae: 8.3760 - val_loss: 4053.8074 - val_mae: 34.9183\n",
      "Epoch 3450/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.7379 - mae: 8.1363 - val_loss: 4120.4688 - val_mae: 35.2461\n",
      "Epoch 3451/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.5516 - mae: 8.3657 - val_loss: 3949.2305 - val_mae: 34.8224\n",
      "Epoch 3452/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 189.8871 - mae: 8.1724 - val_loss: 4039.3005 - val_mae: 35.2121\n",
      "Epoch 3453/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.2171 - mae: 8.3877 - val_loss: 4067.9878 - val_mae: 35.6966\n",
      "Epoch 3454/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 241.6131 - mae: 8.5724 - val_loss: 4059.3328 - val_mae: 35.4295\n",
      "Epoch 3455/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.6328 - mae: 8.4220 - val_loss: 3934.9546 - val_mae: 34.4140\n",
      "Epoch 3456/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.5234 - mae: 8.4186 - val_loss: 4025.1768 - val_mae: 35.5430\n",
      "Epoch 3457/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.4982 - mae: 8.6409 - val_loss: 4053.1470 - val_mae: 35.4588\n",
      "Epoch 3458/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.3128 - mae: 8.6223 - val_loss: 4156.1147 - val_mae: 36.1791\n",
      "Epoch 3459/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.8622 - mae: 8.2128 - val_loss: 4083.2815 - val_mae: 35.7631\n",
      "Epoch 3460/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.4664 - mae: 8.6595 - val_loss: 4103.3027 - val_mae: 35.7393\n",
      "Epoch 3461/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.9534 - mae: 8.5416 - val_loss: 4201.1133 - val_mae: 35.9949\n",
      "Epoch 3462/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.5316 - mae: 8.1386 - val_loss: 4145.8315 - val_mae: 35.8931\n",
      "Epoch 3463/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.4555 - mae: 8.7437 - val_loss: 4117.8730 - val_mae: 35.3464\n",
      "Epoch 3464/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.3766 - mae: 8.5801 - val_loss: 4080.1724 - val_mae: 36.0489\n",
      "Epoch 3465/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.0830 - mae: 8.5670 - val_loss: 4070.2502 - val_mae: 35.1849\n",
      "Epoch 3466/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.7177 - mae: 8.3395 - val_loss: 4043.1780 - val_mae: 35.1324\n",
      "Epoch 3467/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.1613 - mae: 8.7015 - val_loss: 4104.2480 - val_mae: 35.7174\n",
      "Epoch 3468/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.2029 - mae: 8.4329 - val_loss: 4102.6470 - val_mae: 35.5548\n",
      "Epoch 3469/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.2631 - mae: 8.5556 - val_loss: 3952.3721 - val_mae: 34.7042\n",
      "Epoch 3470/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.4090 - mae: 8.5139 - val_loss: 3929.4521 - val_mae: 34.4494\n",
      "Epoch 3471/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.5730 - mae: 8.6887 - val_loss: 3997.9553 - val_mae: 34.6859\n",
      "Epoch 3472/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.8425 - mae: 8.6042 - val_loss: 3967.7000 - val_mae: 34.9831\n",
      "Epoch 3473/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.3716 - mae: 8.4276 - val_loss: 3985.4009 - val_mae: 34.8531\n",
      "Epoch 3474/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.1656 - mae: 8.5559 - val_loss: 3906.2031 - val_mae: 34.5602\n",
      "Epoch 3475/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 189.0241 - mae: 8.3762 - val_loss: 4059.0413 - val_mae: 35.6697\n",
      "Epoch 3476/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.6716 - mae: 8.2928 - val_loss: 3970.6863 - val_mae: 35.3298\n",
      "Epoch 3477/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.1464 - mae: 8.4265 - val_loss: 4116.9551 - val_mae: 35.8445\n",
      "Epoch 3478/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.8257 - mae: 8.5251 - val_loss: 4039.1152 - val_mae: 35.7437\n",
      "Epoch 3479/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.0807 - mae: 8.1678 - val_loss: 4128.0156 - val_mae: 36.1532\n",
      "Epoch 3480/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.1848 - mae: 8.3925 - val_loss: 4025.0522 - val_mae: 35.5793\n",
      "Epoch 3481/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.0675 - mae: 8.1136 - val_loss: 4101.1577 - val_mae: 35.4810\n",
      "Epoch 3482/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.9567 - mae: 7.9568 - val_loss: 4121.5020 - val_mae: 35.5321\n",
      "Epoch 3483/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.5787 - mae: 8.2854 - val_loss: 4143.7588 - val_mae: 35.3929\n",
      "Epoch 3484/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 264.6896 - mae: 8.9725 - val_loss: 4029.8086 - val_mae: 35.8203\n",
      "Epoch 3485/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.6542 - mae: 8.8907 - val_loss: 4075.4312 - val_mae: 35.3694\n",
      "Epoch 3486/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.5718 - mae: 8.7802 - val_loss: 4100.8638 - val_mae: 35.1683\n",
      "Epoch 3487/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.4654 - mae: 8.7333 - val_loss: 4034.6455 - val_mae: 35.2621\n",
      "Epoch 3488/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.6708 - mae: 8.5849 - val_loss: 4101.2520 - val_mae: 35.6553\n",
      "Epoch 3489/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.6822 - mae: 8.4017 - val_loss: 4050.8967 - val_mae: 35.3145\n",
      "Epoch 3490/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.4115 - mae: 8.4069 - val_loss: 4103.2676 - val_mae: 35.4609\n",
      "Epoch 3491/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.3360 - mae: 8.5200 - val_loss: 4088.1506 - val_mae: 35.2620\n",
      "Epoch 3492/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.5067 - mae: 8.1023 - val_loss: 4045.8066 - val_mae: 35.3652\n",
      "Epoch 3493/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.3030 - mae: 8.0715 - val_loss: 4173.8081 - val_mae: 36.1970\n",
      "Epoch 3494/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.3169 - mae: 8.1078 - val_loss: 4025.3433 - val_mae: 35.7400\n",
      "Epoch 3495/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.6387 - mae: 8.3073 - val_loss: 4023.5828 - val_mae: 35.3554\n",
      "Epoch 3496/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.2018 - mae: 8.3136 - val_loss: 4230.3374 - val_mae: 36.6953\n",
      "Epoch 3497/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.5366 - mae: 8.4012 - val_loss: 4184.4507 - val_mae: 37.8148\n",
      "Epoch 3498/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.9969 - mae: 9.2880 - val_loss: 4068.4631 - val_mae: 35.0224\n",
      "Epoch 3499/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.9409 - mae: 8.6647 - val_loss: 4139.6201 - val_mae: 36.4202\n",
      "Epoch 3500/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.7456 - mae: 8.1033 - val_loss: 4166.8496 - val_mae: 35.8876\n",
      "Epoch 3501/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.6233 - mae: 8.0678 - val_loss: 4210.1777 - val_mae: 36.5386\n",
      "Epoch 3502/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.6368 - mae: 8.2498 - val_loss: 4274.2837 - val_mae: 35.9333\n",
      "Epoch 3503/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.1745 - mae: 8.3777 - val_loss: 4301.5786 - val_mae: 36.3652\n",
      "Epoch 3504/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.3279 - mae: 8.3589 - val_loss: 4285.7695 - val_mae: 36.4992\n",
      "Epoch 3505/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.4323 - mae: 8.6513 - val_loss: 4307.5142 - val_mae: 36.6452\n",
      "Epoch 3506/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.4311 - mae: 8.4144 - val_loss: 4234.6758 - val_mae: 36.4179\n",
      "Epoch 3507/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.3137 - mae: 8.3283 - val_loss: 4182.1514 - val_mae: 36.3340\n",
      "Epoch 3508/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.7224 - mae: 8.4339 - val_loss: 4154.7837 - val_mae: 36.0795\n",
      "Epoch 3509/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.2530 - mae: 8.8594 - val_loss: 4138.7612 - val_mae: 36.7366\n",
      "Epoch 3510/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 176.6796 - mae: 8.0238 - val_loss: 4184.4126 - val_mae: 36.2661\n",
      "Epoch 3511/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.7221 - mae: 8.4057 - val_loss: 4174.3574 - val_mae: 35.9543\n",
      "Epoch 3512/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.0105 - mae: 8.1702 - val_loss: 3977.7554 - val_mae: 35.7939\n",
      "Epoch 3513/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.3428 - mae: 8.3535 - val_loss: 4197.3179 - val_mae: 36.2113\n",
      "Epoch 3514/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.7858 - mae: 8.1032 - val_loss: 4218.8374 - val_mae: 36.1022\n",
      "Epoch 3515/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.9057 - mae: 7.9708 - val_loss: 4198.9937 - val_mae: 36.3020\n",
      "Epoch 3516/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.3140 - mae: 8.4738 - val_loss: 4191.2568 - val_mae: 35.6351\n",
      "Epoch 3517/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.8202 - mae: 8.2911 - val_loss: 4107.4111 - val_mae: 35.6825\n",
      "Epoch 3518/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.5223 - mae: 8.4093 - val_loss: 4116.1270 - val_mae: 36.3464\n",
      "Epoch 3519/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.9616 - mae: 8.0988 - val_loss: 4193.8184 - val_mae: 36.2215\n",
      "Epoch 3520/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.8090 - mae: 8.2265 - val_loss: 4168.4028 - val_mae: 36.1373\n",
      "Epoch 3521/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.8207 - mae: 8.1305 - val_loss: 4125.2427 - val_mae: 35.9074\n",
      "Epoch 3522/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.5591 - mae: 8.1914 - val_loss: 4187.6182 - val_mae: 35.9138\n",
      "Epoch 3523/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.9952 - mae: 8.2077 - val_loss: 4132.5049 - val_mae: 36.0647\n",
      "Epoch 3524/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.4982 - mae: 8.0526 - val_loss: 4100.1475 - val_mae: 35.7002\n",
      "Epoch 3525/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 173.5058 - mae: 7.9660 - val_loss: 4274.5225 - val_mae: 36.3994\n",
      "Epoch 3526/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.3324 - mae: 8.6747 - val_loss: 4181.0947 - val_mae: 36.2447\n",
      "Epoch 3527/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.2463 - mae: 8.3631 - val_loss: 4157.9336 - val_mae: 36.1480\n",
      "Epoch 3528/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.5307 - mae: 8.3549 - val_loss: 4216.8438 - val_mae: 36.1942\n",
      "Epoch 3529/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.5258 - mae: 8.3024 - val_loss: 4080.2351 - val_mae: 35.7956\n",
      "Epoch 3530/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 163.4446 - mae: 7.8664 - val_loss: 4152.9878 - val_mae: 35.6031\n",
      "Epoch 3531/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.1237 - mae: 8.0434 - val_loss: 4130.1411 - val_mae: 35.3555\n",
      "Epoch 3532/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.3162 - mae: 8.1556 - val_loss: 4182.9805 - val_mae: 35.6276\n",
      "Epoch 3533/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 186.4724 - mae: 8.0842 - val_loss: 4176.8159 - val_mae: 35.2403\n",
      "Epoch 3534/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 212.4031 - mae: 8.2204 - val_loss: 4244.7646 - val_mae: 36.1623\n",
      "Epoch 3535/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.4409 - mae: 8.0797 - val_loss: 4149.3682 - val_mae: 35.8531\n",
      "Epoch 3536/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.9037 - mae: 8.3717 - val_loss: 4321.8701 - val_mae: 36.5128\n",
      "Epoch 3537/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.9318 - mae: 8.1756 - val_loss: 4143.8149 - val_mae: 35.8322\n",
      "Epoch 3538/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.8938 - mae: 8.2851 - val_loss: 4300.6875 - val_mae: 36.6422\n",
      "Epoch 3539/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.4332 - mae: 8.2921 - val_loss: 4233.7871 - val_mae: 36.2149\n",
      "Epoch 3540/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.9265 - mae: 8.3195 - val_loss: 4157.2524 - val_mae: 36.1426\n",
      "Epoch 3541/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.9378 - mae: 8.2367 - val_loss: 4169.7993 - val_mae: 36.2163\n",
      "Epoch 3542/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.3911 - mae: 8.2183 - val_loss: 4117.1069 - val_mae: 35.7392\n",
      "Epoch 3543/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.5789 - mae: 8.0200 - val_loss: 4166.3872 - val_mae: 36.0022\n",
      "Epoch 3544/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 304.4698 - mae: 8.5900 - val_loss: 4143.3320 - val_mae: 35.8093\n",
      "Epoch 3545/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.6806 - mae: 8.4203 - val_loss: 4119.3643 - val_mae: 35.6888\n",
      "Epoch 3546/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 184.8977 - mae: 7.9562 - val_loss: 4132.8018 - val_mae: 36.3363\n",
      "Epoch 3547/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.1580 - mae: 8.3766 - val_loss: 4206.6904 - val_mae: 36.2567\n",
      "Epoch 3548/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.1553 - mae: 8.4568 - val_loss: 4076.2195 - val_mae: 35.9134\n",
      "Epoch 3549/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.2991 - mae: 8.4493 - val_loss: 4021.6165 - val_mae: 35.8865\n",
      "Epoch 3550/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 201.9626 - mae: 8.2576 - val_loss: 4021.1655 - val_mae: 35.1638\n",
      "Epoch 3551/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.8189 - mae: 8.1932 - val_loss: 4124.9229 - val_mae: 35.6960\n",
      "Epoch 3552/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.3001 - mae: 8.1577 - val_loss: 4069.4250 - val_mae: 36.4001\n",
      "Epoch 3553/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.9709 - mae: 8.1447 - val_loss: 4105.0757 - val_mae: 35.6934\n",
      "Epoch 3554/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.2089 - mae: 7.8633 - val_loss: 4190.1899 - val_mae: 36.2969\n",
      "Epoch 3555/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 166.3314 - mae: 7.8108 - val_loss: 4100.2007 - val_mae: 35.7901\n",
      "Epoch 3556/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.2317 - mae: 8.2489 - val_loss: 4156.3975 - val_mae: 36.1901\n",
      "Epoch 3557/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.9592 - mae: 8.2536 - val_loss: 4153.2241 - val_mae: 36.1103\n",
      "Epoch 3558/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.2793 - mae: 8.4061 - val_loss: 4159.7881 - val_mae: 35.8102\n",
      "Epoch 3559/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.9102 - mae: 8.2885 - val_loss: 4087.8064 - val_mae: 35.7643\n",
      "Epoch 3560/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.5470 - mae: 8.4562 - val_loss: 4075.3860 - val_mae: 35.5499\n",
      "Epoch 3561/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.7587 - mae: 8.3030 - val_loss: 4049.2539 - val_mae: 35.8580\n",
      "Epoch 3562/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.9096 - mae: 8.2452 - val_loss: 4095.6333 - val_mae: 36.3580\n",
      "Epoch 3563/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.4215 - mae: 8.2382 - val_loss: 4044.8752 - val_mae: 35.5686\n",
      "Epoch 3564/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.4919 - mae: 8.4037 - val_loss: 4058.8816 - val_mae: 35.5748\n",
      "Epoch 3565/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.5174 - mae: 8.5518 - val_loss: 4125.3960 - val_mae: 35.8717\n",
      "Epoch 3566/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.6331 - mae: 8.5246 - val_loss: 4082.4495 - val_mae: 35.3994\n",
      "Epoch 3567/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.0002 - mae: 8.2859 - val_loss: 4051.6543 - val_mae: 35.5290\n",
      "Epoch 3568/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.5504 - mae: 8.5452 - val_loss: 4005.8999 - val_mae: 35.4803\n",
      "Epoch 3569/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.4291 - mae: 8.4054 - val_loss: 3980.4021 - val_mae: 34.9623\n",
      "Epoch 3570/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.4422 - mae: 8.2878 - val_loss: 3981.9309 - val_mae: 34.9906\n",
      "Epoch 3571/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.7440 - mae: 8.1219 - val_loss: 4024.3652 - val_mae: 35.0651\n",
      "Epoch 3572/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.0947 - mae: 8.6913 - val_loss: 4096.7319 - val_mae: 35.7971\n",
      "Epoch 3573/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.6334 - mae: 8.4828 - val_loss: 4008.9700 - val_mae: 35.3963\n",
      "Epoch 3574/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.0242 - mae: 8.8404 - val_loss: 4013.7439 - val_mae: 35.8627\n",
      "Epoch 3575/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.3504 - mae: 8.6724 - val_loss: 3942.6218 - val_mae: 35.5511\n",
      "Epoch 3576/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.9453 - mae: 8.3570 - val_loss: 4043.8203 - val_mae: 35.7622\n",
      "Epoch 3577/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 247.2610 - mae: 8.7388 - val_loss: 4194.0190 - val_mae: 36.1582\n",
      "Epoch 3578/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.8534 - mae: 8.2300 - val_loss: 4163.6113 - val_mae: 36.2702\n",
      "Epoch 3579/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.5294 - mae: 8.2025 - val_loss: 4054.8618 - val_mae: 35.9559\n",
      "Epoch 3580/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.3783 - mae: 8.2652 - val_loss: 4018.9438 - val_mae: 36.4606\n",
      "Epoch 3581/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.1893 - mae: 8.0303 - val_loss: 4126.6040 - val_mae: 36.1062\n",
      "Epoch 3582/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 185.0018 - mae: 8.1798 - val_loss: 4219.2739 - val_mae: 36.1880\n",
      "Epoch 3583/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.8488 - mae: 7.9911 - val_loss: 4184.8926 - val_mae: 36.0379\n",
      "Epoch 3584/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.3927 - mae: 8.2308 - val_loss: 4191.6426 - val_mae: 36.1226\n",
      "Epoch 3585/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 171.5567 - mae: 7.8498 - val_loss: 4166.0981 - val_mae: 36.2003\n",
      "Epoch 3586/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 228.8940 - mae: 8.2704 - val_loss: 4209.4302 - val_mae: 36.3031\n",
      "Epoch 3587/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 209.8198 - mae: 8.3428 - val_loss: 4168.2148 - val_mae: 36.0829\n",
      "Epoch 3588/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.8926 - mae: 8.2713 - val_loss: 4240.4443 - val_mae: 36.4473\n",
      "Epoch 3589/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.3824 - mae: 8.1318 - val_loss: 4170.4756 - val_mae: 36.1892\n",
      "Epoch 3590/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.1390 - mae: 8.0400 - val_loss: 4124.7236 - val_mae: 35.8860\n",
      "Epoch 3591/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.8927 - mae: 8.0662 - val_loss: 4154.4995 - val_mae: 35.6814\n",
      "Epoch 3592/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.4294 - mae: 8.4153 - val_loss: 4205.4844 - val_mae: 36.0551\n",
      "Epoch 3593/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.5668 - mae: 8.4172 - val_loss: 4313.5112 - val_mae: 36.1635\n",
      "Epoch 3594/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.2157 - mae: 8.4463 - val_loss: 4140.8223 - val_mae: 35.8095\n",
      "Epoch 3595/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.0289 - mae: 8.8008 - val_loss: 4064.0747 - val_mae: 35.2773\n",
      "Epoch 3596/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.5260 - mae: 8.5272 - val_loss: 4086.0898 - val_mae: 35.9713\n",
      "Epoch 3597/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.3294 - mae: 8.5398 - val_loss: 4095.5867 - val_mae: 35.7483\n",
      "Epoch 3598/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.9951 - mae: 8.0793 - val_loss: 4168.4692 - val_mae: 36.0872\n",
      "Epoch 3599/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 184.1682 - mae: 8.2389 - val_loss: 4211.1670 - val_mae: 36.4541\n",
      "Epoch 3600/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.4263 - mae: 7.9674 - val_loss: 4196.9170 - val_mae: 36.2834\n",
      "Epoch 3601/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.6523 - mae: 8.4412 - val_loss: 4292.3433 - val_mae: 36.6122\n",
      "Epoch 3602/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.5537 - mae: 8.5076 - val_loss: 4267.1436 - val_mae: 36.3949\n",
      "Epoch 3603/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.9068 - mae: 8.5061 - val_loss: 4199.8145 - val_mae: 35.7914\n",
      "Epoch 3604/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 221.6571 - mae: 8.7762 - val_loss: 4147.8071 - val_mae: 36.7298\n",
      "Epoch 3605/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.2170 - mae: 8.6251 - val_loss: 4146.4902 - val_mae: 35.8780\n",
      "Epoch 3606/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.1644 - mae: 8.6671 - val_loss: 4241.5571 - val_mae: 36.5451\n",
      "Epoch 3607/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 240.1363 - mae: 8.3087 - val_loss: 4196.3857 - val_mae: 36.1123\n",
      "Epoch 3608/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 255.9377 - mae: 8.6831 - val_loss: 4198.6685 - val_mae: 36.1331\n",
      "Epoch 3609/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.9043 - mae: 8.4005 - val_loss: 4216.6719 - val_mae: 36.2907\n",
      "Epoch 3610/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 191.2806 - mae: 8.2528 - val_loss: 4274.0947 - val_mae: 36.3452\n",
      "Epoch 3611/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.5993 - mae: 8.4639 - val_loss: 4176.1987 - val_mae: 36.0329\n",
      "Epoch 3612/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.1651 - mae: 8.6561 - val_loss: 4297.7534 - val_mae: 36.0660\n",
      "Epoch 3613/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 275.5625 - mae: 8.9244 - val_loss: 4226.4272 - val_mae: 36.4486\n",
      "Epoch 3614/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.0548 - mae: 8.7916 - val_loss: 4333.7163 - val_mae: 36.5544\n",
      "Epoch 3615/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.8872 - mae: 8.4524 - val_loss: 4215.2578 - val_mae: 36.2393\n",
      "Epoch 3616/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.7702 - mae: 8.3208 - val_loss: 4121.1113 - val_mae: 35.7856\n",
      "Epoch 3617/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.0791 - mae: 8.5812 - val_loss: 4279.3516 - val_mae: 36.6748\n",
      "Epoch 3618/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.3790 - mae: 8.8259 - val_loss: 4078.5364 - val_mae: 36.1391\n",
      "Epoch 3619/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 249.3382 - mae: 8.5219 - val_loss: 4085.2820 - val_mae: 35.2657\n",
      "Epoch 3620/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.4399 - mae: 8.3794 - val_loss: 4102.6685 - val_mae: 35.4485\n",
      "Epoch 3621/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.4374 - mae: 8.5255 - val_loss: 4148.7705 - val_mae: 35.8992\n",
      "Epoch 3622/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.6492 - mae: 8.3755 - val_loss: 4195.7363 - val_mae: 36.1187\n",
      "Epoch 3623/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.0009 - mae: 8.6136 - val_loss: 4257.1377 - val_mae: 36.8049\n",
      "Epoch 3624/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.0161 - mae: 8.6572 - val_loss: 4098.3154 - val_mae: 35.5306\n",
      "Epoch 3625/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 183.8260 - mae: 8.1990 - val_loss: 4203.9199 - val_mae: 36.2393\n",
      "Epoch 3626/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.9338 - mae: 8.0561 - val_loss: 4254.8213 - val_mae: 36.6793\n",
      "Epoch 3627/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.8014 - mae: 8.0929 - val_loss: 4167.8140 - val_mae: 36.1506\n",
      "Epoch 3628/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.2531 - mae: 8.1067 - val_loss: 4226.6450 - val_mae: 36.2830\n",
      "Epoch 3629/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 188.2677 - mae: 7.9693 - val_loss: 4135.3472 - val_mae: 35.9225\n",
      "Epoch 3630/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.5468 - mae: 8.2032 - val_loss: 4218.8042 - val_mae: 36.3538\n",
      "Epoch 3631/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.7297 - mae: 8.2046 - val_loss: 4198.2085 - val_mae: 35.8602\n",
      "Epoch 3632/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.0399 - mae: 8.3284 - val_loss: 4247.4351 - val_mae: 35.8099\n",
      "Epoch 3633/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 177.9486 - mae: 8.1201 - val_loss: 4190.7871 - val_mae: 35.9251\n",
      "Epoch 3634/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.1621 - mae: 8.3873 - val_loss: 4215.0645 - val_mae: 36.2682\n",
      "Epoch 3635/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.8912 - mae: 8.0882 - val_loss: 4117.9751 - val_mae: 35.8825\n",
      "Epoch 3636/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 175.5396 - mae: 7.9748 - val_loss: 4063.4170 - val_mae: 35.6509\n",
      "Epoch 3637/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.5918 - mae: 8.2442 - val_loss: 4053.3918 - val_mae: 35.8876\n",
      "Epoch 3638/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 243.8432 - mae: 8.7887 - val_loss: 4008.9673 - val_mae: 35.5348\n",
      "Epoch 3639/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.0101 - mae: 8.3720 - val_loss: 4028.0239 - val_mae: 35.4897\n",
      "Epoch 3640/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.2161 - mae: 8.3448 - val_loss: 4060.0503 - val_mae: 35.4150\n",
      "Epoch 3641/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.6250 - mae: 8.2914 - val_loss: 4134.5684 - val_mae: 35.6439\n",
      "Epoch 3642/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.8230 - mae: 8.2040 - val_loss: 4049.1245 - val_mae: 35.7509\n",
      "Epoch 3643/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.0738 - mae: 8.3183 - val_loss: 4149.0239 - val_mae: 36.0917\n",
      "Epoch 3644/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.4402 - mae: 8.2315 - val_loss: 4127.7993 - val_mae: 36.2698\n",
      "Epoch 3645/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.3931 - mae: 8.1963 - val_loss: 4193.8984 - val_mae: 36.7353\n",
      "Epoch 3646/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.2472 - mae: 8.0969 - val_loss: 4182.2373 - val_mae: 36.3844\n",
      "Epoch 3647/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.9836 - mae: 8.2420 - val_loss: 4230.3301 - val_mae: 36.6426\n",
      "Epoch 3648/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.8394 - mae: 8.3111 - val_loss: 4236.3564 - val_mae: 36.6037\n",
      "Epoch 3649/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.0569 - mae: 8.3703 - val_loss: 4051.4092 - val_mae: 35.8642\n",
      "Epoch 3650/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.3071 - mae: 8.2813 - val_loss: 4173.1567 - val_mae: 36.6770\n",
      "Epoch 3651/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.5728 - mae: 8.0388 - val_loss: 4142.8066 - val_mae: 36.1974\n",
      "Epoch 3652/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.0802 - mae: 7.8989 - val_loss: 4157.2144 - val_mae: 35.9732\n",
      "Epoch 3653/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.9823 - mae: 8.1634 - val_loss: 4142.9375 - val_mae: 36.2114\n",
      "Epoch 3654/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 188.9996 - mae: 8.0383 - val_loss: 4191.8398 - val_mae: 36.2906\n",
      "Epoch 3655/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.1129 - mae: 8.2119 - val_loss: 4124.8931 - val_mae: 35.6727\n",
      "Epoch 3656/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.4480 - mae: 8.1103 - val_loss: 4052.8362 - val_mae: 35.6320\n",
      "Epoch 3657/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.2346 - mae: 8.1256 - val_loss: 4117.0293 - val_mae: 35.6499\n",
      "Epoch 3658/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.4137 - mae: 8.1649 - val_loss: 4078.0098 - val_mae: 35.9153\n",
      "Epoch 3659/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.5227 - mae: 7.9719 - val_loss: 4203.2671 - val_mae: 35.9817\n",
      "Epoch 3660/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.3708 - mae: 8.4318 - val_loss: 4156.7627 - val_mae: 35.7712\n",
      "Epoch 3661/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.1295 - mae: 8.2741 - val_loss: 4129.4385 - val_mae: 36.2058\n",
      "Epoch 3662/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.7116 - mae: 8.0118 - val_loss: 4209.2441 - val_mae: 36.1912\n",
      "Epoch 3663/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.6208 - mae: 7.8143 - val_loss: 4187.5977 - val_mae: 36.2998\n",
      "Epoch 3664/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.2621 - mae: 8.3938 - val_loss: 4088.8723 - val_mae: 35.2109\n",
      "Epoch 3665/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.6084 - mae: 8.0906 - val_loss: 4237.5308 - val_mae: 36.3980\n",
      "Epoch 3666/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.4174 - mae: 8.1247 - val_loss: 4159.5771 - val_mae: 35.7861\n",
      "Epoch 3667/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.8266 - mae: 8.1070 - val_loss: 4075.6431 - val_mae: 35.4119\n",
      "Epoch 3668/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.6243 - mae: 8.0764 - val_loss: 4290.5513 - val_mae: 36.2888\n",
      "Epoch 3669/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.1507 - mae: 8.0423 - val_loss: 4302.8193 - val_mae: 36.1170\n",
      "Epoch 3670/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.6658 - mae: 8.1733 - val_loss: 4380.6172 - val_mae: 36.5721\n",
      "Epoch 3671/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.7730 - mae: 8.3617 - val_loss: 4152.7300 - val_mae: 35.8073\n",
      "Epoch 3672/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.0745 - mae: 8.4306 - val_loss: 4179.7280 - val_mae: 35.6541\n",
      "Epoch 3673/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.5349 - mae: 8.2972 - val_loss: 4111.7036 - val_mae: 35.9973\n",
      "Epoch 3674/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.0910 - mae: 8.3542 - val_loss: 4128.5278 - val_mae: 35.9974\n",
      "Epoch 3675/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.2156 - mae: 8.1611 - val_loss: 4093.8733 - val_mae: 35.8131\n",
      "Epoch 3676/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.5806 - mae: 7.7492 - val_loss: 4094.2471 - val_mae: 35.5110\n",
      "Epoch 3677/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.9694 - mae: 7.7733 - val_loss: 4165.3857 - val_mae: 35.7016\n",
      "Epoch 3678/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.5732 - mae: 8.0890 - val_loss: 4192.1641 - val_mae: 36.0497\n",
      "Epoch 3679/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.2731 - mae: 8.1872 - val_loss: 4211.4390 - val_mae: 35.8437\n",
      "Epoch 3680/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 178.0986 - mae: 7.8012 - val_loss: 4139.0928 - val_mae: 35.9998\n",
      "Epoch 3681/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.8340 - mae: 8.5571 - val_loss: 4224.1260 - val_mae: 36.0816\n",
      "Epoch 3682/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.2844 - mae: 8.4576 - val_loss: 4125.8608 - val_mae: 35.5142\n",
      "Epoch 3683/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.7824 - mae: 8.5248 - val_loss: 4217.2466 - val_mae: 36.0468\n",
      "Epoch 3684/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.4603 - mae: 8.4403 - val_loss: 4221.8125 - val_mae: 35.8099\n",
      "Epoch 3685/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.3075 - mae: 8.3674 - val_loss: 4245.5024 - val_mae: 36.3125\n",
      "Epoch 3686/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.8652 - mae: 8.0802 - val_loss: 4188.3765 - val_mae: 36.1176\n",
      "Epoch 3687/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.4111 - mae: 8.1547 - val_loss: 4307.0718 - val_mae: 36.1935\n",
      "Epoch 3688/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.5429 - mae: 8.1878 - val_loss: 4255.2119 - val_mae: 35.7292\n",
      "Epoch 3689/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.3016 - mae: 7.9846 - val_loss: 4130.8120 - val_mae: 35.6067\n",
      "Epoch 3690/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.9839 - mae: 8.1723 - val_loss: 4100.2515 - val_mae: 36.1816\n",
      "Epoch 3691/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.3463 - mae: 8.2130 - val_loss: 4145.4990 - val_mae: 36.0939\n",
      "Epoch 3692/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.9561 - mae: 8.2249 - val_loss: 4028.9324 - val_mae: 35.2170\n",
      "Epoch 3693/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.6620 - mae: 8.1847 - val_loss: 4117.0386 - val_mae: 35.8359\n",
      "Epoch 3694/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.4848 - mae: 7.9393 - val_loss: 4185.1055 - val_mae: 36.2697\n",
      "Epoch 3695/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.6478 - mae: 8.2937 - val_loss: 4307.8521 - val_mae: 36.8100\n",
      "Epoch 3696/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.5290 - mae: 8.1751 - val_loss: 4268.3423 - val_mae: 36.3979\n",
      "Epoch 3697/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2618 - mae: 8.0237 - val_loss: 4255.9473 - val_mae: 36.2192\n",
      "Epoch 3698/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.5156 - mae: 8.0810 - val_loss: 4242.2681 - val_mae: 36.3935\n",
      "Epoch 3699/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.3431 - mae: 8.5636 - val_loss: 4158.6514 - val_mae: 35.8750\n",
      "Epoch 3700/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7337 - mae: 8.3094 - val_loss: 4046.4133 - val_mae: 35.5583\n",
      "Epoch 3701/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.8624 - mae: 8.0279 - val_loss: 4071.0723 - val_mae: 35.2643\n",
      "Epoch 3702/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.1458 - mae: 8.0192 - val_loss: 4208.1323 - val_mae: 35.9274\n",
      "Epoch 3703/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.1134 - mae: 8.0292 - val_loss: 4157.4922 - val_mae: 35.9422\n",
      "Epoch 3704/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.5798 - mae: 8.0035 - val_loss: 4236.3179 - val_mae: 35.9332\n",
      "Epoch 3705/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.6477 - mae: 8.1934 - val_loss: 4205.0884 - val_mae: 35.7545\n",
      "Epoch 3706/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.1461 - mae: 8.1499 - val_loss: 4219.6206 - val_mae: 36.1288\n",
      "Epoch 3707/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.7603 - mae: 8.1068 - val_loss: 4250.5308 - val_mae: 35.8291\n",
      "Epoch 3708/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.4913 - mae: 8.1686 - val_loss: 4146.0684 - val_mae: 35.6204\n",
      "Epoch 3709/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.4298 - mae: 7.8851 - val_loss: 4179.1514 - val_mae: 35.6769\n",
      "Epoch 3710/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.8128 - mae: 8.1133 - val_loss: 4072.9785 - val_mae: 35.8622\n",
      "Epoch 3711/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.8873 - mae: 8.1092 - val_loss: 4124.1768 - val_mae: 35.7417\n",
      "Epoch 3712/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.5804 - mae: 8.1590 - val_loss: 3934.4082 - val_mae: 34.5171\n",
      "Epoch 3713/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 286.0403 - mae: 8.5916 - val_loss: 4104.5664 - val_mae: 35.6329\n",
      "Epoch 3714/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.2507 - mae: 8.8725 - val_loss: 4080.8645 - val_mae: 36.0647\n",
      "Epoch 3715/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.2709 - mae: 8.6928 - val_loss: 4213.7544 - val_mae: 36.8812\n",
      "Epoch 3716/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.5516 - mae: 8.5982 - val_loss: 4102.5708 - val_mae: 36.2237\n",
      "Epoch 3717/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.0791 - mae: 8.3446 - val_loss: 4163.0508 - val_mae: 36.4603\n",
      "Epoch 3718/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.4587 - mae: 8.2528 - val_loss: 4162.5566 - val_mae: 36.3469\n",
      "Epoch 3719/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.5898 - mae: 8.1270 - val_loss: 4060.8179 - val_mae: 35.2499\n",
      "Epoch 3720/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.9836 - mae: 8.1059 - val_loss: 4142.0488 - val_mae: 35.5391\n",
      "Epoch 3721/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.9301 - mae: 8.5934 - val_loss: 4231.0273 - val_mae: 35.8026\n",
      "Epoch 3722/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.7956 - mae: 8.2578 - val_loss: 4135.4482 - val_mae: 35.8729\n",
      "Epoch 3723/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.6577 - mae: 8.1263 - val_loss: 4114.2446 - val_mae: 35.8167\n",
      "Epoch 3724/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.2443 - mae: 8.2623 - val_loss: 4158.0078 - val_mae: 35.5646\n",
      "Epoch 3725/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.4271 - mae: 8.4254 - val_loss: 4313.6714 - val_mae: 36.8502\n",
      "Epoch 3726/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.8635 - mae: 8.4578 - val_loss: 4088.0383 - val_mae: 35.7732\n",
      "Epoch 3727/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 299.6922 - mae: 8.7475 - val_loss: 4103.3066 - val_mae: 35.5386\n",
      "Epoch 3728/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.6101 - mae: 8.6974 - val_loss: 4129.2646 - val_mae: 35.6162\n",
      "Epoch 3729/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.2426 - mae: 8.3102 - val_loss: 4057.2141 - val_mae: 35.8452\n",
      "Epoch 3730/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 209.4256 - mae: 8.4888 - val_loss: 4090.5991 - val_mae: 35.4810\n",
      "Epoch 3731/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.3598 - mae: 8.0676 - val_loss: 3964.8962 - val_mae: 34.9742\n",
      "Epoch 3732/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 233.8738 - mae: 8.5993 - val_loss: 4109.5342 - val_mae: 35.1777\n",
      "Epoch 3733/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.3933 - mae: 8.4322 - val_loss: 3993.7527 - val_mae: 35.3849\n",
      "Epoch 3734/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7554 - mae: 8.5130 - val_loss: 4024.7927 - val_mae: 34.9967\n",
      "Epoch 3735/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.1514 - mae: 8.0238 - val_loss: 4011.3098 - val_mae: 35.1713\n",
      "Epoch 3736/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.3593 - mae: 8.4620 - val_loss: 4004.6152 - val_mae: 35.6903\n",
      "Epoch 3737/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.5822 - mae: 8.4696 - val_loss: 3987.2146 - val_mae: 35.2807\n",
      "Epoch 3738/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.0336 - mae: 8.5187 - val_loss: 4009.0857 - val_mae: 35.4185\n",
      "Epoch 3739/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.6234 - mae: 8.2031 - val_loss: 4045.9446 - val_mae: 35.3220\n",
      "Epoch 3740/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.1630 - mae: 8.1913 - val_loss: 4000.5095 - val_mae: 35.5430\n",
      "Epoch 3741/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 260.0024 - mae: 8.3494 - val_loss: 4056.6531 - val_mae: 35.2787\n",
      "Epoch 3742/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.1587 - mae: 8.5663 - val_loss: 4062.4683 - val_mae: 34.8784\n",
      "Epoch 3743/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 257.4238 - mae: 8.9258 - val_loss: 4037.9231 - val_mae: 35.3726\n",
      "Epoch 3744/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.9874 - mae: 8.6379 - val_loss: 3994.4385 - val_mae: 34.7995\n",
      "Epoch 3745/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.6817 - mae: 9.1301 - val_loss: 3994.5518 - val_mae: 34.5569\n",
      "Epoch 3746/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.7146 - mae: 8.5184 - val_loss: 4037.7620 - val_mae: 35.5806\n",
      "Epoch 3747/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.3276 - mae: 8.6506 - val_loss: 4051.9541 - val_mae: 35.1094\n",
      "Epoch 3748/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.5166 - mae: 8.2595 - val_loss: 3997.8618 - val_mae: 35.0138\n",
      "Epoch 3749/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 278.4018 - mae: 8.9083 - val_loss: 3961.3398 - val_mae: 35.3336\n",
      "Epoch 3750/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.4322 - mae: 8.4972 - val_loss: 3998.9885 - val_mae: 35.3990\n",
      "Epoch 3751/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 274.1337 - mae: 8.7117 - val_loss: 4001.5164 - val_mae: 35.1041\n",
      "Epoch 3752/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.5615 - mae: 8.3615 - val_loss: 3977.0767 - val_mae: 35.2216\n",
      "Epoch 3753/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.1555 - mae: 8.6580 - val_loss: 4022.5811 - val_mae: 35.2072\n",
      "Epoch 3754/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.5748 - mae: 8.3150 - val_loss: 4068.0957 - val_mae: 35.0837\n",
      "Epoch 3755/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.5720 - mae: 8.5301 - val_loss: 4056.9255 - val_mae: 35.0427\n",
      "Epoch 3756/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.1123 - mae: 8.8199 - val_loss: 4095.6970 - val_mae: 35.0522\n",
      "Epoch 3757/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.2546 - mae: 8.5363 - val_loss: 4039.6470 - val_mae: 35.0821\n",
      "Epoch 3758/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7640 - mae: 8.5797 - val_loss: 4098.7129 - val_mae: 35.2661\n",
      "Epoch 3759/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.2928 - mae: 8.4886 - val_loss: 3985.3943 - val_mae: 34.9553\n",
      "Epoch 3760/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.5185 - mae: 8.4036 - val_loss: 3910.3530 - val_mae: 35.3189\n",
      "Epoch 3761/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.5236 - mae: 8.5527 - val_loss: 3992.8396 - val_mae: 35.1885\n",
      "Epoch 3762/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.9653 - mae: 8.2292 - val_loss: 4071.7905 - val_mae: 35.5324\n",
      "Epoch 3763/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.1747 - mae: 8.3012 - val_loss: 4045.6560 - val_mae: 35.5240\n",
      "Epoch 3764/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.8047 - mae: 8.6517 - val_loss: 4134.0859 - val_mae: 35.7488\n",
      "Epoch 3765/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.9918 - mae: 8.2693 - val_loss: 4005.2185 - val_mae: 34.8978\n",
      "Epoch 3766/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.4551 - mae: 8.5599 - val_loss: 4075.2009 - val_mae: 35.2986\n",
      "Epoch 3767/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.8782 - mae: 8.3325 - val_loss: 4206.0210 - val_mae: 35.5669\n",
      "Epoch 3768/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 295.1833 - mae: 8.9036 - val_loss: 4160.2134 - val_mae: 35.7715\n",
      "Epoch 3769/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.0345 - mae: 8.5583 - val_loss: 4163.5879 - val_mae: 35.4727\n",
      "Epoch 3770/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 267.1130 - mae: 8.5478 - val_loss: 3861.5505 - val_mae: 34.6353\n",
      "Epoch 3771/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.2753 - mae: 8.6798 - val_loss: 4183.3433 - val_mae: 35.0537\n",
      "Epoch 3772/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.6747 - mae: 8.3087 - val_loss: 4136.5996 - val_mae: 35.6086\n",
      "Epoch 3773/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.3268 - mae: 8.1751 - val_loss: 4187.7139 - val_mae: 35.6735\n",
      "Epoch 3774/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 250.2172 - mae: 8.5587 - val_loss: 4120.1860 - val_mae: 35.8351\n",
      "Epoch 3775/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.8880 - mae: 8.4812 - val_loss: 4166.5171 - val_mae: 36.2294\n",
      "Epoch 3776/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.0500 - mae: 8.4832 - val_loss: 4193.0366 - val_mae: 35.9983\n",
      "Epoch 3777/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 227.2077 - mae: 8.5577 - val_loss: 4298.2983 - val_mae: 35.9636\n",
      "Epoch 3778/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.6559 - mae: 8.2769 - val_loss: 4163.7964 - val_mae: 35.7974\n",
      "Epoch 3779/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.3983 - mae: 8.2413 - val_loss: 4100.6064 - val_mae: 35.0672\n",
      "Epoch 3780/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.4567 - mae: 8.4503 - val_loss: 4226.3857 - val_mae: 35.8321\n",
      "Epoch 3781/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.2041 - mae: 8.4789 - val_loss: 4161.1455 - val_mae: 35.8633\n",
      "Epoch 3782/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 181.7517 - mae: 7.9614 - val_loss: 4279.1626 - val_mae: 36.2435\n",
      "Epoch 3783/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.5626 - mae: 8.2023 - val_loss: 4166.9678 - val_mae: 35.7422\n",
      "Epoch 3784/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.9682 - mae: 8.4294 - val_loss: 4128.4126 - val_mae: 35.4967\n",
      "Epoch 3785/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.1479 - mae: 8.1218 - val_loss: 4160.4331 - val_mae: 35.6674\n",
      "Epoch 3786/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.3115 - mae: 8.0526 - val_loss: 4075.0171 - val_mae: 35.2478\n",
      "Epoch 3787/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.4480 - mae: 8.2869 - val_loss: 4098.9771 - val_mae: 35.0015\n",
      "Epoch 3788/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.7223 - mae: 7.9430 - val_loss: 4142.2539 - val_mae: 35.5407\n",
      "Epoch 3789/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.9835 - mae: 8.3251 - val_loss: 4077.4839 - val_mae: 35.4946\n",
      "Epoch 3790/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.3723 - mae: 8.8999 - val_loss: 4049.1455 - val_mae: 35.3627\n",
      "Epoch 3791/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.2138 - mae: 8.1866 - val_loss: 4199.5640 - val_mae: 36.1730\n",
      "Epoch 3792/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 253.7748 - mae: 8.8635 - val_loss: 4103.8374 - val_mae: 35.8533\n",
      "Epoch 3793/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 177.1609 - mae: 8.0661 - val_loss: 4103.9976 - val_mae: 35.9250\n",
      "Epoch 3794/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.5687 - mae: 8.1097 - val_loss: 4193.8496 - val_mae: 35.7097\n",
      "Epoch 3795/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.2790 - mae: 8.0717 - val_loss: 4275.1216 - val_mae: 36.2679\n",
      "Epoch 3796/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.5319 - mae: 8.0463 - val_loss: 4226.5767 - val_mae: 35.9009\n",
      "Epoch 3797/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.0588 - mae: 8.3852 - val_loss: 4261.1631 - val_mae: 35.7476\n",
      "Epoch 3798/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.1244 - mae: 8.1672 - val_loss: 4262.2344 - val_mae: 36.1539\n",
      "Epoch 3799/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.3610 - mae: 8.1462 - val_loss: 4150.8213 - val_mae: 35.8439\n",
      "Epoch 3800/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.9458 - mae: 8.3928 - val_loss: 4209.9805 - val_mae: 36.3032\n",
      "Epoch 3801/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.1016 - mae: 8.3885 - val_loss: 4150.9380 - val_mae: 35.9350\n",
      "Epoch 3802/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.2191 - mae: 8.2757 - val_loss: 4253.7510 - val_mae: 35.9871\n",
      "Epoch 3803/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.0513 - mae: 8.3602 - val_loss: 4168.4204 - val_mae: 35.8696\n",
      "Epoch 3804/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.7095 - mae: 8.2202 - val_loss: 4067.6597 - val_mae: 35.3608\n",
      "Epoch 3805/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.9165 - mae: 8.5796 - val_loss: 4011.7036 - val_mae: 35.1523\n",
      "Epoch 3806/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.3233 - mae: 8.3417 - val_loss: 4097.9116 - val_mae: 35.2115\n",
      "Epoch 3807/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.4982 - mae: 8.5234 - val_loss: 4120.3857 - val_mae: 35.2221\n",
      "Epoch 3808/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.3778 - mae: 8.5734 - val_loss: 4095.2241 - val_mae: 35.9581\n",
      "Epoch 3809/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.7531 - mae: 8.4021 - val_loss: 4046.8782 - val_mae: 35.4287\n",
      "Epoch 3810/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 291.4451 - mae: 10.0180 - val_loss: 4134.8125 - val_mae: 36.8653\n",
      "Epoch 3811/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.1258 - mae: 10.3343 - val_loss: 4089.7000 - val_mae: 35.8088\n",
      "Epoch 3812/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.8392 - mae: 9.3008 - val_loss: 4057.7109 - val_mae: 35.8367\n",
      "Epoch 3813/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.9424 - mae: 8.6969 - val_loss: 4192.1030 - val_mae: 36.3037\n",
      "Epoch 3814/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.9219 - mae: 8.7281 - val_loss: 4155.2549 - val_mae: 35.6223\n",
      "Epoch 3815/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 319.1380 - mae: 9.4133 - val_loss: 4076.3252 - val_mae: 35.0551\n",
      "Epoch 3816/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.6965 - mae: 8.9811 - val_loss: 3993.4106 - val_mae: 34.9694\n",
      "Epoch 3817/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 278.6761 - mae: 8.9866 - val_loss: 4123.3623 - val_mae: 36.9032\n",
      "Epoch 3818/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.9903 - mae: 8.6710 - val_loss: 4150.6338 - val_mae: 36.9593\n",
      "Epoch 3819/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 270.5280 - mae: 9.2469 - val_loss: 4206.5015 - val_mae: 36.7064\n",
      "Epoch 3820/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.8800 - mae: 8.6070 - val_loss: 4287.3237 - val_mae: 36.7077\n",
      "Epoch 3821/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.3636 - mae: 8.4654 - val_loss: 4184.4600 - val_mae: 35.9995\n",
      "Epoch 3822/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.3294 - mae: 8.4657 - val_loss: 4145.1660 - val_mae: 36.1154\n",
      "Epoch 3823/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.8242 - mae: 8.6813 - val_loss: 4186.5435 - val_mae: 35.6158\n",
      "Epoch 3824/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.8842 - mae: 8.1187 - val_loss: 4131.2720 - val_mae: 35.6590\n",
      "Epoch 3825/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.4828 - mae: 8.2072 - val_loss: 4109.2031 - val_mae: 35.2238\n",
      "Epoch 3826/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 185.5230 - mae: 8.1670 - val_loss: 4063.7197 - val_mae: 35.0573\n",
      "Epoch 3827/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 201.1679 - mae: 8.1518 - val_loss: 4138.8926 - val_mae: 35.8944\n",
      "Epoch 3828/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.1911 - mae: 8.5759 - val_loss: 4082.6877 - val_mae: 35.6724\n",
      "Epoch 3829/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.7419 - mae: 8.4050 - val_loss: 4166.9619 - val_mae: 34.9816\n",
      "Epoch 3830/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.4905 - mae: 8.1962 - val_loss: 4164.4971 - val_mae: 35.6614\n",
      "Epoch 3831/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.1219 - mae: 8.0951 - val_loss: 4167.3623 - val_mae: 36.0499\n",
      "Epoch 3832/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.3114 - mae: 8.1082 - val_loss: 4231.4058 - val_mae: 35.7522\n",
      "Epoch 3833/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 251.4845 - mae: 8.5472 - val_loss: 4255.6821 - val_mae: 36.3621\n",
      "Epoch 3834/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 159.9321 - mae: 7.8596 - val_loss: 4265.5601 - val_mae: 36.7662\n",
      "Epoch 3835/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.9393 - mae: 8.0503 - val_loss: 4289.4229 - val_mae: 37.0205\n",
      "Epoch 3836/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 272.4192 - mae: 8.5485 - val_loss: 4224.5088 - val_mae: 38.9796\n",
      "Epoch 3837/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.2242 - mae: 9.6070 - val_loss: 4267.1333 - val_mae: 36.8342\n",
      "Epoch 3838/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.3152 - mae: 9.0484 - val_loss: 4251.6895 - val_mae: 36.5011\n",
      "Epoch 3839/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.8946 - mae: 9.0015 - val_loss: 4270.9204 - val_mae: 36.4672\n",
      "Epoch 3840/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.6441 - mae: 8.3803 - val_loss: 4281.7969 - val_mae: 36.5568\n",
      "Epoch 3841/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.2018 - mae: 8.4166 - val_loss: 4105.7383 - val_mae: 35.4940\n",
      "Epoch 3842/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.4393 - mae: 8.3513 - val_loss: 4177.2090 - val_mae: 35.8000\n",
      "Epoch 3843/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.5497 - mae: 8.3409 - val_loss: 4195.3457 - val_mae: 35.6334\n",
      "Epoch 3844/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.3816 - mae: 8.0262 - val_loss: 4204.0498 - val_mae: 36.0421\n",
      "Epoch 3845/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.0041 - mae: 8.5314 - val_loss: 4188.1333 - val_mae: 36.0462\n",
      "Epoch 3846/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.5427 - mae: 8.3859 - val_loss: 4215.9966 - val_mae: 35.9641\n",
      "Epoch 3847/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.6480 - mae: 8.2016 - val_loss: 4153.8809 - val_mae: 35.5624\n",
      "Epoch 3848/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.0231 - mae: 8.4033 - val_loss: 4096.4390 - val_mae: 35.3426\n",
      "Epoch 3849/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.3109 - mae: 7.7971 - val_loss: 4084.6052 - val_mae: 35.0877\n",
      "Epoch 3850/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.1096 - mae: 8.2088 - val_loss: 4130.6562 - val_mae: 34.9709\n",
      "Epoch 3851/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.8340 - mae: 7.9619 - val_loss: 4100.1021 - val_mae: 35.1609\n",
      "Epoch 3852/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.4507 - mae: 8.2000 - val_loss: 4131.5967 - val_mae: 35.2045\n",
      "Epoch 3853/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.2334 - mae: 7.9166 - val_loss: 4080.9739 - val_mae: 35.1547\n",
      "Epoch 3854/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.6476 - mae: 8.1198 - val_loss: 4100.7119 - val_mae: 35.6986\n",
      "Epoch 3855/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.1036 - mae: 8.2908 - val_loss: 4104.0918 - val_mae: 35.2872\n",
      "Epoch 3856/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.7907 - mae: 8.0859 - val_loss: 4018.7981 - val_mae: 35.2634\n",
      "Epoch 3857/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.1643 - mae: 8.4324 - val_loss: 3990.5137 - val_mae: 34.9614\n",
      "Epoch 3858/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.3506 - mae: 8.0546 - val_loss: 4065.1692 - val_mae: 34.9870\n",
      "Epoch 3859/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.6940 - mae: 7.9391 - val_loss: 4073.3813 - val_mae: 34.8559\n",
      "Epoch 3860/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.5453 - mae: 8.0020 - val_loss: 4088.6912 - val_mae: 35.2004\n",
      "Epoch 3861/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.3904 - mae: 7.8663 - val_loss: 4046.6848 - val_mae: 34.9480\n",
      "Epoch 3862/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.4801 - mae: 7.7888 - val_loss: 4141.5596 - val_mae: 35.2332\n",
      "Epoch 3863/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.2772 - mae: 7.9869 - val_loss: 4129.2256 - val_mae: 35.1918\n",
      "Epoch 3864/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 173.1072 - mae: 7.8016 - val_loss: 4140.1636 - val_mae: 35.3681\n",
      "Epoch 3865/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.2907 - mae: 8.1172 - val_loss: 4126.3008 - val_mae: 35.2127\n",
      "Epoch 3866/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.6810 - mae: 7.7798 - val_loss: 4140.3779 - val_mae: 35.1331\n",
      "Epoch 3867/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.9067 - mae: 8.2313 - val_loss: 4063.6118 - val_mae: 35.5219\n",
      "Epoch 3868/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.4671 - mae: 8.0573 - val_loss: 4072.5320 - val_mae: 35.3225\n",
      "Epoch 3869/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.0518 - mae: 8.2857 - val_loss: 4125.7788 - val_mae: 35.4756\n",
      "Epoch 3870/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 311.2964 - mae: 8.6525 - val_loss: 4124.0591 - val_mae: 35.8571\n",
      "Epoch 3871/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 336.5463 - mae: 8.9912 - val_loss: 4051.4912 - val_mae: 35.6569\n",
      "Epoch 3872/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.2391 - mae: 7.9937 - val_loss: 4127.0859 - val_mae: 35.2905\n",
      "Epoch 3873/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.9395 - mae: 8.2734 - val_loss: 4100.1797 - val_mae: 35.8427\n",
      "Epoch 3874/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.5572 - mae: 8.2320 - val_loss: 4169.2314 - val_mae: 35.3415\n",
      "Epoch 3875/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.3352 - mae: 8.2208 - val_loss: 4318.0610 - val_mae: 36.1462\n",
      "Epoch 3876/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.4087 - mae: 8.0985 - val_loss: 4356.6763 - val_mae: 36.1342\n",
      "Epoch 3877/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.3004 - mae: 8.2563 - val_loss: 4201.5103 - val_mae: 35.6958\n",
      "Epoch 3878/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.8792 - mae: 8.3297 - val_loss: 4230.8530 - val_mae: 35.9201\n",
      "Epoch 3879/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.7911 - mae: 7.8816 - val_loss: 4134.7046 - val_mae: 35.3310\n",
      "Epoch 3880/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.1840 - mae: 8.1909 - val_loss: 4170.0918 - val_mae: 36.1547\n",
      "Epoch 3881/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.1205 - mae: 8.6195 - val_loss: 4175.3101 - val_mae: 35.8996\n",
      "Epoch 3882/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 283.5770 - mae: 8.8281 - val_loss: 4283.8149 - val_mae: 36.0506\n",
      "Epoch 3883/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 273.1085 - mae: 8.7008 - val_loss: 4268.8340 - val_mae: 36.1093\n",
      "Epoch 3884/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.3449 - mae: 8.3274 - val_loss: 3981.0186 - val_mae: 35.4378\n",
      "Epoch 3885/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 188.0886 - mae: 8.0629 - val_loss: 4211.6396 - val_mae: 35.7064\n",
      "Epoch 3886/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.5282 - mae: 8.2344 - val_loss: 4133.6587 - val_mae: 35.3030\n",
      "Epoch 3887/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 260.6107 - mae: 8.7208 - val_loss: 4037.0959 - val_mae: 35.4454\n",
      "Epoch 3888/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.9777 - mae: 8.2789 - val_loss: 4068.5684 - val_mae: 35.4347\n",
      "Epoch 3889/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.4769 - mae: 8.6707 - val_loss: 4117.5825 - val_mae: 36.0274\n",
      "Epoch 3890/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.9883 - mae: 8.1819 - val_loss: 4130.6846 - val_mae: 35.3402\n",
      "Epoch 3891/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.8914 - mae: 8.3014 - val_loss: 4097.0488 - val_mae: 35.6879\n",
      "Epoch 3892/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 230.5553 - mae: 8.4290 - val_loss: 4084.0320 - val_mae: 35.4022\n",
      "Epoch 3893/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 275.9044 - mae: 8.7918 - val_loss: 4057.0872 - val_mae: 35.7936\n",
      "Epoch 3894/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.6670 - mae: 8.3758 - val_loss: 4114.3701 - val_mae: 35.9783\n",
      "Epoch 3895/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 188.9565 - mae: 8.0248 - val_loss: 3971.5940 - val_mae: 34.8482\n",
      "Epoch 3896/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.0007 - mae: 8.3767 - val_loss: 4040.9316 - val_mae: 35.2949\n",
      "Epoch 3897/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.9478 - mae: 8.6452 - val_loss: 4041.3296 - val_mae: 35.5396\n",
      "Epoch 3898/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.2866 - mae: 8.4267 - val_loss: 4101.9297 - val_mae: 35.3626\n",
      "Epoch 3899/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 272.6033 - mae: 8.6372 - val_loss: 4025.4033 - val_mae: 35.2447\n",
      "Epoch 3900/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.8373 - mae: 7.9269 - val_loss: 4084.9207 - val_mae: 35.0804\n",
      "Epoch 3901/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.2769 - mae: 8.2928 - val_loss: 4258.6069 - val_mae: 35.9413\n",
      "Epoch 3902/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.4238 - mae: 8.2428 - val_loss: 4168.1562 - val_mae: 35.8008\n",
      "Epoch 3903/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.5795 - mae: 8.0835 - val_loss: 4171.6074 - val_mae: 35.7553\n",
      "Epoch 3904/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.7978 - mae: 8.3124 - val_loss: 4155.5576 - val_mae: 35.5013\n",
      "Epoch 3905/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.7010 - mae: 8.3569 - val_loss: 4105.1001 - val_mae: 35.5275\n",
      "Epoch 3906/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.1690 - mae: 8.0957 - val_loss: 3972.2522 - val_mae: 35.0604\n",
      "Epoch 3907/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.2461 - mae: 8.1561 - val_loss: 4041.2556 - val_mae: 35.0375\n",
      "Epoch 3908/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.0331 - mae: 8.4153 - val_loss: 4035.3677 - val_mae: 35.5358\n",
      "Epoch 3909/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.4067 - mae: 8.4003 - val_loss: 4206.0718 - val_mae: 36.5906\n",
      "Epoch 3910/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.1672 - mae: 8.6057 - val_loss: 4125.6567 - val_mae: 35.8325\n",
      "Epoch 3911/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.6849 - mae: 8.5171 - val_loss: 4128.0225 - val_mae: 35.9063\n",
      "Epoch 3912/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.4526 - mae: 8.3749 - val_loss: 4040.1106 - val_mae: 35.6366\n",
      "Epoch 3913/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.3459 - mae: 8.3031 - val_loss: 4090.9250 - val_mae: 35.8077\n",
      "Epoch 3914/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.7798 - mae: 8.2815 - val_loss: 4154.6440 - val_mae: 35.9955\n",
      "Epoch 3915/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.8695 - mae: 8.3699 - val_loss: 4132.4844 - val_mae: 35.7784\n",
      "Epoch 3916/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.3747 - mae: 7.8700 - val_loss: 4081.1267 - val_mae: 35.6734\n",
      "Epoch 3917/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.1801 - mae: 8.3314 - val_loss: 4069.6697 - val_mae: 35.6098\n",
      "Epoch 3918/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.5630 - mae: 8.0153 - val_loss: 4083.7527 - val_mae: 35.5058\n",
      "Epoch 3919/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.4146 - mae: 8.1053 - val_loss: 4165.1118 - val_mae: 36.0547\n",
      "Epoch 3920/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.2502 - mae: 8.1521 - val_loss: 4188.9727 - val_mae: 36.3283\n",
      "Epoch 3921/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 180.8256 - mae: 7.9431 - val_loss: 4198.0532 - val_mae: 36.0379\n",
      "Epoch 3922/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.9202 - mae: 7.8805 - val_loss: 4170.4644 - val_mae: 36.2421\n",
      "Epoch 3923/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.4751 - mae: 8.1688 - val_loss: 4175.4443 - val_mae: 35.6492\n",
      "Epoch 3924/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.5423 - mae: 8.1435 - val_loss: 4102.3809 - val_mae: 35.9376\n",
      "Epoch 3925/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.4394 - mae: 7.9645 - val_loss: 4212.0879 - val_mae: 36.1298\n",
      "Epoch 3926/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.3079 - mae: 7.9387 - val_loss: 4207.9790 - val_mae: 35.9873\n",
      "Epoch 3927/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.4378 - mae: 7.9907 - val_loss: 4090.1479 - val_mae: 35.3386\n",
      "Epoch 3928/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.6350 - mae: 8.1719 - val_loss: 4073.8230 - val_mae: 35.5583\n",
      "Epoch 3929/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 179.9148 - mae: 7.9132 - val_loss: 4045.8096 - val_mae: 35.1666\n",
      "Epoch 3930/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.0839 - mae: 8.1687 - val_loss: 4045.3901 - val_mae: 35.2450\n",
      "Epoch 3931/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.4593 - mae: 8.1964 - val_loss: 4116.1343 - val_mae: 35.4530\n",
      "Epoch 3932/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 252.5605 - mae: 8.2318 - val_loss: 4051.4119 - val_mae: 36.1170\n",
      "Epoch 3933/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 293.6811 - mae: 8.8838 - val_loss: 4118.2178 - val_mae: 35.9290\n",
      "Epoch 3934/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.3238 - mae: 8.7412 - val_loss: 4127.2358 - val_mae: 35.5159\n",
      "Epoch 3935/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 244.9508 - mae: 8.8315 - val_loss: 4162.3105 - val_mae: 35.7806\n",
      "Epoch 3936/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 178.3103 - mae: 8.0991 - val_loss: 4269.6743 - val_mae: 36.5783\n",
      "Epoch 3937/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.7999 - mae: 8.4916 - val_loss: 4162.3823 - val_mae: 36.3562\n",
      "Epoch 3938/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.5683 - mae: 8.5145 - val_loss: 4062.6948 - val_mae: 35.9971\n",
      "Epoch 3939/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 171.8965 - mae: 7.8239 - val_loss: 4210.0103 - val_mae: 36.7961\n",
      "Epoch 3940/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.3137 - mae: 8.1290 - val_loss: 4076.5410 - val_mae: 35.6317\n",
      "Epoch 3941/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.3002 - mae: 8.4584 - val_loss: 4179.8052 - val_mae: 36.1917\n",
      "Epoch 3942/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 242.2448 - mae: 8.6330 - val_loss: 4176.7017 - val_mae: 36.7786\n",
      "Epoch 3943/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.8627 - mae: 8.4107 - val_loss: 4260.7539 - val_mae: 36.1533\n",
      "Epoch 3944/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.1017 - mae: 8.2635 - val_loss: 4311.5132 - val_mae: 36.4252\n",
      "Epoch 3945/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 182.9446 - mae: 8.1074 - val_loss: 4195.4414 - val_mae: 35.9067\n",
      "Epoch 3946/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.0935 - mae: 8.3239 - val_loss: 4268.7446 - val_mae: 36.5204\n",
      "Epoch 3947/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.1968 - mae: 8.2442 - val_loss: 4055.9731 - val_mae: 35.4940\n",
      "Epoch 3948/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 217.8688 - mae: 8.6182 - val_loss: 4069.3162 - val_mae: 35.9035\n",
      "Epoch 3949/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.7144 - mae: 8.3649 - val_loss: 4096.7178 - val_mae: 35.4243\n",
      "Epoch 3950/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.1481 - mae: 8.0652 - val_loss: 4098.2275 - val_mae: 35.6060\n",
      "Epoch 3951/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.9873 - mae: 8.3352 - val_loss: 3977.0549 - val_mae: 35.0256\n",
      "Epoch 3952/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.0851 - mae: 8.1309 - val_loss: 4030.4097 - val_mae: 35.8759\n",
      "Epoch 3953/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.4464 - mae: 7.9558 - val_loss: 3981.1201 - val_mae: 34.9182\n",
      "Epoch 3954/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.2634 - mae: 8.1719 - val_loss: 4081.4331 - val_mae: 35.0570\n",
      "Epoch 3955/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.3887 - mae: 8.2339 - val_loss: 3931.5491 - val_mae: 34.6355\n",
      "Epoch 3956/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.8947 - mae: 7.9278 - val_loss: 4087.3267 - val_mae: 35.7854\n",
      "Epoch 3957/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.8130 - mae: 8.0390 - val_loss: 4096.1157 - val_mae: 35.4154\n",
      "Epoch 3958/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 228.7290 - mae: 8.4491 - val_loss: 4029.6897 - val_mae: 35.4097\n",
      "Epoch 3959/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.3155 - mae: 8.1022 - val_loss: 4018.2258 - val_mae: 36.0136\n",
      "Epoch 3960/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 161.9461 - mae: 7.8527 - val_loss: 4015.6001 - val_mae: 35.4440\n",
      "Epoch 3961/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 254.0114 - mae: 8.3019 - val_loss: 4064.5955 - val_mae: 35.3638\n",
      "Epoch 3962/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.4599 - mae: 8.2089 - val_loss: 4030.9863 - val_mae: 35.3741\n",
      "Epoch 3963/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 221.2608 - mae: 8.2428 - val_loss: 3994.8838 - val_mae: 35.2902\n",
      "Epoch 3964/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.6030 - mae: 8.0754 - val_loss: 4022.1257 - val_mae: 35.5325\n",
      "Epoch 3965/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.3815 - mae: 8.2016 - val_loss: 4025.2766 - val_mae: 35.4756\n",
      "Epoch 3966/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.5358 - mae: 7.9547 - val_loss: 3963.2734 - val_mae: 35.0056\n",
      "Epoch 3967/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.6368 - mae: 8.2095 - val_loss: 3962.5833 - val_mae: 35.3594\n",
      "Epoch 3968/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.8473 - mae: 8.1563 - val_loss: 4025.4604 - val_mae: 35.6144\n",
      "Epoch 3969/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.6206 - mae: 7.9244 - val_loss: 3981.4707 - val_mae: 35.2173\n",
      "Epoch 3970/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.5609 - mae: 8.3229 - val_loss: 4029.1780 - val_mae: 35.5271\n",
      "Epoch 3971/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.7562 - mae: 7.9364 - val_loss: 4070.7153 - val_mae: 35.2863\n",
      "Epoch 3972/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.2639 - mae: 8.5579 - val_loss: 3926.9773 - val_mae: 34.8596\n",
      "Epoch 3973/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.8893 - mae: 7.9907 - val_loss: 3936.4304 - val_mae: 34.9185\n",
      "Epoch 3974/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.3682 - mae: 8.0206 - val_loss: 3942.5652 - val_mae: 34.5880\n",
      "Epoch 3975/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.0683 - mae: 8.0794 - val_loss: 3956.5081 - val_mae: 34.8063\n",
      "Epoch 3976/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.1470 - mae: 7.7876 - val_loss: 3979.1438 - val_mae: 35.1741\n",
      "Epoch 3977/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 175.0567 - mae: 7.7756 - val_loss: 4071.5923 - val_mae: 35.2968\n",
      "Epoch 3978/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.9424 - mae: 8.1061 - val_loss: 4015.2986 - val_mae: 35.4887\n",
      "Epoch 3979/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.9556 - mae: 8.0678 - val_loss: 3968.4580 - val_mae: 35.3626\n",
      "Epoch 3980/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 207.5399 - mae: 8.1011 - val_loss: 4002.4954 - val_mae: 35.1974\n",
      "Epoch 3981/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.1617 - mae: 8.2075 - val_loss: 3905.7668 - val_mae: 34.7410\n",
      "Epoch 3982/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.4598 - mae: 8.1258 - val_loss: 3989.7288 - val_mae: 34.8787\n",
      "Epoch 3983/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.0202 - mae: 8.3285 - val_loss: 4020.8862 - val_mae: 35.3345\n",
      "Epoch 3984/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 167.3513 - mae: 7.5999 - val_loss: 4083.0808 - val_mae: 35.3357\n",
      "Epoch 3985/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.4433 - mae: 7.7570 - val_loss: 4002.7910 - val_mae: 35.1471\n",
      "Epoch 3986/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 174.4821 - mae: 7.8716 - val_loss: 4085.2788 - val_mae: 35.6869\n",
      "Epoch 3987/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 219.7892 - mae: 8.1780 - val_loss: 4030.4009 - val_mae: 34.7227\n",
      "Epoch 3988/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.2668 - mae: 8.1942 - val_loss: 3994.4170 - val_mae: 35.4740\n",
      "Epoch 3989/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.8283 - mae: 8.0788 - val_loss: 3949.1360 - val_mae: 34.7453\n",
      "Epoch 3990/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.2750 - mae: 7.8386 - val_loss: 3909.6221 - val_mae: 34.7585\n",
      "Epoch 3991/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.5644 - mae: 7.8856 - val_loss: 4050.4783 - val_mae: 35.2140\n",
      "Epoch 3992/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 189.2679 - mae: 7.9140 - val_loss: 3961.7000 - val_mae: 35.2931\n",
      "Epoch 3993/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.2220 - mae: 8.5529 - val_loss: 3945.3901 - val_mae: 35.1488\n",
      "Epoch 3994/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.4203 - mae: 7.9585 - val_loss: 4064.7612 - val_mae: 35.3524\n",
      "Epoch 3995/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.9745 - mae: 8.0226 - val_loss: 4052.1890 - val_mae: 35.3959\n",
      "Epoch 3996/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.5881 - mae: 8.0878 - val_loss: 3941.7148 - val_mae: 35.1679\n",
      "Epoch 3997/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.1279 - mae: 8.1020 - val_loss: 4057.1448 - val_mae: 35.3271\n",
      "Epoch 3998/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.4168 - mae: 7.8698 - val_loss: 4053.4082 - val_mae: 35.3652\n",
      "Epoch 3999/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.1557 - mae: 8.0446 - val_loss: 3963.6152 - val_mae: 34.9942\n",
      "Epoch 4000/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.4614 - mae: 8.1314 - val_loss: 4072.7830 - val_mae: 35.7006\n",
      "Epoch 4001/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.2086 - mae: 8.1232 - val_loss: 4056.9414 - val_mae: 34.9060\n",
      "Epoch 4002/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.2133 - mae: 8.1890 - val_loss: 4178.2578 - val_mae: 36.2212\n",
      "Epoch 4003/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 206.5176 - mae: 8.3025 - val_loss: 4141.7900 - val_mae: 35.9300\n",
      "Epoch 4004/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.2026 - mae: 8.2689 - val_loss: 4073.9966 - val_mae: 35.4333\n",
      "Epoch 4005/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.3812 - mae: 8.5306 - val_loss: 4077.6509 - val_mae: 36.1635\n",
      "Epoch 4006/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.4757 - mae: 8.5111 - val_loss: 4059.2903 - val_mae: 35.4230\n",
      "Epoch 4007/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.1987 - mae: 8.1489 - val_loss: 4071.3701 - val_mae: 36.0939\n",
      "Epoch 4008/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.2053 - mae: 8.0983 - val_loss: 4153.7495 - val_mae: 35.8484\n",
      "Epoch 4009/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.4661 - mae: 8.0023 - val_loss: 4224.3765 - val_mae: 36.2348\n",
      "Epoch 4010/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 154.2258 - mae: 7.7148 - val_loss: 4229.6787 - val_mae: 36.3361\n",
      "Epoch 4011/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.8583 - mae: 7.9822 - val_loss: 4402.8535 - val_mae: 36.6153\n",
      "Epoch 4012/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 182.2766 - mae: 8.0141 - val_loss: 4278.1182 - val_mae: 36.4014\n",
      "Epoch 4013/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 231.5202 - mae: 8.2646 - val_loss: 4289.2246 - val_mae: 36.2659\n",
      "Epoch 4014/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.6381 - mae: 7.9535 - val_loss: 4223.8970 - val_mae: 35.9659\n",
      "Epoch 4015/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 176.8675 - mae: 7.8777 - val_loss: 4420.3164 - val_mae: 36.2000\n",
      "Epoch 4016/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 236.4057 - mae: 8.3183 - val_loss: 4207.7427 - val_mae: 35.8432\n",
      "Epoch 4017/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.2646 - mae: 8.2740 - val_loss: 4215.9243 - val_mae: 36.2772\n",
      "Epoch 4018/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.2820 - mae: 8.4008 - val_loss: 4382.5581 - val_mae: 36.8981\n",
      "Epoch 4019/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.8450 - mae: 8.2508 - val_loss: 4539.7886 - val_mae: 37.3700\n",
      "Epoch 4020/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.8371 - mae: 8.0704 - val_loss: 4437.3398 - val_mae: 36.7779\n",
      "Epoch 4021/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.8518 - mae: 8.4916 - val_loss: 4344.5581 - val_mae: 36.3279\n",
      "Epoch 4022/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.8509 - mae: 8.2625 - val_loss: 4261.3364 - val_mae: 36.2149\n",
      "Epoch 4023/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 253.2285 - mae: 8.2375 - val_loss: 4282.6919 - val_mae: 36.4971\n",
      "Epoch 4024/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.7788 - mae: 8.0552 - val_loss: 4212.5103 - val_mae: 36.0676\n",
      "Epoch 4025/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.6728 - mae: 8.2717 - val_loss: 4138.8062 - val_mae: 35.7761\n",
      "Epoch 4026/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 196.8955 - mae: 7.9943 - val_loss: 4244.2593 - val_mae: 35.6972\n",
      "Epoch 4027/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.1846 - mae: 8.1809 - val_loss: 4334.7227 - val_mae: 36.0737\n",
      "Epoch 4028/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 202.5688 - mae: 8.2204 - val_loss: 4373.2090 - val_mae: 36.5026\n",
      "Epoch 4029/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 187.3085 - mae: 7.9609 - val_loss: 4253.1860 - val_mae: 36.0867\n",
      "Epoch 4030/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.2251 - mae: 8.2744 - val_loss: 4119.8062 - val_mae: 35.2641\n",
      "Epoch 4031/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 237.0656 - mae: 8.5655 - val_loss: 4121.6626 - val_mae: 35.8327\n",
      "Epoch 4032/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 213.4874 - mae: 8.2070 - val_loss: 4300.4121 - val_mae: 36.6221\n",
      "Epoch 4033/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 222.0539 - mae: 8.3919 - val_loss: 4071.8569 - val_mae: 36.0927\n",
      "Epoch 4034/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.1735 - mae: 8.4855 - val_loss: 4174.0034 - val_mae: 35.4779\n",
      "Epoch 4035/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 212.7533 - mae: 8.1423 - val_loss: 4284.0347 - val_mae: 36.0189\n",
      "Epoch 4036/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 229.3534 - mae: 8.3671 - val_loss: 4187.2026 - val_mae: 35.6063\n",
      "Epoch 4037/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 225.7377 - mae: 8.1732 - val_loss: 4195.2510 - val_mae: 35.8582\n",
      "Epoch 4038/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.2347 - mae: 8.0150 - val_loss: 4182.0088 - val_mae: 35.6212\n",
      "Epoch 4039/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.3259 - mae: 8.1784 - val_loss: 4260.3081 - val_mae: 36.3994\n",
      "Epoch 4040/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 188.8771 - mae: 7.9667 - val_loss: 4200.2324 - val_mae: 35.9456\n",
      "Epoch 4041/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 201.1011 - mae: 8.1122 - val_loss: 4325.1196 - val_mae: 36.6883\n",
      "Epoch 4042/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.7464 - mae: 8.1184 - val_loss: 4265.9434 - val_mae: 36.5351\n",
      "Epoch 4043/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.3454 - mae: 8.1228 - val_loss: 4316.2588 - val_mae: 36.7033\n",
      "Epoch 4044/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.9121 - mae: 7.9176 - val_loss: 4218.0947 - val_mae: 36.1010\n",
      "Epoch 4045/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.6808 - mae: 8.0828 - val_loss: 4136.3755 - val_mae: 35.8762\n",
      "Epoch 4046/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.1176 - mae: 8.1548 - val_loss: 4245.1797 - val_mae: 36.2483\n",
      "Epoch 4047/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.5515 - mae: 7.9263 - val_loss: 4187.2354 - val_mae: 35.7766\n",
      "Epoch 4048/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.2146 - mae: 8.0316 - val_loss: 4262.6138 - val_mae: 35.6214\n",
      "Epoch 4049/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.4205 - mae: 8.1666 - val_loss: 4389.0967 - val_mae: 36.3915\n",
      "Epoch 4050/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.9622 - mae: 8.1354 - val_loss: 4194.2515 - val_mae: 35.8142\n",
      "Epoch 4051/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.8980 - mae: 7.7773 - val_loss: 4190.2334 - val_mae: 35.4500\n",
      "Epoch 4052/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.3943 - mae: 7.9398 - val_loss: 4389.2266 - val_mae: 35.9987\n",
      "Epoch 4053/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.3655 - mae: 7.9293 - val_loss: 4338.0493 - val_mae: 36.1990\n",
      "Epoch 4054/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.8464 - mae: 8.0429 - val_loss: 4421.7178 - val_mae: 36.1113\n",
      "Epoch 4055/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.4307 - mae: 7.8456 - val_loss: 4240.6616 - val_mae: 36.1713\n",
      "Epoch 4056/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 1080.0879 - mae: 8.8726 - val_loss: 4424.0898 - val_mae: 36.5730\n",
      "Epoch 4057/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.2759 - mae: 8.2843 - val_loss: 4422.1533 - val_mae: 36.5550\n",
      "Epoch 4058/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.7215 - mae: 8.4816 - val_loss: 4441.8486 - val_mae: 36.5924\n",
      "Epoch 4059/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.5412 - mae: 8.3736 - val_loss: 4268.9707 - val_mae: 36.1699\n",
      "Epoch 4060/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 280.5495 - mae: 8.7884 - val_loss: 4264.3062 - val_mae: 36.0279\n",
      "Epoch 4061/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.1351 - mae: 8.5475 - val_loss: 4241.8130 - val_mae: 35.7453\n",
      "Epoch 4062/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.2706 - mae: 8.3681 - val_loss: 4273.7075 - val_mae: 35.8833\n",
      "Epoch 4063/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 164.0221 - mae: 7.7967 - val_loss: 4224.8267 - val_mae: 35.8364\n",
      "Epoch 4064/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.3532 - mae: 8.1808 - val_loss: 4166.0757 - val_mae: 35.8021\n",
      "Epoch 4065/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.7783 - mae: 7.8549 - val_loss: 4111.1792 - val_mae: 35.6634\n",
      "Epoch 4066/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.7493 - mae: 7.9104 - val_loss: 4273.9844 - val_mae: 36.0190\n",
      "Epoch 4067/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.1024 - mae: 7.8725 - val_loss: 4128.5005 - val_mae: 35.1893\n",
      "Epoch 4068/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.2717 - mae: 8.2796 - val_loss: 4198.7520 - val_mae: 35.4848\n",
      "Epoch 4069/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.9646 - mae: 8.1940 - val_loss: 4191.4863 - val_mae: 35.4534\n",
      "Epoch 4070/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.8077 - mae: 8.1346 - val_loss: 4115.0664 - val_mae: 35.3248\n",
      "Epoch 4071/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.1744 - mae: 8.0129 - val_loss: 4190.2827 - val_mae: 35.0729\n",
      "Epoch 4072/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.1640 - mae: 8.1876 - val_loss: 4065.8335 - val_mae: 34.8394\n",
      "Epoch 4073/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 181.9919 - mae: 8.1205 - val_loss: 4026.9221 - val_mae: 34.7605\n",
      "Epoch 4074/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.6030 - mae: 8.7351 - val_loss: 4078.8318 - val_mae: 35.1856\n",
      "Epoch 4075/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 193.3024 - mae: 7.9504 - val_loss: 4087.4714 - val_mae: 34.7318\n",
      "Epoch 4076/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.0010 - mae: 7.8779 - val_loss: 4047.6343 - val_mae: 35.0858\n",
      "Epoch 4077/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.2081 - mae: 7.9062 - val_loss: 4016.0391 - val_mae: 35.3930\n",
      "Epoch 4078/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.0959 - mae: 7.8414 - val_loss: 4073.2070 - val_mae: 35.0981\n",
      "Epoch 4079/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.8823 - mae: 7.8765 - val_loss: 3984.2422 - val_mae: 34.7499\n",
      "Epoch 4080/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 168.7886 - mae: 7.7057 - val_loss: 4176.8481 - val_mae: 35.6701\n",
      "Epoch 4081/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 201.4045 - mae: 7.7096 - val_loss: 4118.4512 - val_mae: 35.4651\n",
      "Epoch 4082/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 182.7161 - mae: 7.9334 - val_loss: 4130.8711 - val_mae: 35.7005\n",
      "Epoch 4083/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.1545 - mae: 8.1169 - val_loss: 4119.5903 - val_mae: 34.9974\n",
      "Epoch 4084/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 183.4821 - mae: 7.9130 - val_loss: 4075.4626 - val_mae: 35.2859\n",
      "Epoch 4085/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 205.4515 - mae: 8.2601 - val_loss: 3941.2437 - val_mae: 34.7321\n",
      "Epoch 4086/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 191.8995 - mae: 8.1027 - val_loss: 4042.3254 - val_mae: 35.5573\n",
      "Epoch 4087/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.6947 - mae: 7.9208 - val_loss: 4067.7087 - val_mae: 35.3669\n",
      "Epoch 4088/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.7697 - mae: 7.9804 - val_loss: 4075.4927 - val_mae: 34.9960\n",
      "Epoch 4089/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.9702 - mae: 8.0724 - val_loss: 4180.4785 - val_mae: 35.7628\n",
      "Epoch 4090/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.3353 - mae: 7.8084 - val_loss: 4166.9102 - val_mae: 35.1932\n",
      "Epoch 4091/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.5469 - mae: 8.0362 - val_loss: 4108.0786 - val_mae: 35.1191\n",
      "Epoch 4092/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.4434 - mae: 8.0726 - val_loss: 4023.0916 - val_mae: 35.4290\n",
      "Epoch 4093/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.8217 - mae: 7.9149 - val_loss: 4107.4077 - val_mae: 34.9450\n",
      "Epoch 4094/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.5097 - mae: 7.9407 - val_loss: 4131.1567 - val_mae: 35.3415\n",
      "Epoch 4095/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.8054 - mae: 7.9743 - val_loss: 4122.9326 - val_mae: 34.9294\n",
      "Epoch 4096/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.0350 - mae: 7.9072 - val_loss: 4084.7336 - val_mae: 34.8085\n",
      "Epoch 4097/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.1808 - mae: 8.0943 - val_loss: 4065.0566 - val_mae: 35.2722\n",
      "Epoch 4098/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.3220 - mae: 8.0876 - val_loss: 4076.1323 - val_mae: 35.5734\n",
      "Epoch 4099/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.4867 - mae: 8.4867 - val_loss: 4168.3716 - val_mae: 35.7523\n",
      "Epoch 4100/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.6869 - mae: 8.1411 - val_loss: 4194.2935 - val_mae: 35.6235\n",
      "Epoch 4101/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 222.4780 - mae: 8.3076 - val_loss: 4103.6724 - val_mae: 35.6731\n",
      "Epoch 4102/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.7681 - mae: 7.7598 - val_loss: 4240.6904 - val_mae: 36.2437\n",
      "Epoch 4103/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.0374 - mae: 8.1848 - val_loss: 4258.4380 - val_mae: 36.2138\n",
      "Epoch 4104/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 224.5092 - mae: 8.2712 - val_loss: 4185.9961 - val_mae: 35.8220\n",
      "Epoch 4105/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.8433 - mae: 7.9435 - val_loss: 4286.2861 - val_mae: 35.9781\n",
      "Epoch 4106/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 248.9435 - mae: 8.4852 - val_loss: 4231.3896 - val_mae: 36.1525\n",
      "Epoch 4107/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.7314 - mae: 8.5635 - val_loss: 4239.5522 - val_mae: 35.9286\n",
      "Epoch 4108/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.9743 - mae: 8.4520 - val_loss: 4214.0312 - val_mae: 36.0534\n",
      "Epoch 4109/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.4744 - mae: 8.5845 - val_loss: 4162.8433 - val_mae: 35.9606\n",
      "Epoch 4110/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.7338 - mae: 8.7456 - val_loss: 4233.5542 - val_mae: 35.8994\n",
      "Epoch 4111/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.4574 - mae: 8.4399 - val_loss: 4344.7769 - val_mae: 36.2180\n",
      "Epoch 4112/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.2054 - mae: 8.4024 - val_loss: 4215.2285 - val_mae: 36.3865\n",
      "Epoch 4113/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.3992 - mae: 8.6813 - val_loss: 4269.8975 - val_mae: 36.4068\n",
      "Epoch 4114/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.9960 - mae: 9.8896 - val_loss: 4190.3477 - val_mae: 36.8095\n",
      "Epoch 4115/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.0690 - mae: 8.2014 - val_loss: 4162.3965 - val_mae: 36.2894\n",
      "Epoch 4116/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.7845 - mae: 8.1494 - val_loss: 4104.7910 - val_mae: 35.5242\n",
      "Epoch 4117/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.0835 - mae: 8.3244 - val_loss: 4042.7168 - val_mae: 36.3115\n",
      "Epoch 4118/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.9721 - mae: 8.2782 - val_loss: 4168.9878 - val_mae: 35.9194\n",
      "Epoch 4119/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.1300 - mae: 8.1590 - val_loss: 4180.8184 - val_mae: 35.6172\n",
      "Epoch 4120/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.3670 - mae: 7.9817 - val_loss: 4129.0005 - val_mae: 35.1978\n",
      "Epoch 4121/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.1842 - mae: 8.0062 - val_loss: 4251.2090 - val_mae: 35.8155\n",
      "Epoch 4122/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.0297 - mae: 7.8690 - val_loss: 4092.4795 - val_mae: 35.6885\n",
      "Epoch 4123/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.0956 - mae: 8.1109 - val_loss: 4162.3862 - val_mae: 35.8884\n",
      "Epoch 4124/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.2594 - mae: 8.1225 - val_loss: 4153.5845 - val_mae: 35.5699\n",
      "Epoch 4125/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.0071 - mae: 7.9952 - val_loss: 4182.0991 - val_mae: 35.9946\n",
      "Epoch 4126/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 239.1784 - mae: 8.3962 - val_loss: 4182.5259 - val_mae: 35.8991\n",
      "Epoch 4127/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.6520 - mae: 8.6320 - val_loss: 4256.2559 - val_mae: 35.9612\n",
      "Epoch 4128/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.6832 - mae: 8.1570 - val_loss: 4334.8716 - val_mae: 36.1158\n",
      "Epoch 4129/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 176.5046 - mae: 7.7808 - val_loss: 4247.1411 - val_mae: 35.7561\n",
      "Epoch 4130/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 195.7341 - mae: 7.9535 - val_loss: 4262.8438 - val_mae: 35.9511\n",
      "Epoch 4131/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 236.1754 - mae: 8.4670 - val_loss: 4245.1997 - val_mae: 35.8508\n",
      "Epoch 4132/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.4782 - mae: 8.1004 - val_loss: 4250.2979 - val_mae: 36.1011\n",
      "Epoch 4133/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.0191 - mae: 8.7094 - val_loss: 4224.1685 - val_mae: 36.8922\n",
      "Epoch 4134/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.5254 - mae: 8.6413 - val_loss: 4244.2061 - val_mae: 35.4406\n",
      "Epoch 4135/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.1277 - mae: 7.7572 - val_loss: 4314.9556 - val_mae: 35.7214\n",
      "Epoch 4136/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.7209 - mae: 7.9319 - val_loss: 4338.6626 - val_mae: 35.3970\n",
      "Epoch 4137/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.6957 - mae: 7.7984 - val_loss: 4215.2471 - val_mae: 35.5661\n",
      "Epoch 4138/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2949 - mae: 7.9865 - val_loss: 4210.4834 - val_mae: 35.4743\n",
      "Epoch 4139/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.4795 - mae: 8.1678 - val_loss: 4139.0225 - val_mae: 35.6014\n",
      "Epoch 4140/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.8440 - mae: 7.8871 - val_loss: 4153.6240 - val_mae: 35.6291\n",
      "Epoch 4141/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.1350 - mae: 7.8545 - val_loss: 4203.2183 - val_mae: 35.6989\n",
      "Epoch 4142/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 172.2235 - mae: 7.7272 - val_loss: 4153.5254 - val_mae: 35.0667\n",
      "Epoch 4143/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 181.7890 - mae: 8.0394 - val_loss: 4146.3125 - val_mae: 35.1839\n",
      "Epoch 4144/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.0691 - mae: 7.9069 - val_loss: 4166.4199 - val_mae: 35.3238\n",
      "Epoch 4145/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.9355 - mae: 7.6693 - val_loss: 4159.2520 - val_mae: 35.7999\n",
      "Epoch 4146/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.7205 - mae: 7.8758 - val_loss: 4102.8843 - val_mae: 35.0905\n",
      "Epoch 4147/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 200.3913 - mae: 8.1739 - val_loss: 4239.4565 - val_mae: 35.9165\n",
      "Epoch 4148/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.8214 - mae: 8.1247 - val_loss: 4190.6538 - val_mae: 35.2472\n",
      "Epoch 4149/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.9082 - mae: 7.9519 - val_loss: 4321.1973 - val_mae: 36.0941\n",
      "Epoch 4150/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.0577 - mae: 7.9280 - val_loss: 4159.3389 - val_mae: 35.5708\n",
      "Epoch 4151/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.4249 - mae: 8.2169 - val_loss: 4226.5527 - val_mae: 35.8026\n",
      "Epoch 4152/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.6350 - mae: 7.8329 - val_loss: 4342.7563 - val_mae: 36.1095\n",
      "Epoch 4153/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.9955 - mae: 8.0428 - val_loss: 4244.8530 - val_mae: 35.7368\n",
      "Epoch 4154/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.2449 - mae: 8.1457 - val_loss: 4234.6826 - val_mae: 35.6175\n",
      "Epoch 4155/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.3416 - mae: 8.4394 - val_loss: 4152.1104 - val_mae: 35.6955\n",
      "Epoch 4156/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.7646 - mae: 8.2827 - val_loss: 4277.3955 - val_mae: 36.1129\n",
      "Epoch 4157/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.4342 - mae: 8.2526 - val_loss: 4109.9092 - val_mae: 35.0090\n",
      "Epoch 4158/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.1277 - mae: 8.3003 - val_loss: 4068.4397 - val_mae: 35.5797\n",
      "Epoch 4159/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.5031 - mae: 8.2216 - val_loss: 4199.0742 - val_mae: 35.9950\n",
      "Epoch 4160/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.3222 - mae: 8.0671 - val_loss: 4069.4592 - val_mae: 35.3801\n",
      "Epoch 4161/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.5783 - mae: 8.2648 - val_loss: 3974.7896 - val_mae: 35.3535\n",
      "Epoch 4162/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.0790 - mae: 7.8480 - val_loss: 3983.8809 - val_mae: 35.4687\n",
      "Epoch 4163/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.1141 - mae: 8.3764 - val_loss: 3990.7969 - val_mae: 35.5426\n",
      "Epoch 4164/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.2441 - mae: 7.9003 - val_loss: 4010.5337 - val_mae: 35.3359\n",
      "Epoch 4165/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.4258 - mae: 7.9473 - val_loss: 4041.3950 - val_mae: 35.2434\n",
      "Epoch 4166/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.1301 - mae: 8.2326 - val_loss: 4136.7476 - val_mae: 35.1366\n",
      "Epoch 4167/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.9023 - mae: 8.1522 - val_loss: 4074.5205 - val_mae: 35.0498\n",
      "Epoch 4168/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.7150 - mae: 7.9632 - val_loss: 4036.3408 - val_mae: 35.1478\n",
      "Epoch 4169/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.0405 - mae: 7.8319 - val_loss: 4033.2095 - val_mae: 35.2749\n",
      "Epoch 4170/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.6838 - mae: 8.1232 - val_loss: 4045.6978 - val_mae: 35.3806\n",
      "Epoch 4171/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.5839 - mae: 7.9184 - val_loss: 4116.6777 - val_mae: 36.1225\n",
      "Epoch 4172/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.2540 - mae: 7.9929 - val_loss: 4055.5420 - val_mae: 35.5607\n",
      "Epoch 4173/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.7188 - mae: 8.3387 - val_loss: 4194.9639 - val_mae: 35.9561\n",
      "Epoch 4174/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.6153 - mae: 8.0766 - val_loss: 4128.0322 - val_mae: 35.7470\n",
      "Epoch 4175/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.8587 - mae: 8.0631 - val_loss: 4113.1577 - val_mae: 35.4454\n",
      "Epoch 4176/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.2492 - mae: 7.9223 - val_loss: 4195.2090 - val_mae: 36.2477\n",
      "Epoch 4177/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.7503 - mae: 8.1072 - val_loss: 4115.1675 - val_mae: 35.7597\n",
      "Epoch 4178/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.8941 - mae: 8.2458 - val_loss: 4197.7925 - val_mae: 36.1089\n",
      "Epoch 4179/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.9540 - mae: 8.2739 - val_loss: 4234.7695 - val_mae: 36.3277\n",
      "Epoch 4180/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.2572 - mae: 8.1305 - val_loss: 4294.7573 - val_mae: 35.7339\n",
      "Epoch 4181/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.7845 - mae: 8.0445 - val_loss: 4246.0425 - val_mae: 35.6870\n",
      "Epoch 4182/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 159.4532 - mae: 7.5598 - val_loss: 4272.5107 - val_mae: 35.8073\n",
      "Epoch 4183/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.5365 - mae: 7.8657 - val_loss: 4240.0044 - val_mae: 35.9216\n",
      "Epoch 4184/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.0629 - mae: 7.5530 - val_loss: 4176.9307 - val_mae: 35.7588\n",
      "Epoch 4185/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 174.9014 - mae: 7.6655 - val_loss: 4091.9790 - val_mae: 34.9996\n",
      "Epoch 4186/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.6548 - mae: 7.6612 - val_loss: 4141.3667 - val_mae: 35.4935\n",
      "Epoch 4187/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.1601 - mae: 7.7151 - val_loss: 4137.0581 - val_mae: 35.5845\n",
      "Epoch 4188/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.7700 - mae: 7.4840 - val_loss: 4351.1841 - val_mae: 36.1618\n",
      "Epoch 4189/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.5604 - mae: 7.7225 - val_loss: 4339.7358 - val_mae: 36.5502\n",
      "Epoch 4190/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.6808 - mae: 7.7636 - val_loss: 4174.6548 - val_mae: 35.5399\n",
      "Epoch 4191/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.0735 - mae: 7.9846 - val_loss: 4300.4155 - val_mae: 36.0032\n",
      "Epoch 4192/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 216.8859 - mae: 8.1734 - val_loss: 4390.8223 - val_mae: 36.2325\n",
      "Epoch 4193/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.6780 - mae: 8.0674 - val_loss: 4267.9678 - val_mae: 36.7514\n",
      "Epoch 4194/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 176.7932 - mae: 7.9868 - val_loss: 4246.0244 - val_mae: 36.5645\n",
      "Epoch 4195/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 218.7773 - mae: 7.9948 - val_loss: 4247.4170 - val_mae: 36.4494\n",
      "Epoch 4196/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.1918 - mae: 7.9957 - val_loss: 4133.0122 - val_mae: 35.7666\n",
      "Epoch 4197/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.8407 - mae: 8.1975 - val_loss: 4259.3413 - val_mae: 35.9260\n",
      "Epoch 4198/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.0640 - mae: 7.9773 - val_loss: 4176.2446 - val_mae: 35.1933\n",
      "Epoch 4199/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.7778 - mae: 8.0135 - val_loss: 4210.9478 - val_mae: 35.9142\n",
      "Epoch 4200/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.0484 - mae: 7.9822 - val_loss: 4171.3818 - val_mae: 36.0070\n",
      "Epoch 4201/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.3556 - mae: 7.9760 - val_loss: 4166.8984 - val_mae: 35.9237\n",
      "Epoch 4202/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.5061 - mae: 8.1674 - val_loss: 4154.8232 - val_mae: 35.8635\n",
      "Epoch 4203/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.6098 - mae: 8.5587 - val_loss: 4129.6187 - val_mae: 37.2500\n",
      "Epoch 4204/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.8751 - mae: 8.7977 - val_loss: 4077.1399 - val_mae: 35.5603\n",
      "Epoch 4205/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 245.2384 - mae: 8.1476 - val_loss: 4303.8872 - val_mae: 36.4324\n",
      "Epoch 4206/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.4569 - mae: 7.6300 - val_loss: 4234.0181 - val_mae: 36.1053\n",
      "Epoch 4207/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.3356 - mae: 7.9388 - val_loss: 4176.5244 - val_mae: 35.8898\n",
      "Epoch 4208/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.6019 - mae: 8.0818 - val_loss: 4147.3467 - val_mae: 35.7901\n",
      "Epoch 4209/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 164.0456 - mae: 7.5117 - val_loss: 4260.9624 - val_mae: 36.7041\n",
      "Epoch 4210/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.4403 - mae: 8.0715 - val_loss: 4184.7144 - val_mae: 36.1941\n",
      "Epoch 4211/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.9542 - mae: 7.8329 - val_loss: 4084.1147 - val_mae: 35.8827\n",
      "Epoch 4212/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.4678 - mae: 7.8856 - val_loss: 4146.4219 - val_mae: 35.4908\n",
      "Epoch 4213/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.5386 - mae: 8.2563 - val_loss: 4154.0654 - val_mae: 35.7858\n",
      "Epoch 4214/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 216.1008 - mae: 8.0910 - val_loss: 4243.0840 - val_mae: 36.0428\n",
      "Epoch 4215/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.8695 - mae: 7.8774 - val_loss: 4193.0605 - val_mae: 35.6939\n",
      "Epoch 4216/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 183.0031 - mae: 8.0275 - val_loss: 4202.6147 - val_mae: 36.0211\n",
      "Epoch 4217/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 159.5124 - mae: 7.6180 - val_loss: 4283.4839 - val_mae: 35.4891\n",
      "Epoch 4218/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.3144 - mae: 7.9804 - val_loss: 4120.9517 - val_mae: 35.8368\n",
      "Epoch 4219/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 208.6191 - mae: 8.1794 - val_loss: 4266.2959 - val_mae: 35.5784\n",
      "Epoch 4220/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.9125 - mae: 7.7507 - val_loss: 4284.1011 - val_mae: 36.0856\n",
      "Epoch 4221/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 184.2447 - mae: 7.9959 - val_loss: 4271.0576 - val_mae: 35.8852\n",
      "Epoch 4222/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.2319 - mae: 8.0715 - val_loss: 4247.8599 - val_mae: 36.3302\n",
      "Epoch 4223/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.0208 - mae: 7.8639 - val_loss: 4238.2910 - val_mae: 35.7755\n",
      "Epoch 4224/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.3217 - mae: 8.1332 - val_loss: 4250.0918 - val_mae: 36.0660\n",
      "Epoch 4225/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.8774 - mae: 8.0326 - val_loss: 4298.8516 - val_mae: 36.5132\n",
      "Epoch 4226/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.9768 - mae: 8.3496 - val_loss: 4274.8857 - val_mae: 35.5563\n",
      "Epoch 4227/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.3514 - mae: 8.1732 - val_loss: 4236.3213 - val_mae: 35.8664\n",
      "Epoch 4228/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 232.4567 - mae: 9.4098 - val_loss: 4202.1787 - val_mae: 35.9917\n",
      "Epoch 4229/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 166.9583 - mae: 7.6197 - val_loss: 4215.6426 - val_mae: 35.7566\n",
      "Epoch 4230/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 252.7200 - mae: 9.5044 - val_loss: 4213.3003 - val_mae: 36.8926\n",
      "Epoch 4231/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 204.1163 - mae: 9.0014 - val_loss: 4108.9600 - val_mae: 36.1414\n",
      "Epoch 4232/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 261.4260 - mae: 9.0030 - val_loss: 4045.1162 - val_mae: 35.1452\n",
      "Epoch 4233/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 222.4648 - mae: 8.1938 - val_loss: 4171.5713 - val_mae: 35.4395\n",
      "Epoch 4234/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 212.3972 - mae: 8.0598 - val_loss: 4125.6089 - val_mae: 36.1025\n",
      "Epoch 4235/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 223.3098 - mae: 8.0862 - val_loss: 4156.3604 - val_mae: 35.3982\n",
      "Epoch 4236/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.9245 - mae: 8.0877 - val_loss: 4196.8735 - val_mae: 35.6909\n",
      "Epoch 4237/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 201.9953 - mae: 8.0225 - val_loss: 4200.6987 - val_mae: 35.4256\n",
      "Epoch 4238/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.1283 - mae: 8.1473 - val_loss: 4135.2690 - val_mae: 35.4834\n",
      "Epoch 4239/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.2081 - mae: 7.9771 - val_loss: 4209.3159 - val_mae: 35.4140\n",
      "Epoch 4240/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.1920 - mae: 7.9806 - val_loss: 4233.5347 - val_mae: 35.7419\n",
      "Epoch 4241/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.0766 - mae: 7.7742 - val_loss: 4155.5430 - val_mae: 35.3264\n",
      "Epoch 4242/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.8440 - mae: 7.9839 - val_loss: 4145.9668 - val_mae: 36.2347\n",
      "Epoch 4243/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.6685 - mae: 7.6984 - val_loss: 4189.9585 - val_mae: 35.9439\n",
      "Epoch 4244/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.8803 - mae: 7.9567 - val_loss: 4192.5625 - val_mae: 35.8005\n",
      "Epoch 4245/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 215.4273 - mae: 8.1451 - val_loss: 4113.6797 - val_mae: 35.5212\n",
      "Epoch 4246/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.8974 - mae: 7.9430 - val_loss: 4164.0137 - val_mae: 35.7553\n",
      "Epoch 4247/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.4617 - mae: 7.8263 - val_loss: 4179.2017 - val_mae: 35.4904\n",
      "Epoch 4248/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.2155 - mae: 7.9516 - val_loss: 4300.8511 - val_mae: 36.3682\n",
      "Epoch 4249/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.5334 - mae: 8.1054 - val_loss: 4262.6387 - val_mae: 36.2840\n",
      "Epoch 4250/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.2988 - mae: 8.1067 - val_loss: 4262.2090 - val_mae: 35.9191\n",
      "Epoch 4251/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 174.3821 - mae: 7.7852 - val_loss: 4190.6816 - val_mae: 35.8221\n",
      "Epoch 4252/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.6394 - mae: 7.7901 - val_loss: 4189.3545 - val_mae: 36.0281\n",
      "Epoch 4253/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.1987 - mae: 7.9837 - val_loss: 4440.3667 - val_mae: 37.4987\n",
      "Epoch 4254/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.1519 - mae: 8.0337 - val_loss: 4257.8989 - val_mae: 36.2422\n",
      "Epoch 4255/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.7838 - mae: 8.2357 - val_loss: 4200.1372 - val_mae: 36.1100\n",
      "Epoch 4256/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.6853 - mae: 7.9066 - val_loss: 4308.7261 - val_mae: 36.5237\n",
      "Epoch 4257/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 214.0890 - mae: 8.1741 - val_loss: 4072.6262 - val_mae: 35.2227\n",
      "Epoch 4258/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 243.7975 - mae: 8.0892 - val_loss: 4029.7839 - val_mae: 34.7641\n",
      "Epoch 4259/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 244.8450 - mae: 8.3653 - val_loss: 3990.4736 - val_mae: 35.0364\n",
      "Epoch 4260/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.9215 - mae: 7.9315 - val_loss: 3939.9021 - val_mae: 34.7913\n",
      "Epoch 4261/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 194.6725 - mae: 7.8905 - val_loss: 4110.7573 - val_mae: 35.3251\n",
      "Epoch 4262/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 199.4043 - mae: 7.9740 - val_loss: 4044.9114 - val_mae: 35.2890\n",
      "Epoch 4263/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 197.3104 - mae: 8.0098 - val_loss: 4088.7754 - val_mae: 35.2673\n",
      "Epoch 4264/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.9924 - mae: 8.1720 - val_loss: 4098.2539 - val_mae: 35.1234\n",
      "Epoch 4265/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.5728 - mae: 7.8940 - val_loss: 4033.0991 - val_mae: 35.1467\n",
      "Epoch 4266/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.5663 - mae: 8.1406 - val_loss: 4143.1016 - val_mae: 35.5392\n",
      "Epoch 4267/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.8118 - mae: 7.9305 - val_loss: 4172.0239 - val_mae: 35.6031\n",
      "Epoch 4268/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.9420 - mae: 8.0380 - val_loss: 4030.2993 - val_mae: 34.7847\n",
      "Epoch 4269/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 180.7802 - mae: 7.8564 - val_loss: 4003.4307 - val_mae: 35.0679\n",
      "Epoch 4270/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.9727 - mae: 8.1760 - val_loss: 4090.9341 - val_mae: 35.8071\n",
      "Epoch 4271/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 177.1469 - mae: 7.8294 - val_loss: 4065.9832 - val_mae: 35.6741\n",
      "Epoch 4272/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.4253 - mae: 7.9709 - val_loss: 4122.8486 - val_mae: 35.8159\n",
      "Epoch 4273/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.7839 - mae: 8.0536 - val_loss: 4132.5474 - val_mae: 35.7424\n",
      "Epoch 4274/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.3563 - mae: 8.0394 - val_loss: 3990.9856 - val_mae: 35.3871\n",
      "Epoch 4275/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 210.1911 - mae: 8.0909 - val_loss: 3968.6628 - val_mae: 35.8290\n",
      "Epoch 4276/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.1215 - mae: 7.8671 - val_loss: 3966.0298 - val_mae: 35.4794\n",
      "Epoch 4277/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 203.6338 - mae: 8.0337 - val_loss: 3974.2095 - val_mae: 35.0757\n",
      "Epoch 4278/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 176.8090 - mae: 7.7647 - val_loss: 4133.6714 - val_mae: 36.0190\n",
      "Epoch 4279/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.3626 - mae: 7.5003 - val_loss: 4201.5757 - val_mae: 36.1490\n",
      "Epoch 4280/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 226.3261 - mae: 8.2507 - val_loss: 4113.5728 - val_mae: 36.4591\n",
      "Epoch 4281/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 181.5283 - mae: 8.0900 - val_loss: 4048.4268 - val_mae: 35.6839\n",
      "Epoch 4282/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 185.2568 - mae: 8.0401 - val_loss: 4262.8535 - val_mae: 36.4791\n",
      "Epoch 4283/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 179.2513 - mae: 7.9944 - val_loss: 4133.7246 - val_mae: 36.3115\n",
      "Epoch 4284/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.4921 - mae: 7.8669 - val_loss: 4190.5796 - val_mae: 37.0603\n",
      "Epoch 4285/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 211.4127 - mae: 8.2489 - val_loss: 4009.1963 - val_mae: 35.1602\n",
      "Epoch 4286/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 179.3612 - mae: 7.7884 - val_loss: 4011.5432 - val_mae: 35.4416\n",
      "Epoch 4287/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.0775 - mae: 8.1522 - val_loss: 4167.0010 - val_mae: 36.1758\n",
      "Epoch 4288/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.5357 - mae: 8.2388 - val_loss: 4073.1421 - val_mae: 35.4183\n",
      "Epoch 4289/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.0545 - mae: 8.0470 - val_loss: 4181.8506 - val_mae: 36.1220\n",
      "Epoch 4290/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.1568 - mae: 8.0698 - val_loss: 4057.8855 - val_mae: 35.5914\n",
      "Epoch 4291/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.5722 - mae: 7.9265 - val_loss: 4030.9231 - val_mae: 35.5079\n",
      "Epoch 4292/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.7957 - mae: 8.3244 - val_loss: 4020.6277 - val_mae: 34.8958\n",
      "Epoch 4293/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.5063 - mae: 8.1427 - val_loss: 3942.8354 - val_mae: 35.0438\n",
      "Epoch 4294/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.2534 - mae: 7.7189 - val_loss: 4115.8066 - val_mae: 35.7494\n",
      "Epoch 4295/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.5427 - mae: 7.9662 - val_loss: 4039.3198 - val_mae: 35.2415\n",
      "Epoch 4296/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.5636 - mae: 8.0793 - val_loss: 4091.9883 - val_mae: 36.1460\n",
      "Epoch 4297/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 276.1481 - mae: 8.3228 - val_loss: 4109.8164 - val_mae: 35.4575\n",
      "Epoch 4298/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.4187 - mae: 7.7856 - val_loss: 4203.1069 - val_mae: 36.3246\n",
      "Epoch 4299/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.3253 - mae: 7.7765 - val_loss: 4137.5972 - val_mae: 35.9546\n",
      "Epoch 4300/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 252.8726 - mae: 8.4931 - val_loss: 4178.5684 - val_mae: 36.1111\n",
      "Epoch 4301/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 257.9840 - mae: 8.2941 - val_loss: 4207.0991 - val_mae: 35.7251\n",
      "Epoch 4302/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.3256 - mae: 8.5939 - val_loss: 4061.4380 - val_mae: 34.9073\n",
      "Epoch 4303/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.2405 - mae: 8.3995 - val_loss: 4118.7222 - val_mae: 35.0950\n",
      "Epoch 4304/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.1033 - mae: 8.2715 - val_loss: 4052.7634 - val_mae: 35.1084\n",
      "Epoch 4305/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.4064 - mae: 8.4396 - val_loss: 4042.8540 - val_mae: 35.2612\n",
      "Epoch 4306/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 198.4854 - mae: 8.2770 - val_loss: 4018.6646 - val_mae: 35.2926\n",
      "Epoch 4307/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 204.1954 - mae: 8.0773 - val_loss: 3982.4841 - val_mae: 35.1684\n",
      "Epoch 4308/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 179.8039 - mae: 7.9017 - val_loss: 4116.1338 - val_mae: 35.3554\n",
      "Epoch 4309/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.4598 - mae: 8.1309 - val_loss: 4118.3394 - val_mae: 35.8104\n",
      "Epoch 4310/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.4076 - mae: 7.9894 - val_loss: 3995.8562 - val_mae: 35.4746\n",
      "Epoch 4311/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.1580 - mae: 8.2123 - val_loss: 4044.0051 - val_mae: 35.3616\n",
      "Epoch 4312/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.0536 - mae: 7.8966 - val_loss: 4108.6558 - val_mae: 35.7423\n",
      "Epoch 4313/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 174.0996 - mae: 7.7459 - val_loss: 4053.7334 - val_mae: 35.4167\n",
      "Epoch 4314/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.2990 - mae: 8.1342 - val_loss: 4148.8604 - val_mae: 36.1261\n",
      "Epoch 4315/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.9663 - mae: 8.0356 - val_loss: 4088.1536 - val_mae: 35.3835\n",
      "Epoch 4316/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.0337 - mae: 8.3074 - val_loss: 4028.7498 - val_mae: 34.8806\n",
      "Epoch 4317/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.4086 - mae: 7.9456 - val_loss: 4054.5747 - val_mae: 34.7457\n",
      "Epoch 4318/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.1816 - mae: 8.0059 - val_loss: 4166.4800 - val_mae: 35.5662\n",
      "Epoch 4319/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 192.1318 - mae: 7.8416 - val_loss: 4218.6084 - val_mae: 35.7533\n",
      "Epoch 4320/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.1579 - mae: 8.3290 - val_loss: 4177.3086 - val_mae: 36.1219\n",
      "Epoch 4321/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 238.2254 - mae: 8.4179 - val_loss: 4138.2583 - val_mae: 35.8058\n",
      "Epoch 4322/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.6297 - mae: 8.2651 - val_loss: 4241.8745 - val_mae: 35.8190\n",
      "Epoch 4323/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.9963 - mae: 7.9661 - val_loss: 4049.5676 - val_mae: 34.9141\n",
      "Epoch 4324/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 474.4391 - mae: 8.8313 - val_loss: 4128.0923 - val_mae: 35.2799\n",
      "Epoch 4325/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.5626 - mae: 8.3802 - val_loss: 3962.5383 - val_mae: 34.4394\n",
      "Epoch 4326/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 295.1585 - mae: 10.1308 - val_loss: 4111.8477 - val_mae: 36.3970\n",
      "Epoch 4327/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 220.4864 - mae: 8.6425 - val_loss: 3982.2427 - val_mae: 35.0849\n",
      "Epoch 4328/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 190.4374 - mae: 8.1601 - val_loss: 4147.5957 - val_mae: 35.8057\n",
      "Epoch 4329/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 266.8247 - mae: 8.4452 - val_loss: 4056.3472 - val_mae: 35.5495\n",
      "Epoch 4330/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.3118 - mae: 8.3679 - val_loss: 4096.0513 - val_mae: 35.4862\n",
      "Epoch 4331/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.7473 - mae: 8.0393 - val_loss: 4171.5112 - val_mae: 35.5967\n",
      "Epoch 4332/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.4773 - mae: 8.2120 - val_loss: 4047.6946 - val_mae: 34.8268\n",
      "Epoch 4333/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 234.9836 - mae: 8.0746 - val_loss: 4052.4470 - val_mae: 35.2761\n",
      "Epoch 4334/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.7729 - mae: 8.2284 - val_loss: 4108.2783 - val_mae: 35.0727\n",
      "Epoch 4335/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.6420 - mae: 8.5588 - val_loss: 4117.1982 - val_mae: 35.2274\n",
      "Epoch 4336/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 234.8582 - mae: 8.2979 - val_loss: 4124.2979 - val_mae: 35.1643\n",
      "Epoch 4337/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 231.2221 - mae: 8.0087 - val_loss: 4060.5327 - val_mae: 34.8676\n",
      "Epoch 4338/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.7609 - mae: 8.2687 - val_loss: 4055.4314 - val_mae: 35.1959\n",
      "Epoch 4339/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 261.6489 - mae: 8.5319 - val_loss: 4191.3047 - val_mae: 35.7637\n",
      "Epoch 4340/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.0834 - mae: 8.0011 - val_loss: 4137.5269 - val_mae: 35.6582\n",
      "Epoch 4341/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 219.5386 - mae: 7.9453 - val_loss: 4077.6873 - val_mae: 35.0808\n",
      "Epoch 4342/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 204.3413 - mae: 8.0782 - val_loss: 4144.2988 - val_mae: 35.3564\n",
      "Epoch 4343/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 182.7949 - mae: 7.8340 - val_loss: 4189.4219 - val_mae: 35.8020\n",
      "Epoch 4344/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.1236 - mae: 8.3400 - val_loss: 4132.9604 - val_mae: 35.6163\n",
      "Epoch 4345/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.3892 - mae: 8.4459 - val_loss: 4117.2988 - val_mae: 35.1147\n",
      "Epoch 4346/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.2370 - mae: 8.2055 - val_loss: 4108.8643 - val_mae: 35.3254\n",
      "Epoch 4347/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.2436 - mae: 8.2336 - val_loss: 4169.1152 - val_mae: 35.6398\n",
      "Epoch 4348/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.1287 - mae: 8.1134 - val_loss: 4183.9297 - val_mae: 36.1929\n",
      "Epoch 4349/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 208.4878 - mae: 8.3557 - val_loss: 4220.7637 - val_mae: 36.0124\n",
      "Epoch 4350/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.8902 - mae: 7.8272 - val_loss: 4122.4209 - val_mae: 35.2971\n",
      "Epoch 4351/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 230.2805 - mae: 8.4129 - val_loss: 4161.4219 - val_mae: 35.2507\n",
      "Epoch 4352/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 210.6907 - mae: 8.1178 - val_loss: 4211.7275 - val_mae: 34.8312\n",
      "Epoch 4353/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.6355 - mae: 8.6845 - val_loss: 4135.2534 - val_mae: 34.9650\n",
      "Epoch 4354/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.5657 - mae: 8.4294 - val_loss: 4190.8115 - val_mae: 36.2187\n",
      "Epoch 4355/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 255.2759 - mae: 8.5319 - val_loss: 4091.9260 - val_mae: 36.1313\n",
      "Epoch 4356/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 231.4705 - mae: 8.4729 - val_loss: 4189.7563 - val_mae: 35.7868\n",
      "Epoch 4357/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 242.0660 - mae: 8.1910 - val_loss: 4124.4375 - val_mae: 35.6756\n",
      "Epoch 4358/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.8012 - mae: 8.0069 - val_loss: 4134.2344 - val_mae: 35.2343\n",
      "Epoch 4359/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.6389 - mae: 7.8106 - val_loss: 4105.2363 - val_mae: 35.1510\n",
      "Epoch 4360/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.3945 - mae: 8.0450 - val_loss: 4136.3853 - val_mae: 35.5220\n",
      "Epoch 4361/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.0016 - mae: 8.3301 - val_loss: 4078.7974 - val_mae: 35.6923\n",
      "Epoch 4362/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.3120 - mae: 7.7166 - val_loss: 4156.0376 - val_mae: 36.2438\n",
      "Epoch 4363/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.4816 - mae: 8.1761 - val_loss: 4152.4233 - val_mae: 35.6469\n",
      "Epoch 4364/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.7666 - mae: 8.0523 - val_loss: 4144.4561 - val_mae: 36.2944\n",
      "Epoch 4365/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.8014 - mae: 7.8368 - val_loss: 4037.9368 - val_mae: 35.0666\n",
      "Epoch 4366/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.5759 - mae: 8.0021 - val_loss: 4093.9785 - val_mae: 35.3884\n",
      "Epoch 4367/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.0399 - mae: 8.1296 - val_loss: 4209.4463 - val_mae: 36.8633\n",
      "Epoch 4368/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 251.8197 - mae: 8.2570 - val_loss: 4179.5527 - val_mae: 35.9062\n",
      "Epoch 4369/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.2693 - mae: 7.7079 - val_loss: 4229.3481 - val_mae: 35.9587\n",
      "Epoch 4370/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.0519 - mae: 7.8819 - val_loss: 4225.2080 - val_mae: 35.8715\n",
      "Epoch 4371/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.7428 - mae: 8.0890 - val_loss: 4132.5757 - val_mae: 35.5948\n",
      "Epoch 4372/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.1438 - mae: 7.7851 - val_loss: 4158.5957 - val_mae: 35.7357\n",
      "Epoch 4373/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 157.4082 - mae: 7.6378 - val_loss: 4163.2236 - val_mae: 35.9252\n",
      "Epoch 4374/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.8137 - mae: 8.3147 - val_loss: 4175.9692 - val_mae: 35.5062\n",
      "Epoch 4375/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.7395 - mae: 8.2788 - val_loss: 4118.3711 - val_mae: 35.4388\n",
      "Epoch 4376/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.4129 - mae: 8.2461 - val_loss: 4205.9048 - val_mae: 36.3407\n",
      "Epoch 4377/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.6616 - mae: 7.7578 - val_loss: 4265.5591 - val_mae: 36.1648\n",
      "Epoch 4378/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.5960 - mae: 7.8257 - val_loss: 4268.9771 - val_mae: 35.9895\n",
      "Epoch 4379/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.3660 - mae: 8.0312 - val_loss: 4221.9014 - val_mae: 36.3706\n",
      "Epoch 4380/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.1854 - mae: 7.8235 - val_loss: 4191.7510 - val_mae: 35.5583\n",
      "Epoch 4381/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 215.3298 - mae: 8.1346 - val_loss: 4171.6416 - val_mae: 35.2282\n",
      "Epoch 4382/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.7500 - mae: 8.0846 - val_loss: 4169.0293 - val_mae: 35.3710\n",
      "Epoch 4383/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 229.4146 - mae: 8.4871 - val_loss: 4300.9116 - val_mae: 36.2825\n",
      "Epoch 4384/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.9989 - mae: 8.3854 - val_loss: 4302.4946 - val_mae: 36.3187\n",
      "Epoch 4385/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.1120 - mae: 7.8848 - val_loss: 4239.9443 - val_mae: 35.9857\n",
      "Epoch 4386/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.5356 - mae: 7.9964 - val_loss: 4238.7388 - val_mae: 36.1897\n",
      "Epoch 4387/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.6598 - mae: 8.1821 - val_loss: 4221.6538 - val_mae: 35.8483\n",
      "Epoch 4388/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.3780 - mae: 8.3875 - val_loss: 4218.5669 - val_mae: 36.1008\n",
      "Epoch 4389/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.1059 - mae: 8.6179 - val_loss: 4125.4204 - val_mae: 35.6738\n",
      "Epoch 4390/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.6880 - mae: 8.6046 - val_loss: 4250.4341 - val_mae: 36.1575\n",
      "Epoch 4391/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.1117 - mae: 8.1933 - val_loss: 4206.3511 - val_mae: 35.7966\n",
      "Epoch 4392/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.0898 - mae: 8.0358 - val_loss: 4189.5542 - val_mae: 35.9651\n",
      "Epoch 4393/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.6667 - mae: 8.2311 - val_loss: 4230.5679 - val_mae: 35.9176\n",
      "Epoch 4394/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.5447 - mae: 8.6318 - val_loss: 4122.5703 - val_mae: 35.6432\n",
      "Epoch 4395/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.6581 - mae: 8.7624 - val_loss: 4134.0562 - val_mae: 36.0947\n",
      "Epoch 4396/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.2572 - mae: 8.5211 - val_loss: 4207.3188 - val_mae: 36.3156\n",
      "Epoch 4397/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.2675 - mae: 8.2442 - val_loss: 4019.9473 - val_mae: 35.0773\n",
      "Epoch 4398/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.0434 - mae: 8.3631 - val_loss: 4082.9961 - val_mae: 35.5596\n",
      "Epoch 4399/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.9037 - mae: 8.4482 - val_loss: 4164.2021 - val_mae: 36.0213\n",
      "Epoch 4400/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.2849 - mae: 8.0505 - val_loss: 4023.4238 - val_mae: 35.2170\n",
      "Epoch 4401/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.0007 - mae: 8.2042 - val_loss: 4089.0803 - val_mae: 35.3203\n",
      "Epoch 4402/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.4754 - mae: 8.3538 - val_loss: 4011.8501 - val_mae: 35.3209\n",
      "Epoch 4403/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.7807 - mae: 8.2055 - val_loss: 4009.1494 - val_mae: 35.8437\n",
      "Epoch 4404/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.4554 - mae: 8.2427 - val_loss: 4107.3574 - val_mae: 35.9040\n",
      "Epoch 4405/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 196.0885 - mae: 8.1064 - val_loss: 4078.8398 - val_mae: 35.9573\n",
      "Epoch 4406/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 175.1169 - mae: 7.9575 - val_loss: 4113.1670 - val_mae: 35.4864\n",
      "Epoch 4407/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.3003 - mae: 8.2776 - val_loss: 4039.5847 - val_mae: 35.3237\n",
      "Epoch 4408/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.8544 - mae: 8.1462 - val_loss: 4183.0845 - val_mae: 36.1246\n",
      "Epoch 4409/10000\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 235.9958 - mae: 8.1793 - val_loss: 4125.2842 - val_mae: 36.0149\n",
      "Epoch 4410/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.2755 - mae: 8.2364 - val_loss: 4046.8579 - val_mae: 35.8776\n",
      "Epoch 4411/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.5005 - mae: 7.8831 - val_loss: 4159.1655 - val_mae: 36.0720\n",
      "Epoch 4412/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.8857 - mae: 7.9867 - val_loss: 4117.4668 - val_mae: 36.4121\n",
      "Epoch 4413/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.3434 - mae: 8.1309 - val_loss: 4050.6509 - val_mae: 35.8606\n",
      "Epoch 4414/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.9653 - mae: 7.7528 - val_loss: 4120.3740 - val_mae: 35.9351\n",
      "Epoch 4415/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.2758 - mae: 7.9781 - val_loss: 4135.9834 - val_mae: 36.9671\n",
      "Epoch 4416/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 265.9280 - mae: 8.6345 - val_loss: 4164.5088 - val_mae: 36.1007\n",
      "Epoch 4417/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.4166 - mae: 8.0011 - val_loss: 4131.1826 - val_mae: 35.7262\n",
      "Epoch 4418/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.4424 - mae: 7.8822 - val_loss: 4145.7422 - val_mae: 35.8365\n",
      "Epoch 4419/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.2870 - mae: 7.8504 - val_loss: 4112.4766 - val_mae: 35.6844\n",
      "Epoch 4420/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.7693 - mae: 8.0336 - val_loss: 4211.1533 - val_mae: 35.9757\n",
      "Epoch 4421/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.8921 - mae: 7.6896 - val_loss: 4053.0400 - val_mae: 35.7180\n",
      "Epoch 4422/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.1482 - mae: 8.9771 - val_loss: 4162.1255 - val_mae: 35.5804\n",
      "Epoch 4423/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.1976 - mae: 7.7858 - val_loss: 4145.4375 - val_mae: 36.0800\n",
      "Epoch 4424/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.1072 - mae: 7.8428 - val_loss: 4143.9756 - val_mae: 36.0395\n",
      "Epoch 4425/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.0188 - mae: 8.0953 - val_loss: 4186.6138 - val_mae: 36.4714\n",
      "Epoch 4426/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.2233 - mae: 7.7853 - val_loss: 4127.1543 - val_mae: 35.2989\n",
      "Epoch 4427/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.5598 - mae: 7.8700 - val_loss: 4147.5078 - val_mae: 35.8447\n",
      "Epoch 4428/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.7041 - mae: 7.6942 - val_loss: 4155.5552 - val_mae: 35.7626\n",
      "Epoch 4429/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.6825 - mae: 7.8782 - val_loss: 4102.5674 - val_mae: 35.6257\n",
      "Epoch 4430/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.5690 - mae: 7.9708 - val_loss: 4078.3716 - val_mae: 35.7612\n",
      "Epoch 4431/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 147.3678 - mae: 7.5163 - val_loss: 4136.4912 - val_mae: 35.4626\n",
      "Epoch 4432/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.2056 - mae: 7.7540 - val_loss: 4205.5146 - val_mae: 36.0963\n",
      "Epoch 4433/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.8587 - mae: 7.9676 - val_loss: 4154.6938 - val_mae: 35.5426\n",
      "Epoch 4434/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.5558 - mae: 8.2307 - val_loss: 4118.0986 - val_mae: 35.5854\n",
      "Epoch 4435/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.2025 - mae: 8.2774 - val_loss: 4106.1289 - val_mae: 35.1574\n",
      "Epoch 4436/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.7031 - mae: 8.1028 - val_loss: 4039.9250 - val_mae: 34.9450\n",
      "Epoch 4437/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.3998 - mae: 8.0356 - val_loss: 4064.7268 - val_mae: 34.9888\n",
      "Epoch 4438/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.1974 - mae: 8.1254 - val_loss: 4076.4370 - val_mae: 35.3107\n",
      "Epoch 4439/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.4574 - mae: 8.1803 - val_loss: 4030.3328 - val_mae: 34.6314\n",
      "Epoch 4440/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.4713 - mae: 8.1767 - val_loss: 4086.3167 - val_mae: 35.3304\n",
      "Epoch 4441/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.2316 - mae: 8.2699 - val_loss: 4150.9912 - val_mae: 35.3418\n",
      "Epoch 4442/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.3205 - mae: 8.0672 - val_loss: 4193.1553 - val_mae: 36.4668\n",
      "Epoch 4443/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.5795 - mae: 8.5052 - val_loss: 4219.9609 - val_mae: 35.5544\n",
      "Epoch 4444/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 240.2239 - mae: 8.2720 - val_loss: 4223.2144 - val_mae: 35.7198\n",
      "Epoch 4445/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.8425 - mae: 8.3934 - val_loss: 4188.2383 - val_mae: 35.7457\n",
      "Epoch 4446/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.1804 - mae: 8.2641 - val_loss: 4125.5674 - val_mae: 35.2555\n",
      "Epoch 4447/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 179.3694 - mae: 7.9714 - val_loss: 4186.8745 - val_mae: 35.1352\n",
      "Epoch 4448/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 253.1807 - mae: 8.6259 - val_loss: 4151.2783 - val_mae: 35.7332\n",
      "Epoch 4449/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 303.4707 - mae: 8.5845 - val_loss: 4088.7559 - val_mae: 36.0014\n",
      "Epoch 4450/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.9000 - mae: 8.0421 - val_loss: 4127.6353 - val_mae: 35.4296\n",
      "Epoch 4451/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.1266 - mae: 8.0001 - val_loss: 4183.1333 - val_mae: 35.5691\n",
      "Epoch 4452/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.1780 - mae: 7.9351 - val_loss: 4144.2212 - val_mae: 35.2381\n",
      "Epoch 4453/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.1669 - mae: 8.0106 - val_loss: 4139.9609 - val_mae: 35.6028\n",
      "Epoch 4454/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.1342 - mae: 8.2256 - val_loss: 4186.6333 - val_mae: 35.7614\n",
      "Epoch 4455/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.2214 - mae: 7.8625 - val_loss: 4167.3760 - val_mae: 35.2962\n",
      "Epoch 4456/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.0564 - mae: 8.3016 - val_loss: 4194.6572 - val_mae: 34.9385\n",
      "Epoch 4457/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.7060 - mae: 7.9622 - val_loss: 4145.3643 - val_mae: 35.6281\n",
      "Epoch 4458/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.1100 - mae: 7.6892 - val_loss: 4160.4419 - val_mae: 35.8388\n",
      "Epoch 4459/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.6426 - mae: 8.0221 - val_loss: 4181.7583 - val_mae: 35.6258\n",
      "Epoch 4460/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.1827 - mae: 7.8584 - val_loss: 4258.4751 - val_mae: 36.0770\n",
      "Epoch 4461/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.3635 - mae: 7.8474 - val_loss: 4181.6670 - val_mae: 35.8649\n",
      "Epoch 4462/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.1470 - mae: 7.7807 - val_loss: 4236.7617 - val_mae: 36.0185\n",
      "Epoch 4463/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.0252 - mae: 8.1555 - val_loss: 4193.1240 - val_mae: 36.0898\n",
      "Epoch 4464/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.3201 - mae: 7.9482 - val_loss: 4258.8799 - val_mae: 36.3849\n",
      "Epoch 4465/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.9282 - mae: 8.1158 - val_loss: 4215.2134 - val_mae: 36.7033\n",
      "Epoch 4466/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.5583 - mae: 7.9182 - val_loss: 4203.7163 - val_mae: 35.9695\n",
      "Epoch 4467/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.5624 - mae: 8.1022 - val_loss: 4191.0840 - val_mae: 36.7110\n",
      "Epoch 4468/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.6957 - mae: 8.2197 - val_loss: 4184.2397 - val_mae: 36.0028\n",
      "Epoch 4469/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.7652 - mae: 7.8163 - val_loss: 4253.4897 - val_mae: 36.1826\n",
      "Epoch 4470/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.1191 - mae: 7.8033 - val_loss: 4221.9746 - val_mae: 36.3383\n",
      "Epoch 4471/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.6871 - mae: 8.0633 - val_loss: 4234.4111 - val_mae: 35.9506\n",
      "Epoch 4472/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.8626 - mae: 7.8132 - val_loss: 4211.9468 - val_mae: 36.1734\n",
      "Epoch 4473/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.5596 - mae: 7.9013 - val_loss: 4205.6929 - val_mae: 35.9405\n",
      "Epoch 4474/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.2750 - mae: 8.1260 - val_loss: 4136.3521 - val_mae: 35.8597\n",
      "Epoch 4475/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.4828 - mae: 7.5991 - val_loss: 4268.2075 - val_mae: 36.2351\n",
      "Epoch 4476/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 170.1356 - mae: 7.5741 - val_loss: 4193.2520 - val_mae: 36.2650\n",
      "Epoch 4477/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 179.6275 - mae: 7.8376 - val_loss: 4209.9980 - val_mae: 36.0814\n",
      "Epoch 4478/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 173.5358 - mae: 7.6612 - val_loss: 4140.8042 - val_mae: 35.6552\n",
      "Epoch 4479/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 186.7181 - mae: 7.9900 - val_loss: 4222.9287 - val_mae: 36.3611\n",
      "Epoch 4480/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 183.0102 - mae: 7.6819 - val_loss: 4136.8340 - val_mae: 35.5218\n",
      "Epoch 4481/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.1037 - mae: 7.9237 - val_loss: 4215.9243 - val_mae: 35.4658\n",
      "Epoch 4482/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.4636 - mae: 8.0622 - val_loss: 4197.7393 - val_mae: 35.4437\n",
      "Epoch 4483/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.1436 - mae: 7.8738 - val_loss: 4197.1523 - val_mae: 35.9753\n",
      "Epoch 4484/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.7755 - mae: 7.8622 - val_loss: 4212.9819 - val_mae: 35.9901\n",
      "Epoch 4485/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.9037 - mae: 7.9194 - val_loss: 4258.4087 - val_mae: 36.0541\n",
      "Epoch 4486/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 180.2789 - mae: 7.9690 - val_loss: 4162.4468 - val_mae: 36.3478\n",
      "Epoch 4487/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.0763 - mae: 8.0454 - val_loss: 4235.3379 - val_mae: 36.6859\n",
      "Epoch 4488/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 225.9889 - mae: 8.1857 - val_loss: 4226.3770 - val_mae: 36.0511\n",
      "Epoch 4489/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 229.1175 - mae: 8.2030 - val_loss: 4246.3384 - val_mae: 36.4663\n",
      "Epoch 4490/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 197.9763 - mae: 7.8229 - val_loss: 4242.6284 - val_mae: 35.9730\n",
      "Epoch 4491/10000\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 166.2115 - mae: 7.6917 - val_loss: 4225.3984 - val_mae: 36.2470\n",
      "Epoch 4492/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 218.4223 - mae: 8.1308 - val_loss: 4237.6553 - val_mae: 35.8517\n",
      "Epoch 4493/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 199.0259 - mae: 7.9820 - val_loss: 4331.0620 - val_mae: 36.8698\n",
      "Epoch 4494/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 202.3524 - mae: 7.9510 - val_loss: 4175.2095 - val_mae: 36.1983\n",
      "Epoch 4495/10000\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 192.4978 - mae: 8.0214 - val_loss: 4230.3457 - val_mae: 36.4406\n",
      "Epoch 4496/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 173.1857 - mae: 7.6829 - val_loss: 4213.3931 - val_mae: 36.0288\n",
      "Epoch 4497/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 195.9424 - mae: 8.0670 - val_loss: 4220.7803 - val_mae: 35.6350\n",
      "Epoch 4498/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 210.1362 - mae: 8.2041 - val_loss: 4166.0435 - val_mae: 36.2708\n",
      "Epoch 4499/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.9867 - mae: 8.2663 - val_loss: 4268.4058 - val_mae: 36.5443\n",
      "Epoch 4500/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 230.0765 - mae: 8.4811 - val_loss: 4280.2920 - val_mae: 36.2804\n",
      "Epoch 4501/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.8018 - mae: 8.4929 - val_loss: 4304.5288 - val_mae: 36.3043\n",
      "Epoch 4502/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.5722 - mae: 8.4467 - val_loss: 4348.2998 - val_mae: 37.7985\n",
      "Epoch 4503/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.6155 - mae: 8.0902 - val_loss: 4297.5078 - val_mae: 36.6471\n",
      "Epoch 4504/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.8008 - mae: 8.0613 - val_loss: 4286.7837 - val_mae: 36.2453\n",
      "Epoch 4505/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.2668 - mae: 7.9773 - val_loss: 4226.5259 - val_mae: 36.1591\n",
      "Epoch 4506/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.3004 - mae: 7.9276 - val_loss: 4356.1187 - val_mae: 36.4943\n",
      "Epoch 4507/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2887 - mae: 8.0153 - val_loss: 4200.3086 - val_mae: 35.9775\n",
      "Epoch 4508/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.6393 - mae: 7.9852 - val_loss: 4235.3140 - val_mae: 35.5105\n",
      "Epoch 4509/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.6111 - mae: 7.6230 - val_loss: 4161.4995 - val_mae: 35.6506\n",
      "Epoch 4510/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.6583 - mae: 7.7956 - val_loss: 4226.2412 - val_mae: 35.6309\n",
      "Epoch 4511/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.8389 - mae: 8.1096 - val_loss: 4210.1172 - val_mae: 35.6125\n",
      "Epoch 4512/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.6700 - mae: 8.0311 - val_loss: 4132.4355 - val_mae: 35.6210\n",
      "Epoch 4513/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.9632 - mae: 8.3128 - val_loss: 4390.7344 - val_mae: 36.6223\n",
      "Epoch 4514/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.2932 - mae: 7.5581 - val_loss: 4271.7466 - val_mae: 36.1376\n",
      "Epoch 4515/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.1456 - mae: 7.8480 - val_loss: 4280.7334 - val_mae: 36.4355\n",
      "Epoch 4516/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.9850 - mae: 7.7855 - val_loss: 4400.5967 - val_mae: 36.6435\n",
      "Epoch 4517/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.0996 - mae: 8.1095 - val_loss: 4369.6436 - val_mae: 36.5071\n",
      "Epoch 4518/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.9011 - mae: 7.9450 - val_loss: 4381.9263 - val_mae: 36.5443\n",
      "Epoch 4519/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.1364 - mae: 7.6930 - val_loss: 4295.6538 - val_mae: 36.3903\n",
      "Epoch 4520/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.5039 - mae: 7.6941 - val_loss: 4272.0107 - val_mae: 36.9175\n",
      "Epoch 4521/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.7030 - mae: 7.8747 - val_loss: 4170.9312 - val_mae: 36.2902\n",
      "Epoch 4522/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.5264 - mae: 8.1280 - val_loss: 4231.5879 - val_mae: 35.7188\n",
      "Epoch 4523/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.8882 - mae: 8.2292 - val_loss: 4317.1875 - val_mae: 36.0070\n",
      "Epoch 4524/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.1500 - mae: 7.7542 - val_loss: 4259.5820 - val_mae: 36.2190\n",
      "Epoch 4525/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.1468 - mae: 7.7132 - val_loss: 4255.0708 - val_mae: 36.0391\n",
      "Epoch 4526/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.5499 - mae: 7.6871 - val_loss: 4231.6445 - val_mae: 36.1779\n",
      "Epoch 4527/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.5475 - mae: 7.7965 - val_loss: 4240.9741 - val_mae: 35.9047\n",
      "Epoch 4528/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.7492 - mae: 7.8819 - val_loss: 4274.1733 - val_mae: 35.5766\n",
      "Epoch 4529/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.7044 - mae: 7.5500 - val_loss: 4120.9155 - val_mae: 34.8501\n",
      "Epoch 4530/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.6781 - mae: 7.8189 - val_loss: 4138.3994 - val_mae: 35.6429\n",
      "Epoch 4531/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.0349 - mae: 7.7216 - val_loss: 4108.4614 - val_mae: 35.0468\n",
      "Epoch 4532/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.5502 - mae: 7.9071 - val_loss: 3939.7651 - val_mae: 34.5332\n",
      "Epoch 4533/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.2542 - mae: 7.7304 - val_loss: 4138.3398 - val_mae: 35.8766\n",
      "Epoch 4534/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.9484 - mae: 8.0639 - val_loss: 4051.6702 - val_mae: 35.1094\n",
      "Epoch 4535/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.4585 - mae: 7.8396 - val_loss: 4297.7466 - val_mae: 35.6584\n",
      "Epoch 4536/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.3778 - mae: 7.9697 - val_loss: 4244.3838 - val_mae: 35.8433\n",
      "Epoch 4537/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.7550 - mae: 8.0885 - val_loss: 4201.2910 - val_mae: 36.2326\n",
      "Epoch 4538/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.6540 - mae: 8.2968 - val_loss: 4195.1348 - val_mae: 35.8523\n",
      "Epoch 4539/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 164.5185 - mae: 7.5888 - val_loss: 4162.8159 - val_mae: 35.5638\n",
      "Epoch 4540/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.4671 - mae: 7.8754 - val_loss: 4106.0791 - val_mae: 35.2381\n",
      "Epoch 4541/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.1743 - mae: 7.7877 - val_loss: 4142.0220 - val_mae: 35.3945\n",
      "Epoch 4542/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.6629 - mae: 7.7250 - val_loss: 4226.4419 - val_mae: 35.7674\n",
      "Epoch 4543/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.8611 - mae: 8.0611 - val_loss: 4179.0347 - val_mae: 35.9153\n",
      "Epoch 4544/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.7822 - mae: 7.8193 - val_loss: 4136.7988 - val_mae: 35.6126\n",
      "Epoch 4545/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 220.0883 - mae: 8.1028 - val_loss: 4140.7778 - val_mae: 35.4520\n",
      "Epoch 4546/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 182.1260 - mae: 7.4839 - val_loss: 4095.9287 - val_mae: 35.9072\n",
      "Epoch 4547/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 244.2539 - mae: 8.4594 - val_loss: 4110.9878 - val_mae: 35.5744\n",
      "Epoch 4548/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 160.3983 - mae: 7.8387 - val_loss: 4122.2036 - val_mae: 36.8236\n",
      "Epoch 4549/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.8394 - mae: 8.2006 - val_loss: 4133.4077 - val_mae: 35.2212\n",
      "Epoch 4550/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.8360 - mae: 8.0471 - val_loss: 4107.4580 - val_mae: 35.4783\n",
      "Epoch 4551/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.4624 - mae: 8.0126 - val_loss: 4056.1643 - val_mae: 35.3621\n",
      "Epoch 4552/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 155.8539 - mae: 7.4967 - val_loss: 4145.7085 - val_mae: 35.4060\n",
      "Epoch 4553/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 194.7346 - mae: 7.5173 - val_loss: 4179.6431 - val_mae: 35.7069\n",
      "Epoch 4554/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.8377 - mae: 7.9796 - val_loss: 4115.8213 - val_mae: 35.5845\n",
      "Epoch 4555/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.6957 - mae: 7.7189 - val_loss: 4104.0933 - val_mae: 35.3012\n",
      "Epoch 4556/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2067 - mae: 7.9062 - val_loss: 4186.9741 - val_mae: 35.6064\n",
      "Epoch 4557/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.3232 - mae: 8.0595 - val_loss: 4155.3228 - val_mae: 35.8075\n",
      "Epoch 4558/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.8871 - mae: 8.0180 - val_loss: 4158.6660 - val_mae: 35.2388\n",
      "Epoch 4559/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.8025 - mae: 8.1095 - val_loss: 4179.2832 - val_mae: 35.7653\n",
      "Epoch 4560/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 159.3354 - mae: 7.4439 - val_loss: 4136.5684 - val_mae: 35.6455\n",
      "Epoch 4561/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.5311 - mae: 7.6917 - val_loss: 4118.1978 - val_mae: 35.5161\n",
      "Epoch 4562/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.9145 - mae: 7.5863 - val_loss: 4110.4238 - val_mae: 35.2934\n",
      "Epoch 4563/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 168.7592 - mae: 7.7054 - val_loss: 4048.2070 - val_mae: 35.2608\n",
      "Epoch 4564/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.0067 - mae: 8.1137 - val_loss: 4029.2366 - val_mae: 35.4035\n",
      "Epoch 4565/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.2744 - mae: 7.9779 - val_loss: 4203.9985 - val_mae: 35.5393\n",
      "Epoch 4566/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.9613 - mae: 7.9334 - val_loss: 4123.2041 - val_mae: 35.2409\n",
      "Epoch 4567/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.6240 - mae: 7.7099 - val_loss: 4067.8027 - val_mae: 35.7032\n",
      "Epoch 4568/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.4142 - mae: 7.8424 - val_loss: 4218.5371 - val_mae: 35.8021\n",
      "Epoch 4569/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.2362 - mae: 7.6908 - val_loss: 4175.2827 - val_mae: 35.5679\n",
      "Epoch 4570/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.1674 - mae: 7.5786 - val_loss: 4174.7007 - val_mae: 35.6419\n",
      "Epoch 4571/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.2051 - mae: 7.7329 - val_loss: 4197.8496 - val_mae: 35.6740\n",
      "Epoch 4572/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.2047 - mae: 7.5826 - val_loss: 4175.3184 - val_mae: 35.4981\n",
      "Epoch 4573/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.9232 - mae: 7.7443 - val_loss: 4163.8838 - val_mae: 35.4366\n",
      "Epoch 4574/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.2995 - mae: 7.7657 - val_loss: 4095.6528 - val_mae: 35.4089\n",
      "Epoch 4575/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.5812 - mae: 7.8341 - val_loss: 4276.6519 - val_mae: 35.8915\n",
      "Epoch 4576/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.9898 - mae: 8.2255 - val_loss: 4108.0576 - val_mae: 35.5588\n",
      "Epoch 4577/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.9787 - mae: 8.0352 - val_loss: 4115.7324 - val_mae: 35.4844\n",
      "Epoch 4578/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.1817 - mae: 7.8952 - val_loss: 4006.0356 - val_mae: 35.8702\n",
      "Epoch 4579/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.0912 - mae: 8.4736 - val_loss: 4139.3770 - val_mae: 36.1289\n",
      "Epoch 4580/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.0713 - mae: 8.2358 - val_loss: 4214.4868 - val_mae: 36.4254\n",
      "Epoch 4581/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.2761 - mae: 8.3084 - val_loss: 4190.5752 - val_mae: 35.8346\n",
      "Epoch 4582/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.7742 - mae: 8.3057 - val_loss: 4174.1357 - val_mae: 35.4834\n",
      "Epoch 4583/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.9511 - mae: 8.3871 - val_loss: 4461.8218 - val_mae: 37.0866\n",
      "Epoch 4584/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 262.9609 - mae: 8.5328 - val_loss: 4298.6426 - val_mae: 36.5243\n",
      "Epoch 4585/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 259.6059 - mae: 8.6953 - val_loss: 4232.8384 - val_mae: 35.9061\n",
      "Epoch 4586/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 250.7743 - mae: 8.3047 - val_loss: 4248.4165 - val_mae: 35.7802\n",
      "Epoch 4587/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2602 - mae: 8.3129 - val_loss: 4129.9727 - val_mae: 35.0856\n",
      "Epoch 4588/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.1341 - mae: 8.4356 - val_loss: 4175.5679 - val_mae: 35.3763\n",
      "Epoch 4589/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.8156 - mae: 8.1681 - val_loss: 4208.2720 - val_mae: 35.5495\n",
      "Epoch 4590/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.7859 - mae: 8.0838 - val_loss: 4160.3452 - val_mae: 35.3943\n",
      "Epoch 4591/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 247.6947 - mae: 8.5212 - val_loss: 4123.1133 - val_mae: 35.8418\n",
      "Epoch 4592/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.1508 - mae: 8.2505 - val_loss: 4001.3352 - val_mae: 35.1967\n",
      "Epoch 4593/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.7642 - mae: 8.0079 - val_loss: 4186.8203 - val_mae: 35.5849\n",
      "Epoch 4594/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.5388 - mae: 8.1476 - val_loss: 4121.6426 - val_mae: 35.2090\n",
      "Epoch 4595/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 199.1788 - mae: 7.9122 - val_loss: 4060.5657 - val_mae: 35.0810\n",
      "Epoch 4596/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.2522 - mae: 8.0875 - val_loss: 4114.6382 - val_mae: 35.2734\n",
      "Epoch 4597/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.4109 - mae: 8.0303 - val_loss: 4155.3340 - val_mae: 35.7789\n",
      "Epoch 4598/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 164.5648 - mae: 7.6453 - val_loss: 4064.8164 - val_mae: 35.8159\n",
      "Epoch 4599/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.7054 - mae: 7.8483 - val_loss: 4037.6799 - val_mae: 35.6605\n",
      "Epoch 4600/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.8444 - mae: 8.0286 - val_loss: 4080.8867 - val_mae: 35.0891\n",
      "Epoch 4601/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.7261 - mae: 8.2011 - val_loss: 4063.6045 - val_mae: 36.3311\n",
      "Epoch 4602/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.8728 - mae: 7.7659 - val_loss: 3997.8479 - val_mae: 35.0986\n",
      "Epoch 4603/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.7388 - mae: 7.7736 - val_loss: 4061.8113 - val_mae: 35.1510\n",
      "Epoch 4604/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 164.1989 - mae: 7.5417 - val_loss: 4064.1846 - val_mae: 35.0960\n",
      "Epoch 4605/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.1791 - mae: 8.0972 - val_loss: 3985.6052 - val_mae: 34.7469\n",
      "Epoch 4606/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.1733 - mae: 7.6534 - val_loss: 4022.1116 - val_mae: 35.0847\n",
      "Epoch 4607/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.3905 - mae: 8.0331 - val_loss: 4029.9727 - val_mae: 34.6473\n",
      "Epoch 4608/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.1144 - mae: 7.6981 - val_loss: 4131.3413 - val_mae: 35.7950\n",
      "Epoch 4609/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 162.3738 - mae: 7.7670 - val_loss: 4093.5200 - val_mae: 35.2896\n",
      "Epoch 4610/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 164.7224 - mae: 7.6664 - val_loss: 4047.2637 - val_mae: 34.7061\n",
      "Epoch 4611/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.4276 - mae: 7.6644 - val_loss: 4048.3940 - val_mae: 35.3835\n",
      "Epoch 4612/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 159.5423 - mae: 7.5207 - val_loss: 4022.3328 - val_mae: 34.6544\n",
      "Epoch 4613/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.7729 - mae: 7.6277 - val_loss: 4158.4790 - val_mae: 35.3922\n",
      "Epoch 4614/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.1678 - mae: 7.9162 - val_loss: 4050.4885 - val_mae: 35.3932\n",
      "Epoch 4615/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.9096 - mae: 7.8113 - val_loss: 4132.7930 - val_mae: 35.2404\n",
      "Epoch 4616/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.5783 - mae: 7.6089 - val_loss: 4165.3027 - val_mae: 35.9649\n",
      "Epoch 4617/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.7141 - mae: 7.7218 - val_loss: 4090.1501 - val_mae: 35.6908\n",
      "Epoch 4618/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.7125 - mae: 7.7864 - val_loss: 4199.5557 - val_mae: 35.7517\n",
      "Epoch 4619/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.7614 - mae: 7.6058 - val_loss: 4200.9497 - val_mae: 35.7216\n",
      "Epoch 4620/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 150.6205 - mae: 7.5577 - val_loss: 4266.7295 - val_mae: 36.6941\n",
      "Epoch 4621/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.5191 - mae: 7.9644 - val_loss: 4140.4292 - val_mae: 35.8466\n",
      "Epoch 4622/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.3146 - mae: 8.0627 - val_loss: 4090.0984 - val_mae: 35.1347\n",
      "Epoch 4623/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 158.9353 - mae: 7.5423 - val_loss: 4160.0718 - val_mae: 35.2949\n",
      "Epoch 4624/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.5478 - mae: 7.6663 - val_loss: 4217.8423 - val_mae: 36.0304\n",
      "Epoch 4625/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 241.7805 - mae: 8.1074 - val_loss: 4131.3589 - val_mae: 35.4106\n",
      "Epoch 4626/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.2467 - mae: 7.7499 - val_loss: 4139.4297 - val_mae: 35.7541\n",
      "Epoch 4627/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.3902 - mae: 7.5355 - val_loss: 4153.4507 - val_mae: 35.6598\n",
      "Epoch 4628/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.7765 - mae: 7.4945 - val_loss: 4004.5852 - val_mae: 35.3765\n",
      "Epoch 4629/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.8475 - mae: 7.3923 - val_loss: 4027.3972 - val_mae: 35.8942\n",
      "Epoch 4630/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.1784 - mae: 7.8012 - val_loss: 4099.9600 - val_mae: 35.6229\n",
      "Epoch 4631/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.5048 - mae: 7.3904 - val_loss: 4018.9202 - val_mae: 35.5763\n",
      "Epoch 4632/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.8736 - mae: 7.7895 - val_loss: 3960.8645 - val_mae: 35.1615\n",
      "Epoch 4633/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 154.1198 - mae: 7.4280 - val_loss: 4191.3418 - val_mae: 36.1090\n",
      "Epoch 4634/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.3882 - mae: 7.8222 - val_loss: 4186.3872 - val_mae: 36.1303\n",
      "Epoch 4635/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.2208 - mae: 7.5548 - val_loss: 4144.3486 - val_mae: 35.3410\n",
      "Epoch 4636/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 188.7083 - mae: 7.8342 - val_loss: 4129.7764 - val_mae: 35.6220\n",
      "Epoch 4637/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 151.9154 - mae: 7.5028 - val_loss: 4140.7725 - val_mae: 35.0218\n",
      "Epoch 4638/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.6991 - mae: 7.7241 - val_loss: 4063.0042 - val_mae: 35.9699\n",
      "Epoch 4639/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 215.7517 - mae: 8.0703 - val_loss: 4047.0640 - val_mae: 35.1846\n",
      "Epoch 4640/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 218.1948 - mae: 8.1928 - val_loss: 4000.8569 - val_mae: 35.5879\n",
      "Epoch 4641/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 153.5918 - mae: 7.6114 - val_loss: 4120.8418 - val_mae: 35.1091\n",
      "Epoch 4642/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 162.3263 - mae: 7.4925 - val_loss: 4075.5623 - val_mae: 35.3404\n",
      "Epoch 4643/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 192.9445 - mae: 7.8552 - val_loss: 4135.1846 - val_mae: 35.4911\n",
      "Epoch 4644/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 218.7254 - mae: 8.0362 - val_loss: 4133.2769 - val_mae: 35.6715\n",
      "Epoch 4645/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.5569 - mae: 7.7057 - val_loss: 4090.5859 - val_mae: 35.3680\n",
      "Epoch 4646/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.1399 - mae: 7.6417 - val_loss: 4142.4287 - val_mae: 35.8276\n",
      "Epoch 4647/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.2302 - mae: 7.6403 - val_loss: 4041.1038 - val_mae: 35.5402\n",
      "Epoch 4648/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.7525 - mae: 7.7276 - val_loss: 4195.6577 - val_mae: 35.7280\n",
      "Epoch 4649/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 162.7633 - mae: 7.6030 - val_loss: 4179.7319 - val_mae: 35.6613\n",
      "Epoch 4650/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.0009 - mae: 7.8770 - val_loss: 4118.1919 - val_mae: 36.3195\n",
      "Epoch 4651/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.3936 - mae: 7.6605 - val_loss: 4082.0242 - val_mae: 36.2362\n",
      "Epoch 4652/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.3305 - mae: 7.5085 - val_loss: 4172.8418 - val_mae: 35.7008\n",
      "Epoch 4653/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.7646 - mae: 7.5467 - val_loss: 4185.8872 - val_mae: 35.6669\n",
      "Epoch 4654/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.2002 - mae: 7.6309 - val_loss: 4146.9336 - val_mae: 35.3520\n",
      "Epoch 4655/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 155.5178 - mae: 7.6844 - val_loss: 4142.3301 - val_mae: 35.9471\n",
      "Epoch 4656/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 163.6053 - mae: 7.5949 - val_loss: 4015.9165 - val_mae: 35.6322\n",
      "Epoch 4657/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.7881 - mae: 7.6047 - val_loss: 4074.4990 - val_mae: 35.3327\n",
      "Epoch 4658/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 153.0923 - mae: 7.3863 - val_loss: 4147.8291 - val_mae: 35.6498\n",
      "Epoch 4659/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 141.1771 - mae: 7.3926 - val_loss: 4086.7812 - val_mae: 35.6447\n",
      "Epoch 4660/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 162.3527 - mae: 7.7133 - val_loss: 4036.8579 - val_mae: 35.3929\n",
      "Epoch 4661/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.3540 - mae: 7.7186 - val_loss: 4096.1191 - val_mae: 35.6366\n",
      "Epoch 4662/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.2816 - mae: 7.7584 - val_loss: 4020.8381 - val_mae: 35.0413\n",
      "Epoch 4663/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.8415 - mae: 7.5952 - val_loss: 3991.9390 - val_mae: 34.7168\n",
      "Epoch 4664/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.6291 - mae: 7.6537 - val_loss: 4035.9521 - val_mae: 35.1989\n",
      "Epoch 4665/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 165.5272 - mae: 7.5371 - val_loss: 3952.6116 - val_mae: 34.6368\n",
      "Epoch 4666/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 207.6396 - mae: 7.9358 - val_loss: 3815.9041 - val_mae: 34.3657\n",
      "Epoch 4667/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 176.5178 - mae: 7.5623 - val_loss: 3906.4729 - val_mae: 34.9335\n",
      "Epoch 4668/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 144.8150 - mae: 7.4408 - val_loss: 3974.3291 - val_mae: 35.1656\n",
      "Epoch 4669/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 163.8453 - mae: 7.5581 - val_loss: 3962.7607 - val_mae: 35.2305\n",
      "Epoch 4670/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.1055 - mae: 7.8819 - val_loss: 4046.8013 - val_mae: 35.4745\n",
      "Epoch 4671/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.3195 - mae: 7.7006 - val_loss: 4062.5764 - val_mae: 35.3328\n",
      "Epoch 4672/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.7213 - mae: 7.6981 - val_loss: 4165.9106 - val_mae: 35.9153\n",
      "Epoch 4673/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.5795 - mae: 7.9106 - val_loss: 4088.2288 - val_mae: 35.5226\n",
      "Epoch 4674/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 177.6816 - mae: 7.7572 - val_loss: 4138.3276 - val_mae: 35.1378\n",
      "Epoch 4675/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 202.0145 - mae: 8.0989 - val_loss: 4190.0967 - val_mae: 36.0927\n",
      "Epoch 4676/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 234.8996 - mae: 8.5368 - val_loss: 4117.1040 - val_mae: 35.6034\n",
      "Epoch 4677/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.8099 - mae: 7.7582 - val_loss: 4051.2239 - val_mae: 35.2236\n",
      "Epoch 4678/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.9704 - mae: 7.9505 - val_loss: 4081.6907 - val_mae: 34.9546\n",
      "Epoch 4679/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.2948 - mae: 7.9981 - val_loss: 4022.1423 - val_mae: 35.3062\n",
      "Epoch 4680/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.0298 - mae: 7.7780 - val_loss: 4080.2615 - val_mae: 35.7394\n",
      "Epoch 4681/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.7472 - mae: 7.6643 - val_loss: 3985.2017 - val_mae: 34.9753\n",
      "Epoch 4682/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.6020 - mae: 7.9922 - val_loss: 3975.5378 - val_mae: 35.2522\n",
      "Epoch 4683/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.8868 - mae: 7.6623 - val_loss: 4074.0627 - val_mae: 35.6147\n",
      "Epoch 4684/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.6367 - mae: 7.6341 - val_loss: 4115.6074 - val_mae: 35.7947\n",
      "Epoch 4685/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.8533 - mae: 7.6558 - val_loss: 4100.8345 - val_mae: 36.3419\n",
      "Epoch 4686/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 169.4045 - mae: 7.7270 - val_loss: 4010.1948 - val_mae: 35.4142\n",
      "Epoch 4687/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.7834 - mae: 7.7723 - val_loss: 3959.6836 - val_mae: 35.2091\n",
      "Epoch 4688/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.8098 - mae: 7.7221 - val_loss: 4012.1729 - val_mae: 34.8883\n",
      "Epoch 4689/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 162.6861 - mae: 7.6807 - val_loss: 4093.3389 - val_mae: 35.4957\n",
      "Epoch 4690/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.9189 - mae: 7.8338 - val_loss: 4183.1943 - val_mae: 36.0557\n",
      "Epoch 4691/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.5892 - mae: 7.9612 - val_loss: 3886.8281 - val_mae: 34.5600\n",
      "Epoch 4692/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 163.9561 - mae: 7.6352 - val_loss: 3899.0039 - val_mae: 34.7780\n",
      "Epoch 4693/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.7240 - mae: 7.8892 - val_loss: 4035.5093 - val_mae: 35.4583\n",
      "Epoch 4694/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.3131 - mae: 7.7638 - val_loss: 4029.0830 - val_mae: 35.5275\n",
      "Epoch 4695/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 187.1249 - mae: 7.6709 - val_loss: 4103.3569 - val_mae: 35.9120\n",
      "Epoch 4696/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 160.7118 - mae: 7.5461 - val_loss: 4171.5869 - val_mae: 36.0358\n",
      "Epoch 4697/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 193.3984 - mae: 7.7391 - val_loss: 4213.1558 - val_mae: 36.1640\n",
      "Epoch 4698/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.9158 - mae: 7.9053 - val_loss: 4242.4473 - val_mae: 36.0861\n",
      "Epoch 4699/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.2132 - mae: 7.7164 - val_loss: 4109.9429 - val_mae: 35.9922\n",
      "Epoch 4700/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.9790 - mae: 8.1368 - val_loss: 4070.9517 - val_mae: 35.4936\n",
      "Epoch 4701/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.7184 - mae: 7.7164 - val_loss: 3994.3079 - val_mae: 35.1428\n",
      "Epoch 4702/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.9532 - mae: 7.6581 - val_loss: 4077.0603 - val_mae: 35.3493\n",
      "Epoch 4703/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.1026 - mae: 7.8385 - val_loss: 4067.7888 - val_mae: 35.4407\n",
      "Epoch 4704/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.8227 - mae: 7.8728 - val_loss: 4139.0791 - val_mae: 35.5632\n",
      "Epoch 4705/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.7792 - mae: 7.8684 - val_loss: 4164.5854 - val_mae: 36.0728\n",
      "Epoch 4706/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 229.6023 - mae: 8.5053 - val_loss: 4193.0938 - val_mae: 36.0067\n",
      "Epoch 4707/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 242.0010 - mae: 8.2809 - val_loss: 4164.4438 - val_mae: 35.8712\n",
      "Epoch 4708/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.2400 - mae: 8.0527 - val_loss: 4056.3552 - val_mae: 35.5601\n",
      "Epoch 4709/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 228.9962 - mae: 8.0745 - val_loss: 4239.2700 - val_mae: 36.3778\n",
      "Epoch 4710/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 245.5396 - mae: 8.4889 - val_loss: 4210.6924 - val_mae: 35.8180\n",
      "Epoch 4711/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 179.3315 - mae: 7.7698 - val_loss: 4251.7729 - val_mae: 36.0231\n",
      "Epoch 4712/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.9079 - mae: 8.1589 - val_loss: 4227.7402 - val_mae: 36.5673\n",
      "Epoch 4713/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 202.4920 - mae: 8.0155 - val_loss: 4089.4890 - val_mae: 35.9636\n",
      "Epoch 4714/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.5668 - mae: 7.9202 - val_loss: 4223.0342 - val_mae: 35.5645\n",
      "Epoch 4715/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 210.9405 - mae: 8.1058 - val_loss: 4357.2036 - val_mae: 36.8607\n",
      "Epoch 4716/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.1623 - mae: 8.0023 - val_loss: 4243.1460 - val_mae: 36.0709\n",
      "Epoch 4717/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.9284 - mae: 8.0912 - val_loss: 4211.5537 - val_mae: 36.1586\n",
      "Epoch 4718/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.7351 - mae: 8.1068 - val_loss: 4194.0679 - val_mae: 35.4662\n",
      "Epoch 4719/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.7756 - mae: 8.1099 - val_loss: 4120.0059 - val_mae: 35.9274\n",
      "Epoch 4720/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.3514 - mae: 7.7457 - val_loss: 4188.4302 - val_mae: 35.5087\n",
      "Epoch 4721/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.5523 - mae: 8.1105 - val_loss: 4093.1316 - val_mae: 35.0178\n",
      "Epoch 4722/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.5273 - mae: 8.1227 - val_loss: 4298.0010 - val_mae: 36.7724\n",
      "Epoch 4723/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.6262 - mae: 8.1051 - val_loss: 4232.2964 - val_mae: 36.3400\n",
      "Epoch 4724/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.3024 - mae: 8.0256 - val_loss: 4225.7500 - val_mae: 36.0630\n",
      "Epoch 4725/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.5567 - mae: 7.8522 - val_loss: 4206.1846 - val_mae: 36.1021\n",
      "Epoch 4726/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 208.1775 - mae: 7.8977 - val_loss: 4192.8970 - val_mae: 35.9399\n",
      "Epoch 4727/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.8577 - mae: 8.0747 - val_loss: 4180.1128 - val_mae: 35.7647\n",
      "Epoch 4728/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.8273 - mae: 8.0326 - val_loss: 4140.4385 - val_mae: 35.4260\n",
      "Epoch 4729/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.6286 - mae: 7.8846 - val_loss: 4031.7415 - val_mae: 35.4192\n",
      "Epoch 4730/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.5664 - mae: 8.2586 - val_loss: 4114.0640 - val_mae: 34.9028\n",
      "Epoch 4731/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.4023 - mae: 8.5033 - val_loss: 4071.6965 - val_mae: 35.4325\n",
      "Epoch 4732/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 195.2250 - mae: 8.1050 - val_loss: 4013.4954 - val_mae: 34.9773\n",
      "Epoch 4733/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.4686 - mae: 8.0165 - val_loss: 4034.5354 - val_mae: 35.3672\n",
      "Epoch 4734/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.7390 - mae: 7.6832 - val_loss: 4084.4282 - val_mae: 35.2478\n",
      "Epoch 4735/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.8710 - mae: 7.8215 - val_loss: 4074.8667 - val_mae: 34.7804\n",
      "Epoch 4736/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.6963 - mae: 7.7839 - val_loss: 4013.8281 - val_mae: 34.5485\n",
      "Epoch 4737/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.6159 - mae: 8.5908 - val_loss: 4043.5442 - val_mae: 34.9267\n",
      "Epoch 4738/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.3221 - mae: 8.0246 - val_loss: 4200.9277 - val_mae: 35.5237\n",
      "Epoch 4739/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.6418 - mae: 7.7912 - val_loss: 4126.2949 - val_mae: 35.1698\n",
      "Epoch 4740/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.6035 - mae: 7.8720 - val_loss: 4079.7087 - val_mae: 35.2472\n",
      "Epoch 4741/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.2651 - mae: 7.9984 - val_loss: 4176.6060 - val_mae: 35.3333\n",
      "Epoch 4742/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.8628 - mae: 8.0200 - val_loss: 4045.2305 - val_mae: 35.0784\n",
      "Epoch 4743/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.0509 - mae: 7.8408 - val_loss: 4112.3438 - val_mae: 35.3208\n",
      "Epoch 4744/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 163.2240 - mae: 7.7180 - val_loss: 4187.0464 - val_mae: 35.4813\n",
      "Epoch 4745/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.8493 - mae: 7.8074 - val_loss: 4098.5396 - val_mae: 35.1257\n",
      "Epoch 4746/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 202.7775 - mae: 8.0287 - val_loss: 4063.6829 - val_mae: 34.8884\n",
      "Epoch 4747/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 217.8380 - mae: 8.2032 - val_loss: 4207.5078 - val_mae: 35.6581\n",
      "Epoch 4748/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.4287 - mae: 8.1282 - val_loss: 4071.1409 - val_mae: 35.5237\n",
      "Epoch 4749/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 164.1254 - mae: 7.7422 - val_loss: 4114.0137 - val_mae: 35.6036\n",
      "Epoch 4750/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 171.0469 - mae: 7.7210 - val_loss: 4108.9248 - val_mae: 35.8310\n",
      "Epoch 4751/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 204.6757 - mae: 8.0192 - val_loss: 4039.5771 - val_mae: 36.1172\n",
      "Epoch 4752/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 190.7627 - mae: 7.9751 - val_loss: 4058.0034 - val_mae: 36.0534\n",
      "Epoch 4753/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 242.1727 - mae: 8.1082 - val_loss: 4160.2373 - val_mae: 35.9635\n",
      "Epoch 4754/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.3213 - mae: 7.7647 - val_loss: 4039.0049 - val_mae: 35.5826\n",
      "Epoch 4755/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.2259 - mae: 7.9526 - val_loss: 3986.6682 - val_mae: 35.1043\n",
      "Epoch 4756/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.1163 - mae: 7.6941 - val_loss: 3962.4065 - val_mae: 34.9247\n",
      "Epoch 4757/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 196.0102 - mae: 7.9033 - val_loss: 4085.4280 - val_mae: 35.5741\n",
      "Epoch 4758/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 222.7968 - mae: 8.1527 - val_loss: 4077.4216 - val_mae: 35.8113\n",
      "Epoch 4759/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 163.6462 - mae: 7.4946 - val_loss: 4034.8486 - val_mae: 35.9872\n",
      "Epoch 4760/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 217.3046 - mae: 8.1123 - val_loss: 3892.9697 - val_mae: 36.1579\n",
      "Epoch 4761/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 198.2028 - mae: 7.9731 - val_loss: 3912.6042 - val_mae: 34.9060\n",
      "Epoch 4762/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 184.9182 - mae: 7.8709 - val_loss: 3994.9128 - val_mae: 35.4924\n",
      "Epoch 4763/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 150.6665 - mae: 7.5702 - val_loss: 4045.2930 - val_mae: 35.3095\n",
      "Epoch 4764/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.6180 - mae: 7.7114 - val_loss: 4100.3252 - val_mae: 35.3761\n",
      "Epoch 4765/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.1763 - mae: 7.6215 - val_loss: 4100.6104 - val_mae: 35.3172\n",
      "Epoch 4766/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.3054 - mae: 7.9450 - val_loss: 3965.4639 - val_mae: 35.0656\n",
      "Epoch 4767/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.1315 - mae: 7.7162 - val_loss: 4082.4482 - val_mae: 35.2617\n",
      "Epoch 4768/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.0258 - mae: 7.7419 - val_loss: 4097.7363 - val_mae: 35.7600\n",
      "Epoch 4769/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.9510 - mae: 7.7166 - val_loss: 4156.4771 - val_mae: 35.7553\n",
      "Epoch 4770/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 221.5787 - mae: 7.9747 - val_loss: 4116.5435 - val_mae: 35.5369\n",
      "Epoch 4771/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 171.9337 - mae: 8.4355 - val_loss: 4237.8027 - val_mae: 37.5426\n",
      "Epoch 4772/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 213.6116 - mae: 9.1552 - val_loss: 4201.8296 - val_mae: 36.3787\n",
      "Epoch 4773/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 186.3021 - mae: 7.8756 - val_loss: 4119.0239 - val_mae: 35.8761\n",
      "Epoch 4774/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 193.3242 - mae: 7.7398 - val_loss: 4297.8975 - val_mae: 36.4368\n",
      "Epoch 4775/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.4288 - mae: 7.9609 - val_loss: 4195.9673 - val_mae: 36.9134\n",
      "Epoch 4776/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.1789 - mae: 7.8147 - val_loss: 4286.6016 - val_mae: 36.5160\n",
      "Epoch 4777/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 186.3489 - mae: 7.8338 - val_loss: 4148.4458 - val_mae: 36.5927\n",
      "Epoch 4778/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 200.2094 - mae: 7.7062 - val_loss: 4224.8594 - val_mae: 36.1336\n",
      "Epoch 4779/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 210.3250 - mae: 7.9593 - val_loss: 4095.8799 - val_mae: 35.6247\n",
      "Epoch 4780/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 166.3604 - mae: 7.5900 - val_loss: 4176.4097 - val_mae: 36.3084\n",
      "Epoch 4781/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 204.8177 - mae: 7.7624 - val_loss: 4161.7422 - val_mae: 35.8399\n",
      "Epoch 4782/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 218.5236 - mae: 7.9908 - val_loss: 4176.8999 - val_mae: 36.2554\n",
      "Epoch 4783/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 203.2347 - mae: 8.1748 - val_loss: 4210.5884 - val_mae: 36.0942\n",
      "Epoch 4784/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 180.1622 - mae: 7.6772 - val_loss: 4096.8784 - val_mae: 35.9163\n",
      "Epoch 4785/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.2018 - mae: 8.0035 - val_loss: 4160.5684 - val_mae: 35.7522\n",
      "Epoch 4786/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.6823 - mae: 8.1296 - val_loss: 4149.4487 - val_mae: 35.4308\n",
      "Epoch 4787/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.5350 - mae: 7.6864 - val_loss: 4094.9036 - val_mae: 35.2799\n",
      "Epoch 4788/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 149.7219 - mae: 7.4699 - val_loss: 4148.6172 - val_mae: 35.3631\n",
      "Epoch 4789/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 187.7569 - mae: 7.9091 - val_loss: 4182.7314 - val_mae: 35.8385\n",
      "Epoch 4790/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.2955 - mae: 7.7044 - val_loss: 4061.8054 - val_mae: 35.4479\n",
      "Epoch 4791/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 177.5157 - mae: 7.8431 - val_loss: 3992.9707 - val_mae: 34.7866\n",
      "Epoch 4792/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.2022 - mae: 7.7994 - val_loss: 4210.3296 - val_mae: 35.9354\n",
      "Epoch 4793/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 183.9285 - mae: 7.9561 - val_loss: 4159.9888 - val_mae: 35.6182\n",
      "Epoch 4794/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 188.8351 - mae: 7.9127 - val_loss: 4152.4619 - val_mae: 35.5579\n",
      "Epoch 4795/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 220.7040 - mae: 7.8818 - val_loss: 4150.8579 - val_mae: 35.4264\n",
      "Epoch 4796/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 155.9195 - mae: 7.5649 - val_loss: 4079.1965 - val_mae: 35.2935\n",
      "Epoch 4797/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.3218 - mae: 7.6991 - val_loss: 4112.9971 - val_mae: 36.2419\n",
      "Epoch 4798/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.1721 - mae: 7.9318 - val_loss: 4080.5955 - val_mae: 34.8821\n",
      "Epoch 4799/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.1986 - mae: 8.0299 - val_loss: 4112.1753 - val_mae: 35.4955\n",
      "Epoch 4800/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 249.0662 - mae: 8.0110 - val_loss: 4176.1655 - val_mae: 36.0398\n",
      "Epoch 4801/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 228.5175 - mae: 8.1766 - val_loss: 4316.9312 - val_mae: 36.6028\n",
      "Epoch 4802/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 218.3800 - mae: 8.3668 - val_loss: 4223.2793 - val_mae: 36.2346\n",
      "Epoch 4803/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.1488 - mae: 8.1378 - val_loss: 4170.3091 - val_mae: 36.2392\n",
      "Epoch 4804/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.4990 - mae: 8.1533 - val_loss: 4121.8433 - val_mae: 35.5130\n",
      "Epoch 4805/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.5672 - mae: 7.6786 - val_loss: 4277.0542 - val_mae: 36.3803\n",
      "Epoch 4806/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.0341 - mae: 7.7378 - val_loss: 4287.0293 - val_mae: 36.5489\n",
      "Epoch 4807/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.7650 - mae: 7.7387 - val_loss: 4115.0186 - val_mae: 36.1534\n",
      "Epoch 4808/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.6738 - mae: 8.1455 - val_loss: 4158.4424 - val_mae: 36.0922\n",
      "Epoch 4809/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 212.4675 - mae: 8.0067 - val_loss: 4184.6479 - val_mae: 36.2508\n",
      "Epoch 4810/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 192.8128 - mae: 7.9059 - val_loss: 4242.3335 - val_mae: 36.5052\n",
      "Epoch 4811/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.2860 - mae: 7.7730 - val_loss: 4120.7544 - val_mae: 35.6082\n",
      "Epoch 4812/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.2431 - mae: 8.0837 - val_loss: 4246.6826 - val_mae: 36.3196\n",
      "Epoch 4813/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.4665 - mae: 7.9635 - val_loss: 4275.1196 - val_mae: 36.2938\n",
      "Epoch 4814/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.7735 - mae: 7.9453 - val_loss: 4264.8696 - val_mae: 36.2882\n",
      "Epoch 4815/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.8622 - mae: 7.8636 - val_loss: 4262.6982 - val_mae: 36.8814\n",
      "Epoch 4816/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.2410 - mae: 7.5857 - val_loss: 4341.9204 - val_mae: 36.5624\n",
      "Epoch 4817/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 157.6235 - mae: 7.4477 - val_loss: 4228.4961 - val_mae: 36.2726\n",
      "Epoch 4818/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 153.1524 - mae: 7.5569 - val_loss: 4157.7598 - val_mae: 35.8699\n",
      "Epoch 4819/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.2679 - mae: 8.1918 - val_loss: 4184.6021 - val_mae: 35.5052\n",
      "Epoch 4820/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.6769 - mae: 7.7444 - val_loss: 4235.2319 - val_mae: 36.0617\n",
      "Epoch 4821/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.1194 - mae: 8.1847 - val_loss: 4179.3882 - val_mae: 35.7253\n",
      "Epoch 4822/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 237.5101 - mae: 8.0870 - val_loss: 4110.0435 - val_mae: 35.7870\n",
      "Epoch 4823/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.0414 - mae: 8.0088 - val_loss: 4217.0317 - val_mae: 35.9181\n",
      "Epoch 4824/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.5076 - mae: 7.8100 - val_loss: 4288.7363 - val_mae: 36.7923\n",
      "Epoch 4825/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.1129 - mae: 7.7683 - val_loss: 4184.7510 - val_mae: 36.1659\n",
      "Epoch 4826/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 246.7348 - mae: 8.2901 - val_loss: 4216.1538 - val_mae: 36.0870\n",
      "Epoch 4827/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.9475 - mae: 8.3004 - val_loss: 4194.5088 - val_mae: 36.1800\n",
      "Epoch 4828/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.8074 - mae: 7.9977 - val_loss: 4373.2119 - val_mae: 36.5422\n",
      "Epoch 4829/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.5477 - mae: 8.2328 - val_loss: 4315.3374 - val_mae: 36.7772\n",
      "Epoch 4830/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 238.5486 - mae: 8.4841 - val_loss: 4230.3906 - val_mae: 36.4178\n",
      "Epoch 4831/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.4789 - mae: 7.8057 - val_loss: 4275.0693 - val_mae: 36.6724\n",
      "Epoch 4832/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.0073 - mae: 7.9978 - val_loss: 4286.2373 - val_mae: 36.4010\n",
      "Epoch 4833/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.0529 - mae: 7.8636 - val_loss: 4146.3008 - val_mae: 36.3700\n",
      "Epoch 4834/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.2811 - mae: 8.0256 - val_loss: 4270.1465 - val_mae: 36.7968\n",
      "Epoch 4835/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 287.8515 - mae: 8.0494 - val_loss: 4469.2480 - val_mae: 37.0784\n",
      "Epoch 4836/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.3775 - mae: 7.8783 - val_loss: 4329.9419 - val_mae: 36.5796\n",
      "Epoch 4837/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.9701 - mae: 8.1097 - val_loss: 4351.3979 - val_mae: 36.5294\n",
      "Epoch 4838/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.5889 - mae: 8.5565 - val_loss: 4488.4971 - val_mae: 37.3730\n",
      "Epoch 4839/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.7553 - mae: 8.3612 - val_loss: 4408.2324 - val_mae: 36.9347\n",
      "Epoch 4840/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 231.6505 - mae: 8.2269 - val_loss: 4195.8330 - val_mae: 35.7486\n",
      "Epoch 4841/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.5656 - mae: 8.0088 - val_loss: 4263.3384 - val_mae: 35.8097\n",
      "Epoch 4842/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.3837 - mae: 7.8141 - val_loss: 4334.4844 - val_mae: 35.8474\n",
      "Epoch 4843/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.5066 - mae: 8.3520 - val_loss: 4203.8735 - val_mae: 35.6719\n",
      "Epoch 4844/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 244.5306 - mae: 8.0791 - val_loss: 4306.5312 - val_mae: 36.4027\n",
      "Epoch 4845/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.6575 - mae: 8.7822 - val_loss: 4268.8735 - val_mae: 36.8045\n",
      "Epoch 4846/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 226.1667 - mae: 8.1090 - val_loss: 4166.6416 - val_mae: 35.8760\n",
      "Epoch 4847/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 171.2499 - mae: 7.8014 - val_loss: 4214.5425 - val_mae: 36.2207\n",
      "Epoch 4848/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.0713 - mae: 7.5780 - val_loss: 4157.9282 - val_mae: 36.1370\n",
      "Epoch 4849/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.2321 - mae: 7.6642 - val_loss: 4154.9907 - val_mae: 36.2360\n",
      "Epoch 4850/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.8697 - mae: 7.5887 - val_loss: 4158.4053 - val_mae: 35.8042\n",
      "Epoch 4851/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 268.1681 - mae: 8.1463 - val_loss: 4070.7354 - val_mae: 36.1801\n",
      "Epoch 4852/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 225.8115 - mae: 8.0049 - val_loss: 4070.6655 - val_mae: 35.8353\n",
      "Epoch 4853/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.9389 - mae: 7.7844 - val_loss: 4100.7334 - val_mae: 35.6286\n",
      "Epoch 4854/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 175.0738 - mae: 7.6068 - val_loss: 4232.4170 - val_mae: 36.2870\n",
      "Epoch 4855/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.0769 - mae: 7.8724 - val_loss: 4101.7783 - val_mae: 36.1706\n",
      "Epoch 4856/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.1766 - mae: 8.3221 - val_loss: 4190.7671 - val_mae: 35.8482\n",
      "Epoch 4857/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.7037 - mae: 7.8766 - val_loss: 4291.5684 - val_mae: 36.9530\n",
      "Epoch 4858/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.1516 - mae: 7.7184 - val_loss: 4248.9648 - val_mae: 36.3228\n",
      "Epoch 4859/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 227.9108 - mae: 8.2453 - val_loss: 4208.7354 - val_mae: 36.4619\n",
      "Epoch 4860/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.7936 - mae: 7.8832 - val_loss: 4224.4897 - val_mae: 36.5127\n",
      "Epoch 4861/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.0937 - mae: 8.1521 - val_loss: 4145.6870 - val_mae: 35.7656\n",
      "Epoch 4862/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.1217 - mae: 7.8522 - val_loss: 4203.4282 - val_mae: 35.5603\n",
      "Epoch 4863/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.5373 - mae: 7.9671 - val_loss: 4151.6318 - val_mae: 36.2283\n",
      "Epoch 4864/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 266.5553 - mae: 8.5320 - val_loss: 4122.2808 - val_mae: 35.6702\n",
      "Epoch 4865/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.4887 - mae: 8.0829 - val_loss: 4276.1240 - val_mae: 36.5020\n",
      "Epoch 4866/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.7568 - mae: 8.0405 - val_loss: 4325.9795 - val_mae: 36.3080\n",
      "Epoch 4867/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 236.4446 - mae: 8.4111 - val_loss: 4225.7534 - val_mae: 36.4788\n",
      "Epoch 4868/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.1645 - mae: 8.5321 - val_loss: 4126.7578 - val_mae: 35.3148\n",
      "Epoch 4869/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 279.9681 - mae: 8.9757 - val_loss: 4201.4702 - val_mae: 36.1333\n",
      "Epoch 4870/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 257.1744 - mae: 8.3765 - val_loss: 4158.0879 - val_mae: 35.4349\n",
      "Epoch 4871/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 218.6780 - mae: 7.9962 - val_loss: 4180.7090 - val_mae: 35.7569\n",
      "Epoch 4872/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 201.9942 - mae: 8.0147 - val_loss: 4095.6628 - val_mae: 35.5959\n",
      "Epoch 4873/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.2676 - mae: 7.8240 - val_loss: 4057.6035 - val_mae: 35.2830\n",
      "Epoch 4874/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.0655 - mae: 8.1142 - val_loss: 4071.0813 - val_mae: 35.6011\n",
      "Epoch 4875/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 190.1069 - mae: 7.8670 - val_loss: 4063.2151 - val_mae: 35.2892\n",
      "Epoch 4876/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.1215 - mae: 8.1306 - val_loss: 4042.8567 - val_mae: 35.0347\n",
      "Epoch 4877/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 207.9375 - mae: 7.7861 - val_loss: 4099.3345 - val_mae: 35.3801\n",
      "Epoch 4878/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.2107 - mae: 7.9594 - val_loss: 4069.9160 - val_mae: 35.4852\n",
      "Epoch 4879/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.5056 - mae: 8.0388 - val_loss: 4100.7153 - val_mae: 35.8525\n",
      "Epoch 4880/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.1946 - mae: 7.8684 - val_loss: 4109.3896 - val_mae: 35.4914\n",
      "Epoch 4881/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 194.6034 - mae: 7.8748 - val_loss: 4001.4651 - val_mae: 35.4612\n",
      "Epoch 4882/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.8676 - mae: 7.5188 - val_loss: 4064.9856 - val_mae: 35.7678\n",
      "Epoch 4883/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.6989 - mae: 7.6230 - val_loss: 3998.4224 - val_mae: 35.4132\n",
      "Epoch 4884/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.6841 - mae: 7.9486 - val_loss: 4115.8418 - val_mae: 35.6472\n",
      "Epoch 4885/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.9993 - mae: 7.8726 - val_loss: 4171.3306 - val_mae: 35.9396\n",
      "Epoch 4886/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.8046 - mae: 7.9561 - val_loss: 4203.5762 - val_mae: 35.7367\n",
      "Epoch 4887/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.5958 - mae: 8.1453 - val_loss: 4148.4697 - val_mae: 35.6899\n",
      "Epoch 4888/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 152.0736 - mae: 7.4978 - val_loss: 4152.1191 - val_mae: 35.7746\n",
      "Epoch 4889/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 174.9427 - mae: 7.8195 - val_loss: 4173.7222 - val_mae: 35.9951\n",
      "Epoch 4890/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.9650 - mae: 7.7952 - val_loss: 4225.2656 - val_mae: 36.2634\n",
      "Epoch 4891/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.6473 - mae: 7.7389 - val_loss: 4091.5359 - val_mae: 35.0816\n",
      "Epoch 4892/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.3741 - mae: 7.6438 - val_loss: 4033.4851 - val_mae: 35.2730\n",
      "Epoch 4893/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.3145 - mae: 7.4941 - val_loss: 4088.4497 - val_mae: 35.5517\n",
      "Epoch 4894/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.7931 - mae: 7.7700 - val_loss: 4154.6777 - val_mae: 35.3242\n",
      "Epoch 4895/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.3654 - mae: 7.7758 - val_loss: 4151.4941 - val_mae: 35.2462\n",
      "Epoch 4896/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 148.1188 - mae: 7.4006 - val_loss: 4139.3584 - val_mae: 35.1599\n",
      "Epoch 4897/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.3549 - mae: 7.8741 - val_loss: 3886.5759 - val_mae: 34.2430\n",
      "Epoch 4898/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.2181 - mae: 8.2166 - val_loss: 4221.5088 - val_mae: 35.7541\n",
      "Epoch 4899/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.3208 - mae: 7.5597 - val_loss: 4061.3142 - val_mae: 36.1658\n",
      "Epoch 4900/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.6848 - mae: 8.0529 - val_loss: 4125.3403 - val_mae: 35.2819\n",
      "Epoch 4901/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 223.6471 - mae: 8.2463 - val_loss: 4155.4805 - val_mae: 35.6582\n",
      "Epoch 4902/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.0080 - mae: 7.7420 - val_loss: 4179.2383 - val_mae: 35.8219\n",
      "Epoch 4903/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 163.3264 - mae: 7.6522 - val_loss: 4211.6538 - val_mae: 35.7439\n",
      "Epoch 4904/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.2489 - mae: 8.0151 - val_loss: 4245.9775 - val_mae: 36.0928\n",
      "Epoch 4905/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.2877 - mae: 8.0416 - val_loss: 4304.3833 - val_mae: 36.8398\n",
      "Epoch 4906/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.2023 - mae: 7.8556 - val_loss: 4236.0806 - val_mae: 36.1716\n",
      "Epoch 4907/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.4163 - mae: 7.6226 - val_loss: 4212.5972 - val_mae: 35.8178\n",
      "Epoch 4908/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.2619 - mae: 7.8094 - val_loss: 4184.1772 - val_mae: 35.5254\n",
      "Epoch 4909/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.4080 - mae: 7.9409 - val_loss: 4176.0874 - val_mae: 35.5696\n",
      "Epoch 4910/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.3015 - mae: 7.6122 - val_loss: 4287.4268 - val_mae: 36.4036\n",
      "Epoch 4911/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.5159 - mae: 7.9898 - val_loss: 4220.5972 - val_mae: 36.3906\n",
      "Epoch 4912/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 202.8862 - mae: 7.8846 - val_loss: 4316.5015 - val_mae: 36.2957\n",
      "Epoch 4913/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.0025 - mae: 8.0375 - val_loss: 4292.7988 - val_mae: 36.1041\n",
      "Epoch 4914/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.1215 - mae: 8.0163 - val_loss: 4361.3691 - val_mae: 36.6114\n",
      "Epoch 4915/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.9963 - mae: 8.0136 - val_loss: 4285.1411 - val_mae: 36.4823\n",
      "Epoch 4916/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.0742 - mae: 7.6991 - val_loss: 4236.6699 - val_mae: 36.2703\n",
      "Epoch 4917/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 177.5280 - mae: 7.9988 - val_loss: 4282.4858 - val_mae: 36.3868\n",
      "Epoch 4918/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.4364 - mae: 7.8583 - val_loss: 4287.7466 - val_mae: 36.0895\n",
      "Epoch 4919/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 194.3563 - mae: 7.9212 - val_loss: 4294.4390 - val_mae: 36.4857\n",
      "Epoch 4920/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 192.9228 - mae: 8.0185 - val_loss: 4177.5317 - val_mae: 36.1758\n",
      "Epoch 4921/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.9193 - mae: 8.1290 - val_loss: 4247.5000 - val_mae: 37.4837\n",
      "Epoch 4922/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.4520 - mae: 7.9440 - val_loss: 4399.1606 - val_mae: 36.6888\n",
      "Epoch 4923/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.7094 - mae: 7.7339 - val_loss: 4329.0107 - val_mae: 36.7483\n",
      "Epoch 4924/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.1208 - mae: 7.7878 - val_loss: 4280.5171 - val_mae: 36.5395\n",
      "Epoch 4925/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.6694 - mae: 8.0201 - val_loss: 4282.9409 - val_mae: 36.3902\n",
      "Epoch 4926/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.2961 - mae: 7.7440 - val_loss: 4323.3740 - val_mae: 36.8435\n",
      "Epoch 4927/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 194.7589 - mae: 8.1624 - val_loss: 4220.8418 - val_mae: 36.6440\n",
      "Epoch 4928/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.9989 - mae: 8.0872 - val_loss: 4332.1836 - val_mae: 36.4038\n",
      "Epoch 4929/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.5594 - mae: 8.1323 - val_loss: 4228.4429 - val_mae: 35.5237\n",
      "Epoch 4930/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.9283 - mae: 7.6421 - val_loss: 4257.4834 - val_mae: 35.8288\n",
      "Epoch 4931/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.8338 - mae: 8.0638 - val_loss: 4195.2856 - val_mae: 36.0857\n",
      "Epoch 4932/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.6069 - mae: 7.6563 - val_loss: 4216.4380 - val_mae: 36.1752\n",
      "Epoch 4933/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.7903 - mae: 8.0335 - val_loss: 4191.4883 - val_mae: 35.3762\n",
      "Epoch 4934/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.9510 - mae: 7.6354 - val_loss: 4184.4512 - val_mae: 36.3674\n",
      "Epoch 4935/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.6973 - mae: 7.7721 - val_loss: 4100.7671 - val_mae: 35.5952\n",
      "Epoch 4936/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.5746 - mae: 7.8265 - val_loss: 4142.8677 - val_mae: 36.0188\n",
      "Epoch 4937/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.7914 - mae: 7.9646 - val_loss: 4116.6440 - val_mae: 36.0840\n",
      "Epoch 4938/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.2296 - mae: 7.8516 - val_loss: 4238.5000 - val_mae: 35.9767\n",
      "Epoch 4939/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.3612 - mae: 7.9520 - val_loss: 4278.4116 - val_mae: 36.4080\n",
      "Epoch 4940/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.2225 - mae: 7.8681 - val_loss: 4274.9790 - val_mae: 36.3236\n",
      "Epoch 4941/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.6933 - mae: 7.8402 - val_loss: 4117.1592 - val_mae: 36.1733\n",
      "Epoch 4942/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 239.0211 - mae: 8.1047 - val_loss: 4217.2773 - val_mae: 36.5395\n",
      "Epoch 4943/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 168.3094 - mae: 7.6273 - val_loss: 4329.4653 - val_mae: 36.3657\n",
      "Epoch 4944/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 249.3867 - mae: 8.2869 - val_loss: 4143.6118 - val_mae: 36.4392\n",
      "Epoch 4945/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.7033 - mae: 7.6575 - val_loss: 4226.0737 - val_mae: 36.2966\n",
      "Epoch 4946/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 209.2983 - mae: 7.9396 - val_loss: 4265.5361 - val_mae: 36.1775\n",
      "Epoch 4947/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.0408 - mae: 7.9989 - val_loss: 4266.5762 - val_mae: 36.5004\n",
      "Epoch 4948/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.6932 - mae: 8.3595 - val_loss: 4123.2686 - val_mae: 35.8705\n",
      "Epoch 4949/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 224.7893 - mae: 8.1126 - val_loss: 4143.4541 - val_mae: 36.1819\n",
      "Epoch 4950/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 170.0907 - mae: 7.7006 - val_loss: 4185.9365 - val_mae: 35.4083\n",
      "Epoch 4951/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 183.4768 - mae: 7.7598 - val_loss: 4112.7524 - val_mae: 35.3341\n",
      "Epoch 4952/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 207.5613 - mae: 8.0912 - val_loss: 4186.7417 - val_mae: 36.2677\n",
      "Epoch 4953/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 191.9727 - mae: 7.9715 - val_loss: 4077.3079 - val_mae: 35.6545\n",
      "Epoch 4954/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 256.3097 - mae: 8.2584 - val_loss: 4240.8936 - val_mae: 35.8645\n",
      "Epoch 4955/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.5267 - mae: 7.9334 - val_loss: 4247.3755 - val_mae: 36.1226\n",
      "Epoch 4956/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.3232 - mae: 7.9306 - val_loss: 4182.0977 - val_mae: 35.9768\n",
      "Epoch 4957/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.0304 - mae: 8.0760 - val_loss: 4227.8877 - val_mae: 36.1431\n",
      "Epoch 4958/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.3998 - mae: 7.9622 - val_loss: 4054.5613 - val_mae: 35.7001\n",
      "Epoch 4959/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.3313 - mae: 7.8403 - val_loss: 4127.1733 - val_mae: 35.6005\n",
      "Epoch 4960/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 215.6712 - mae: 7.9362 - val_loss: 4002.9282 - val_mae: 35.1822\n",
      "Epoch 4961/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 200.9494 - mae: 8.0122 - val_loss: 4149.1357 - val_mae: 35.8098\n",
      "Epoch 4962/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 181.9322 - mae: 7.9516 - val_loss: 4065.8147 - val_mae: 35.4752\n",
      "Epoch 4963/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 193.1136 - mae: 7.9082 - val_loss: 4230.6768 - val_mae: 36.3901\n",
      "Epoch 4964/10000\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 170.5081 - mae: 7.6899 - val_loss: 4051.1794 - val_mae: 35.2447\n",
      "Epoch 4965/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 183.2867 - mae: 7.7212 - val_loss: 4093.9092 - val_mae: 35.5478\n",
      "Epoch 4966/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 192.3598 - mae: 7.9369 - val_loss: 4149.2358 - val_mae: 35.5024\n",
      "Epoch 4967/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 205.9625 - mae: 8.0414 - val_loss: 4349.8022 - val_mae: 36.8102\n",
      "Epoch 4968/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 213.0459 - mae: 7.9676 - val_loss: 4264.7178 - val_mae: 36.4889\n",
      "Epoch 4969/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.9086 - mae: 7.8140 - val_loss: 4343.7090 - val_mae: 36.7674\n",
      "Epoch 4970/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.8199 - mae: 7.7285 - val_loss: 4379.9673 - val_mae: 36.9156\n",
      "Epoch 4971/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.9239 - mae: 7.8480 - val_loss: 4287.0190 - val_mae: 36.2740\n",
      "Epoch 4972/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7642 - mae: 7.9159 - val_loss: 4290.1631 - val_mae: 36.0841\n",
      "Epoch 4973/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.8376 - mae: 7.9735 - val_loss: 4141.6968 - val_mae: 35.4377\n",
      "Epoch 4974/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 233.7466 - mae: 8.2119 - val_loss: 4330.0063 - val_mae: 36.0362\n",
      "Epoch 4975/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.9714 - mae: 7.8027 - val_loss: 4263.4624 - val_mae: 35.8230\n",
      "Epoch 4976/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 217.6220 - mae: 7.8676 - val_loss: 4177.3286 - val_mae: 35.8304\n",
      "Epoch 4977/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.1562 - mae: 7.8810 - val_loss: 4260.9102 - val_mae: 36.4584\n",
      "Epoch 4978/10000\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 181.7991 - mae: 7.4304 - val_loss: 4307.4316 - val_mae: 36.4677\n",
      "Epoch 4979/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 179.4037 - mae: 7.6868 - val_loss: 4155.7163 - val_mae: 35.8249\n",
      "Epoch 4980/10000\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 191.6645 - mae: 7.7335 - val_loss: 4280.1387 - val_mae: 36.0663\n",
      "Epoch 4981/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 227.5705 - mae: 8.0716 - val_loss: 4266.3062 - val_mae: 35.7323\n",
      "Epoch 4982/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 175.9203 - mae: 7.6043 - val_loss: 4208.5410 - val_mae: 36.1378\n",
      "Epoch 4983/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 221.7621 - mae: 8.0057 - val_loss: 4293.0884 - val_mae: 36.0860\n",
      "Epoch 4984/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 199.5968 - mae: 7.9004 - val_loss: 4164.9390 - val_mae: 35.9897\n",
      "Epoch 4985/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 181.5363 - mae: 7.9346 - val_loss: 4246.8257 - val_mae: 36.0716\n",
      "Epoch 4986/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 165.3450 - mae: 7.6291 - val_loss: 4167.0854 - val_mae: 36.1820\n",
      "Epoch 4987/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 170.8526 - mae: 7.7434 - val_loss: 4174.3950 - val_mae: 35.8510\n",
      "Epoch 4988/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 160.2372 - mae: 7.5346 - val_loss: 4144.3794 - val_mae: 35.6053\n",
      "Epoch 4989/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 193.4482 - mae: 7.9684 - val_loss: 4152.7964 - val_mae: 35.4451\n",
      "Epoch 4990/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 210.1861 - mae: 8.1978 - val_loss: 4111.4082 - val_mae: 35.4746\n",
      "Epoch 4991/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 196.8840 - mae: 7.9116 - val_loss: 4098.8496 - val_mae: 35.3917\n",
      "Epoch 4992/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.2607 - mae: 7.9930 - val_loss: 4108.1519 - val_mae: 35.3618\n",
      "Epoch 4993/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 205.9599 - mae: 7.9895 - val_loss: 4133.2769 - val_mae: 35.7131\n",
      "Epoch 4994/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7176 - mae: 8.2159 - val_loss: 4125.6870 - val_mae: 35.7868\n",
      "Epoch 4995/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 173.3309 - mae: 7.7655 - val_loss: 4206.7739 - val_mae: 35.5740\n",
      "Epoch 4996/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.4353 - mae: 7.9451 - val_loss: 4220.3574 - val_mae: 35.8927\n",
      "Epoch 4997/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.6138 - mae: 7.8250 - val_loss: 4308.7212 - val_mae: 36.4915\n",
      "Epoch 4998/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.0607 - mae: 8.0121 - val_loss: 4220.3535 - val_mae: 36.3278\n",
      "Epoch 4999/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.4179 - mae: 7.8561 - val_loss: 4142.6118 - val_mae: 35.8627\n",
      "Epoch 5000/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.1828 - mae: 8.1247 - val_loss: 4223.4585 - val_mae: 36.3626\n",
      "Epoch 5001/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.6179 - mae: 8.0204 - val_loss: 4093.3062 - val_mae: 35.7907\n",
      "Epoch 5002/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.7684 - mae: 8.0452 - val_loss: 4296.1113 - val_mae: 36.8325\n",
      "Epoch 5003/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 224.6013 - mae: 8.0476 - val_loss: 4252.3472 - val_mae: 36.2673\n",
      "Epoch 5004/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 212.5363 - mae: 8.0579 - val_loss: 4277.7764 - val_mae: 35.8710\n",
      "Epoch 5005/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 232.3589 - mae: 8.2450 - val_loss: 4357.2134 - val_mae: 36.5817\n",
      "Epoch 5006/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 188.4807 - mae: 8.3528 - val_loss: 4408.5654 - val_mae: 36.4703\n",
      "Epoch 5007/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 223.7540 - mae: 8.3246 - val_loss: 4430.4834 - val_mae: 36.2877\n",
      "Epoch 5008/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 258.1600 - mae: 8.6028 - val_loss: 4417.9097 - val_mae: 36.6683\n",
      "Epoch 5009/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.1320 - mae: 8.0355 - val_loss: 4236.5269 - val_mae: 35.7161\n",
      "Epoch 5010/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.2418 - mae: 8.1130 - val_loss: 4191.3789 - val_mae: 35.3980\n",
      "Epoch 5011/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 216.7695 - mae: 8.2597 - val_loss: 4203.4990 - val_mae: 35.9348\n",
      "Epoch 5012/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 171.4866 - mae: 7.7381 - val_loss: 4269.2593 - val_mae: 35.8334\n",
      "Epoch 5013/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 239.6195 - mae: 8.3602 - val_loss: 4176.4014 - val_mae: 35.9151\n",
      "Epoch 5014/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 194.6863 - mae: 8.0047 - val_loss: 4110.9644 - val_mae: 35.8214\n",
      "Epoch 5015/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 213.3626 - mae: 8.1687 - val_loss: 4161.9258 - val_mae: 35.9779\n",
      "Epoch 5016/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 167.5221 - mae: 7.8391 - val_loss: 4136.5352 - val_mae: 35.3352\n",
      "Epoch 5017/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 271.0856 - mae: 8.1190 - val_loss: 4245.5591 - val_mae: 36.2993\n",
      "Epoch 5018/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 206.3744 - mae: 8.0745 - val_loss: 4218.4419 - val_mae: 36.0483\n",
      "Epoch 5019/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 200.7549 - mae: 7.9306 - val_loss: 4240.8706 - val_mae: 36.0313\n",
      "Epoch 5020/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 215.0948 - mae: 8.1011 - val_loss: 4112.0166 - val_mae: 36.0058\n",
      "Epoch 5021/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 249.6775 - mae: 8.1304 - val_loss: 4047.3162 - val_mae: 35.7889\n",
      "Epoch 5022/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 227.3663 - mae: 8.5476 - val_loss: 4148.7368 - val_mae: 35.9878\n",
      "Epoch 5023/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 179.8230 - mae: 7.8812 - val_loss: 4164.9453 - val_mae: 35.9152\n",
      "Epoch 5024/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 179.9258 - mae: 7.8071 - val_loss: 4086.3438 - val_mae: 35.5087\n",
      "Epoch 5025/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.2307 - mae: 7.7581 - val_loss: 4068.1907 - val_mae: 35.1051\n",
      "Epoch 5026/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.8099 - mae: 8.1416 - val_loss: 3998.0210 - val_mae: 35.4597\n",
      "Epoch 5027/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 235.7875 - mae: 8.1861 - val_loss: 4188.1118 - val_mae: 36.0298\n",
      "Epoch 5028/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 195.4315 - mae: 7.9467 - val_loss: 4187.3198 - val_mae: 35.9616\n",
      "Epoch 5029/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.0174 - mae: 7.6712 - val_loss: 4211.7095 - val_mae: 35.6951\n",
      "Epoch 5030/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.1999 - mae: 7.8060 - val_loss: 4255.4673 - val_mae: 36.0387\n",
      "Epoch 5031/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.7888 - mae: 7.9184 - val_loss: 4203.5142 - val_mae: 35.7670\n",
      "Epoch 5032/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.6467 - mae: 7.6636 - val_loss: 4243.2192 - val_mae: 35.7629\n",
      "Epoch 5033/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 150.7487 - mae: 7.4302 - val_loss: 4285.6558 - val_mae: 35.8822\n",
      "Epoch 5034/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.5852 - mae: 7.7072 - val_loss: 4300.9805 - val_mae: 36.1611\n",
      "Epoch 5035/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.5675 - mae: 7.8357 - val_loss: 4305.9141 - val_mae: 36.1713\n",
      "Epoch 5036/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 223.4535 - mae: 8.0834 - val_loss: 4246.7598 - val_mae: 35.7997\n",
      "Epoch 5037/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 188.9777 - mae: 7.7334 - val_loss: 4201.4941 - val_mae: 35.5367\n",
      "Epoch 5038/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 167.2545 - mae: 7.6075 - val_loss: 4274.1279 - val_mae: 36.2944\n",
      "Epoch 5039/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 156.8902 - mae: 7.5806 - val_loss: 4222.2534 - val_mae: 35.8924\n",
      "Epoch 5040/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.9580 - mae: 7.8259 - val_loss: 4296.0356 - val_mae: 36.4089\n",
      "Epoch 5041/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 170.9291 - mae: 7.8329 - val_loss: 4227.0181 - val_mae: 36.1050\n",
      "Epoch 5042/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.6618 - mae: 7.7160 - val_loss: 4207.1787 - val_mae: 35.6672\n",
      "Epoch 5043/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 187.4455 - mae: 7.9813 - val_loss: 4340.2974 - val_mae: 36.1306\n",
      "Epoch 5044/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.4295 - mae: 7.9268 - val_loss: 4253.1592 - val_mae: 36.5212\n",
      "Epoch 5045/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 180.9031 - mae: 7.7946 - val_loss: 4229.3687 - val_mae: 35.8559\n",
      "Epoch 5046/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.6646 - mae: 7.7383 - val_loss: 4289.4541 - val_mae: 36.2247\n",
      "Epoch 5047/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 269.7732 - mae: 8.4679 - val_loss: 4429.1328 - val_mae: 37.1098\n",
      "Epoch 5048/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 222.9202 - mae: 8.0424 - val_loss: 4172.4521 - val_mae: 35.9330\n",
      "Epoch 5049/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 238.4855 - mae: 8.6799 - val_loss: 4216.1787 - val_mae: 36.9481\n",
      "Epoch 5050/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 250.7930 - mae: 8.9485 - val_loss: 4116.3872 - val_mae: 36.1999\n",
      "Epoch 5051/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 214.6589 - mae: 8.4189 - val_loss: 4228.0728 - val_mae: 36.4905\n",
      "Epoch 5052/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 235.0927 - mae: 8.3797 - val_loss: 4226.9653 - val_mae: 35.8313\n",
      "Epoch 5053/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 187.4816 - mae: 8.0320 - val_loss: 4196.4146 - val_mae: 36.5924\n",
      "Epoch 5054/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 200.9781 - mae: 8.0673 - val_loss: 4239.2754 - val_mae: 36.1796\n",
      "Epoch 5055/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 212.9742 - mae: 8.1087 - val_loss: 4229.2915 - val_mae: 36.3572\n",
      "Epoch 5056/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 264.8493 - mae: 8.3762 - val_loss: 4151.7778 - val_mae: 35.6768\n",
      "Epoch 5057/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 171.2456 - mae: 7.8470 - val_loss: 4238.0786 - val_mae: 35.8905\n",
      "Epoch 5058/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 186.0435 - mae: 7.9502 - val_loss: 4200.4272 - val_mae: 36.2519\n",
      "Epoch 5059/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 202.6780 - mae: 8.0197 - val_loss: 4255.8208 - val_mae: 36.3868\n",
      "Epoch 5060/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 169.9549 - mae: 7.8087 - val_loss: 4305.8335 - val_mae: 36.4148\n",
      "Epoch 5061/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 229.2063 - mae: 8.2888 - val_loss: 4164.6201 - val_mae: 35.8525\n",
      "Epoch 5062/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 214.3263 - mae: 8.3091 - val_loss: 4224.6084 - val_mae: 36.3257\n",
      "Epoch 5063/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 177.0128 - mae: 7.7688 - val_loss: 4187.2036 - val_mae: 36.0906\n",
      "Epoch 5064/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 211.2600 - mae: 8.1826 - val_loss: 4193.0083 - val_mae: 35.7083\n",
      "Epoch 5065/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 200.8270 - mae: 7.9662 - val_loss: 4161.7988 - val_mae: 35.9092\n",
      "Epoch 5066/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 211.1110 - mae: 8.1333 - val_loss: 4135.9326 - val_mae: 35.6373\n",
      "Epoch 5067/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 198.5348 - mae: 8.0895 - val_loss: 4228.0557 - val_mae: 36.1743\n",
      "Epoch 5068/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 194.4178 - mae: 7.9377 - val_loss: 4297.8618 - val_mae: 36.2480\n",
      "Epoch 5069/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 203.6117 - mae: 7.8089 - val_loss: 4303.5405 - val_mae: 36.7199\n",
      "Epoch 5070/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 226.8949 - mae: 8.1495 - val_loss: 4043.7080 - val_mae: 35.7721\n",
      "Epoch 5071/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 222.7810 - mae: 8.2022 - val_loss: 4196.1943 - val_mae: 36.7605\n",
      "Epoch 5072/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 182.1594 - mae: 7.9104 - val_loss: 4118.2661 - val_mae: 35.6562\n",
      "Epoch 5073/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 206.9196 - mae: 8.2053 - val_loss: 4139.9419 - val_mae: 35.6992\n",
      "Epoch 5074/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 169.2612 - mae: 7.7121 - val_loss: 4187.6494 - val_mae: 35.8369\n",
      "Epoch 5075/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 163.8853 - mae: 7.7305 - val_loss: 4223.3301 - val_mae: 36.2717\n",
      "Epoch 5076/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 197.0194 - mae: 7.8254 - val_loss: 4139.5474 - val_mae: 35.6409\n",
      "Epoch 5077/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 191.8155 - mae: 7.9034 - val_loss: 4184.8467 - val_mae: 35.6282\n",
      "Epoch 5078/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 195.8786 - mae: 7.9399 - val_loss: 4225.3706 - val_mae: 36.2933\n",
      "Epoch 5079/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 189.5180 - mae: 8.1819 - val_loss: 4221.2686 - val_mae: 36.3113\n",
      "Epoch 5080/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 180.8867 - mae: 7.9000 - val_loss: 4264.9258 - val_mae: 36.6801\n",
      "Epoch 5081/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 201.1293 - mae: 7.8300 - val_loss: 4207.8989 - val_mae: 36.3496\n",
      "Epoch 5082/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.8158 - mae: 7.8115 - val_loss: 4222.5151 - val_mae: 36.6102\n",
      "Epoch 5083/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 153.1461 - mae: 7.4876 - val_loss: 4236.6357 - val_mae: 36.3247\n",
      "Epoch 5084/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.6891 - mae: 7.5710 - val_loss: 4304.6729 - val_mae: 36.6020\n",
      "Epoch 5085/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 201.1729 - mae: 7.8925 - val_loss: 4233.8442 - val_mae: 35.8319\n",
      "Epoch 5086/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 177.3291 - mae: 7.6663 - val_loss: 4248.8994 - val_mae: 35.5860\n",
      "Epoch 5087/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.5166 - mae: 7.7874 - val_loss: 4264.0249 - val_mae: 35.7671\n",
      "Epoch 5088/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 184.7335 - mae: 7.8881 - val_loss: 4220.7837 - val_mae: 36.0980\n",
      "Epoch 5089/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.3781 - mae: 7.6897 - val_loss: 4346.0439 - val_mae: 36.5465\n",
      "Epoch 5090/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 163.4222 - mae: 7.5451 - val_loss: 4267.8999 - val_mae: 36.2048\n",
      "Epoch 5091/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.5329 - mae: 7.7911 - val_loss: 4427.9512 - val_mae: 36.6626\n",
      "Epoch 5092/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.8950 - mae: 7.5931 - val_loss: 4125.0054 - val_mae: 35.5985\n",
      "Epoch 5093/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 156.3757 - mae: 7.6807 - val_loss: 4267.9546 - val_mae: 35.8507\n",
      "Epoch 5094/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.6068 - mae: 7.8978 - val_loss: 4298.7812 - val_mae: 35.8433\n",
      "Epoch 5095/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.3294 - mae: 7.9971 - val_loss: 4127.9346 - val_mae: 34.9671\n",
      "Epoch 5096/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.1997 - mae: 8.0436 - val_loss: 4173.0938 - val_mae: 35.7189\n",
      "Epoch 5097/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.5610 - mae: 7.6746 - val_loss: 4161.3799 - val_mae: 35.6133\n",
      "Epoch 5098/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.1316 - mae: 7.7444 - val_loss: 4153.5713 - val_mae: 35.5263\n",
      "Epoch 5099/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.6287 - mae: 7.8882 - val_loss: 4258.0459 - val_mae: 36.0422\n",
      "Epoch 5100/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.5477 - mae: 7.7762 - val_loss: 4177.3667 - val_mae: 35.4667\n",
      "Epoch 5101/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 208.6359 - mae: 8.1094 - val_loss: 4170.3979 - val_mae: 36.2439\n",
      "Epoch 5102/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 209.2829 - mae: 8.1250 - val_loss: 4143.6514 - val_mae: 35.4348\n",
      "Epoch 5103/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 210.7935 - mae: 8.0161 - val_loss: 4303.3267 - val_mae: 36.4188\n",
      "Epoch 5104/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 195.3715 - mae: 8.0000 - val_loss: 4280.2466 - val_mae: 36.3325\n",
      "Epoch 5105/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 220.1055 - mae: 8.0709 - val_loss: 4196.6582 - val_mae: 35.7241\n",
      "Epoch 5106/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 162.6319 - mae: 7.6183 - val_loss: 4157.0161 - val_mae: 35.8725\n",
      "Epoch 5107/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 182.7301 - mae: 7.7795 - val_loss: 4234.5044 - val_mae: 35.7511\n",
      "Epoch 5108/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 220.6533 - mae: 8.0505 - val_loss: 4142.7959 - val_mae: 35.5814\n",
      "Epoch 5109/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 221.0367 - mae: 8.1549 - val_loss: 4157.9473 - val_mae: 35.6611\n",
      "Epoch 5110/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 178.9637 - mae: 7.7464 - val_loss: 4106.7285 - val_mae: 35.4364\n",
      "Epoch 5111/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 167.0176 - mae: 7.7572 - val_loss: 4172.2153 - val_mae: 35.8673\n",
      "Epoch 5112/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 184.2286 - mae: 7.7673 - val_loss: 4156.2920 - val_mae: 36.0870\n",
      "Epoch 5113/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 233.4266 - mae: 8.0899 - val_loss: 4169.9971 - val_mae: 35.5984\n",
      "Epoch 5114/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 167.8022 - mae: 7.7185 - val_loss: 4154.7764 - val_mae: 35.9276\n",
      "Epoch 5115/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.6385 - mae: 7.5094 - val_loss: 4329.7832 - val_mae: 36.3469\n",
      "Epoch 5116/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 161.2289 - mae: 7.4744 - val_loss: 4258.3491 - val_mae: 35.7402\n",
      "Epoch 5117/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 160.6693 - mae: 7.5138 - val_loss: 4359.6978 - val_mae: 36.2752\n",
      "Epoch 5118/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 155.4229 - mae: 7.4910 - val_loss: 4268.5747 - val_mae: 36.3197\n",
      "Epoch 5119/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 179.9178 - mae: 7.7056 - val_loss: 4112.3291 - val_mae: 35.8971\n",
      "Epoch 5120/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.3559 - mae: 7.7319 - val_loss: 4299.1904 - val_mae: 36.2173\n",
      "Epoch 5121/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 180.4768 - mae: 7.6478 - val_loss: 4342.0874 - val_mae: 36.5817\n",
      "Epoch 5122/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.7092 - mae: 7.7281 - val_loss: 4334.8828 - val_mae: 36.3914\n",
      "Epoch 5123/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.0012 - mae: 7.5729 - val_loss: 4333.6099 - val_mae: 36.4807\n",
      "Epoch 5124/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.0962 - mae: 7.6900 - val_loss: 4315.1665 - val_mae: 36.3198\n",
      "Epoch 5125/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 165.6906 - mae: 7.7347 - val_loss: 4188.2603 - val_mae: 35.7783\n",
      "Epoch 5126/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.2816 - mae: 7.7334 - val_loss: 4237.4824 - val_mae: 35.9314\n",
      "Epoch 5127/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.6092 - mae: 7.9278 - val_loss: 4345.4868 - val_mae: 36.3416\n",
      "Epoch 5128/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.2902 - mae: 7.7575 - val_loss: 4238.1108 - val_mae: 36.1071\n",
      "Epoch 5129/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 151.0283 - mae: 7.3797 - val_loss: 4238.4727 - val_mae: 35.7452\n",
      "Epoch 5130/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.5094 - mae: 7.9383 - val_loss: 4173.8726 - val_mae: 35.3409\n",
      "Epoch 5131/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.8752 - mae: 7.8398 - val_loss: 4234.3403 - val_mae: 35.7243\n",
      "Epoch 5132/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.9691 - mae: 7.7478 - val_loss: 4303.7407 - val_mae: 36.3227\n",
      "Epoch 5133/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 186.6169 - mae: 7.8937 - val_loss: 4232.2656 - val_mae: 35.9264\n",
      "Epoch 5134/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 146.4008 - mae: 7.4669 - val_loss: 4270.1865 - val_mae: 36.0196\n",
      "Epoch 5135/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 183.9685 - mae: 7.8531 - val_loss: 4203.0088 - val_mae: 35.7403\n",
      "Epoch 5136/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.4620 - mae: 7.8762 - val_loss: 4169.8188 - val_mae: 35.4961\n",
      "Epoch 5137/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.3940 - mae: 7.8317 - val_loss: 4151.4834 - val_mae: 35.6399\n",
      "Epoch 5138/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 185.2482 - mae: 7.9697 - val_loss: 4179.4429 - val_mae: 35.6161\n",
      "Epoch 5139/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 193.6169 - mae: 7.8335 - val_loss: 4032.5127 - val_mae: 35.5372\n",
      "Epoch 5140/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 167.6741 - mae: 7.6961 - val_loss: 4102.2441 - val_mae: 35.9277\n",
      "Epoch 5141/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 181.1360 - mae: 7.8214 - val_loss: 4074.0457 - val_mae: 35.7814\n",
      "Epoch 5142/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 197.2908 - mae: 7.8539 - val_loss: 4233.4375 - val_mae: 36.0779\n",
      "Epoch 5143/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 194.8724 - mae: 7.7274 - val_loss: 4247.9092 - val_mae: 36.1790\n",
      "Epoch 5144/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 174.5842 - mae: 7.8315 - val_loss: 4176.7612 - val_mae: 35.6134\n",
      "Epoch 5145/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.7895 - mae: 7.9136 - val_loss: 4122.0239 - val_mae: 35.7170\n",
      "Epoch 5146/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.5850 - mae: 7.7792 - val_loss: 4127.7974 - val_mae: 35.7232\n",
      "Epoch 5147/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 211.2476 - mae: 7.9803 - val_loss: 4304.9346 - val_mae: 36.2501\n",
      "Epoch 5148/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.5427 - mae: 7.4888 - val_loss: 4096.1206 - val_mae: 35.9765\n",
      "Epoch 5149/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.0968 - mae: 7.5534 - val_loss: 4166.0820 - val_mae: 35.2996\n",
      "Epoch 5150/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 170.3123 - mae: 7.6664 - val_loss: 4240.7739 - val_mae: 35.9181\n",
      "Epoch 5151/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.3879 - mae: 7.7949 - val_loss: 4209.3594 - val_mae: 35.9545\n",
      "Epoch 5152/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 199.2032 - mae: 7.7489 - val_loss: 4192.7036 - val_mae: 36.1322\n",
      "Epoch 5153/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 172.6222 - mae: 7.6448 - val_loss: 3993.6357 - val_mae: 34.9695\n",
      "Epoch 5154/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 209.6270 - mae: 8.0386 - val_loss: 3953.8481 - val_mae: 34.7869\n",
      "Epoch 5155/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.3933 - mae: 8.0387 - val_loss: 4037.0496 - val_mae: 35.1831\n",
      "Epoch 5156/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 197.8698 - mae: 7.8531 - val_loss: 3956.0535 - val_mae: 34.6720\n",
      "Epoch 5157/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 175.1944 - mae: 7.7780 - val_loss: 4244.9028 - val_mae: 36.3939\n",
      "Epoch 5158/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 163.6238 - mae: 7.6619 - val_loss: 4138.6245 - val_mae: 35.6152\n",
      "Epoch 5159/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 161.1987 - mae: 7.8198 - val_loss: 4171.3447 - val_mae: 35.9251\n",
      "Epoch 5160/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 206.9522 - mae: 8.0657 - val_loss: 4141.2285 - val_mae: 35.6541\n",
      "Epoch 5161/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 158.4700 - mae: 7.4978 - val_loss: 4262.2012 - val_mae: 35.9327\n",
      "Epoch 5162/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 183.3146 - mae: 7.8082 - val_loss: 4233.2671 - val_mae: 36.0655\n",
      "Epoch 5163/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 165.2398 - mae: 7.6357 - val_loss: 4267.4087 - val_mae: 35.7503\n",
      "Epoch 5164/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 236.0633 - mae: 8.0549 - val_loss: 4227.2563 - val_mae: 36.3541\n",
      "Epoch 5165/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 209.3208 - mae: 8.1459 - val_loss: 4353.1025 - val_mae: 36.1472\n",
      "Epoch 5166/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 194.0844 - mae: 7.9490 - val_loss: 4328.2515 - val_mae: 36.1122\n",
      "Epoch 5167/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 207.1140 - mae: 8.0833 - val_loss: 4291.7017 - val_mae: 36.0138\n",
      "Epoch 5168/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 186.3679 - mae: 8.0628 - val_loss: 4262.9717 - val_mae: 36.2699\n",
      "Epoch 5169/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 275.7898 - mae: 8.3376 - val_loss: 4246.2378 - val_mae: 36.6598\n",
      "Epoch 5170/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 198.6668 - mae: 7.9314 - val_loss: 4274.4463 - val_mae: 36.4456\n",
      "Epoch 5171/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 199.8256 - mae: 7.7637 - val_loss: 4253.6714 - val_mae: 35.9938\n",
      "Epoch 5172/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.8116 - mae: 7.8567 - val_loss: 4172.7275 - val_mae: 35.7939\n",
      "Epoch 5173/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.7368 - mae: 7.8456 - val_loss: 4135.7236 - val_mae: 35.5553\n",
      "Epoch 5174/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.6421 - mae: 8.1101 - val_loss: 4146.0894 - val_mae: 35.8118\n",
      "Epoch 5175/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.0207 - mae: 7.8498 - val_loss: 4131.8013 - val_mae: 35.3946\n",
      "Epoch 5176/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.2105 - mae: 7.9732 - val_loss: 4127.9497 - val_mae: 35.3850\n",
      "Epoch 5177/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 191.2682 - mae: 8.0872 - val_loss: 4195.0762 - val_mae: 35.7569\n",
      "Epoch 5178/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 188.7202 - mae: 7.8065 - val_loss: 4194.1992 - val_mae: 35.2645\n",
      "Epoch 5179/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 197.9498 - mae: 7.6607 - val_loss: 4142.0137 - val_mae: 35.0109\n",
      "Epoch 5180/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 208.4667 - mae: 8.0269 - val_loss: 4100.4072 - val_mae: 35.5095\n",
      "Epoch 5181/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.8494 - mae: 7.7019 - val_loss: 4160.8521 - val_mae: 35.3091\n",
      "Epoch 5182/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 202.8759 - mae: 7.9380 - val_loss: 4121.8735 - val_mae: 35.7468\n",
      "Epoch 5183/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.2315 - mae: 8.0816 - val_loss: 4258.7007 - val_mae: 36.1113\n",
      "Epoch 5184/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.5675 - mae: 7.8658 - val_loss: 4238.2344 - val_mae: 36.1883\n",
      "Epoch 5185/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.9373 - mae: 8.0889 - val_loss: 4290.4219 - val_mae: 36.1760\n",
      "Epoch 5186/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 205.7849 - mae: 8.0520 - val_loss: 4155.8325 - val_mae: 35.8870\n",
      "Epoch 5187/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 227.4986 - mae: 8.1261 - val_loss: 4168.8149 - val_mae: 35.7846\n",
      "Epoch 5188/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 230.5765 - mae: 8.0272 - val_loss: 4173.4189 - val_mae: 35.6788\n",
      "Epoch 5189/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.3556 - mae: 8.1461 - val_loss: 4290.7227 - val_mae: 36.0565\n",
      "Epoch 5190/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 214.8077 - mae: 8.0883 - val_loss: 4278.3130 - val_mae: 36.2377\n",
      "Epoch 5191/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.7650 - mae: 8.0043 - val_loss: 4210.5522 - val_mae: 35.8664\n",
      "Epoch 5192/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 232.8898 - mae: 8.2907 - val_loss: 4185.4595 - val_mae: 35.5946\n",
      "Epoch 5193/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 177.2305 - mae: 7.7528 - val_loss: 4323.9746 - val_mae: 36.2693\n",
      "Epoch 5194/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.5068 - mae: 8.0311 - val_loss: 4201.8091 - val_mae: 36.1569\n",
      "Epoch 5195/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 192.9178 - mae: 7.7653 - val_loss: 4217.2593 - val_mae: 36.1459\n",
      "Epoch 5196/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 220.7548 - mae: 8.1756 - val_loss: 4270.6870 - val_mae: 36.3296\n",
      "Epoch 5197/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 281.4898 - mae: 8.6447 - val_loss: 4289.0068 - val_mae: 36.3207\n",
      "Epoch 5198/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.4816 - mae: 8.1064 - val_loss: 4366.9683 - val_mae: 36.6780\n",
      "Epoch 5199/10000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 186.7735 - mae: 7.8060 - val_loss: 4261.9087 - val_mae: 36.5130\n",
      "Epoch 5200/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 198.7272 - mae: 7.8514 - val_loss: 4416.1226 - val_mae: 36.5522\n",
      "Epoch 5201/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 176.2916 - mae: 7.6509 - val_loss: 4281.2593 - val_mae: 36.0970\n",
      "Epoch 5202/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 191.7983 - mae: 7.9825 - val_loss: 4196.9834 - val_mae: 35.8449\n",
      "Epoch 5203/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 218.8731 - mae: 8.0542 - val_loss: 4248.6362 - val_mae: 35.8122\n",
      "Epoch 5204/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 215.7642 - mae: 8.2608 - val_loss: 4269.3804 - val_mae: 36.4727\n",
      "Epoch 5205/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 203.7821 - mae: 8.2043 - val_loss: 4277.6665 - val_mae: 36.3218\n",
      "Epoch 5206/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 178.3141 - mae: 7.8550 - val_loss: 4158.6841 - val_mae: 35.4324\n",
      "Epoch 5207/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 221.6469 - mae: 8.0729 - val_loss: 4212.3232 - val_mae: 36.0218\n",
      "Epoch 5208/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 184.4792 - mae: 7.8309 - val_loss: 4223.1528 - val_mae: 35.9552\n",
      "Epoch 5209/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 211.3777 - mae: 8.0475 - val_loss: 4173.8062 - val_mae: 35.8203\n",
      "Epoch 5210/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 179.8745 - mae: 7.7750 - val_loss: 4152.8130 - val_mae: 35.6032\n",
      "Epoch 5211/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 200.7760 - mae: 7.9548 - val_loss: 4153.7461 - val_mae: 35.4076\n",
      "Epoch 5212/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 189.0635 - mae: 7.8884 - val_loss: 4319.9526 - val_mae: 36.0662\n",
      "Epoch 5213/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 182.0177 - mae: 7.7968 - val_loss: 4119.0137 - val_mae: 35.6390\n",
      "Epoch 5214/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 188.3675 - mae: 7.8979 - val_loss: 4187.3828 - val_mae: 36.1238\n",
      "Epoch 5215/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 163.9957 - mae: 7.6438 - val_loss: 4203.8770 - val_mae: 36.0580\n",
      "Epoch 5216/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 243.3813 - mae: 8.3155 - val_loss: 4204.7700 - val_mae: 35.3596\n",
      "Epoch 5217/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 220.8996 - mae: 7.9438 - val_loss: 4167.9023 - val_mae: 35.3349\n",
      "Epoch 5218/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.1821 - mae: 8.0091 - val_loss: 4194.0669 - val_mae: 36.0465\n",
      "Epoch 5219/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 210.8042 - mae: 7.8040 - val_loss: 4129.8765 - val_mae: 35.5839\n",
      "Epoch 5220/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 196.5229 - mae: 7.8714 - val_loss: 4111.1636 - val_mae: 35.8550\n",
      "Epoch 5221/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 198.5553 - mae: 8.0282 - val_loss: 4109.9678 - val_mae: 35.9401\n",
      "Epoch 5222/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 193.5665 - mae: 8.1716 - val_loss: 4151.6514 - val_mae: 35.8945\n",
      "Epoch 5223/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 206.4863 - mae: 8.0796 - val_loss: 4065.3613 - val_mae: 35.4561\n",
      "Epoch 5224/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 204.8849 - mae: 8.1039 - val_loss: 4094.5427 - val_mae: 35.6877\n",
      "Epoch 5225/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 169.2032 - mae: 7.5744 - val_loss: 4209.5298 - val_mae: 36.0519\n",
      "Epoch 5226/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 200.6380 - mae: 7.9023 - val_loss: 4128.1313 - val_mae: 35.5678\n",
      "Epoch 5227/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 219.8112 - mae: 7.9748 - val_loss: 4139.9146 - val_mae: 35.8107\n",
      "Epoch 5228/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 191.0004 - mae: 7.9565 - val_loss: 4169.1777 - val_mae: 35.9686\n",
      "Epoch 5229/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 189.0879 - mae: 7.9755 - val_loss: 4183.5278 - val_mae: 35.9355\n",
      "Epoch 5230/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 195.3285 - mae: 7.7949 - val_loss: 4174.3887 - val_mae: 35.5255\n",
      "Epoch 5231/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 201.9835 - mae: 7.9517 - val_loss: 4287.5303 - val_mae: 36.3692\n",
      "Epoch 5232/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 181.9789 - mae: 7.7523 - val_loss: 4269.3403 - val_mae: 36.1154\n",
      "Epoch 5233/10000\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 177.5319 - mae: 7.7865 - val_loss: 4218.9819 - val_mae: 36.0787\n",
      "Epoch 5234/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 195.2150 - mae: 7.8368 - val_loss: 4121.8677 - val_mae: 35.8322\n",
      "Epoch 5235/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 166.1132 - mae: 7.6640 - val_loss: 4144.6992 - val_mae: 35.3991\n",
      "Epoch 5236/10000\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 172.9707 - mae: 7.7454 - val_loss: 4199.3882 - val_mae: 35.6972\n",
      "Epoch 5237/10000\n",
      " 85/122 [===================>..........] - ETA: 0s - loss: 183.7824 - mae: 7.8151"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# MSE loss for regression, MAE metric for evaluation\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 5: Train Model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\talha\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 4: Compile Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # MSE loss for regression, MAE metric for evaluation\n",
    "\n",
    "# Step 5: Train Model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10000, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 4632.5830 - mae: 38.4491\n",
      "Mean Squared Error: 4632.5830078125\n",
      "Mean Absolute Error: 38.449073791503906\n",
      "27/27 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Evaluate Model\n",
    "mse, mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "# Plotting true vs predicted values for test set\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.scatter(y_test, y_test_pred, color='blue')\n",
    "ax.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=4)\n",
    "ax.set_xlim([-50, 450])\n",
    "ax.set_ylim([-50, 450])\n",
    "ax.set_xlabel('True Values', fontsize=18)\n",
    "ax.set_ylabel('Predicted Values', fontsize=18)\n",
    "ax.set_title(f'Neural Network - True vs Predicted Values (Test Set)', fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
